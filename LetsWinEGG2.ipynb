{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "from gensim import corpora, models, utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
    "from gensim.models import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy lib\n",
    "# On https://spacy.io/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Parameters #\n",
    "##############\n",
    "\n",
    "min_gram = 1\n",
    "max_gram = 3\n",
    "\n",
    "# To create ours partitions, we must first know the years which will be the limits\n",
    "limit_years = [2007, 2010, 2013, 2016]\n",
    "\n",
    "# Ignore words that appear at a frequency less than max_frequ in the corpus\n",
    "max_frequ = 0.8\n",
    "\n",
    "# Ignore words appearing less than min_appear in the whole corpus\n",
    "min_appear = 5\n",
    "\n",
    "# Range fo cluster number you want to test\n",
    "cluster_ranges = range(2, 30) #range(2, 100) # Warning, long to compute (but nice)\n",
    "\n",
    "# Number of trial you want to do for each test\n",
    "nb_trial_by_test = 3\n",
    "\n",
    "# Number of cluster you finally choose\n",
    "nb_cluster = 20\n",
    "\n",
    "# Max iteration for each kmeans (default: 300)\n",
    "max_iter = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas preprocessing methods.\n",
    "\n",
    "# Lemmatisation without poncutations\n",
    "\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()\n",
    "fstw = stopwords.words('french')\n",
    "\n",
    "# French Stop Words, extraits depuis le fichier stopwords-fr.txt + stopwords french de nltk\n",
    "sourceFST = [x.replace('\\n', '') for x in open('stopwords-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]+fstw\n",
    "sourceFST += [x.replace('\\n', '') for x in open('perso_words-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]\n",
    "\n",
    "# Based on ration of french and english stopwords\n",
    "def isEnglish(article):\n",
    "    total_fsw = len([x for x in article.split() if x in sourceFST])\n",
    "    total_esw = len([x for x in article.split() if x in stopwords.words('english')])\n",
    "    ratio = 100\n",
    "    if total_fsw != 0:\n",
    "        ratio = total_esw/total_fsw\n",
    "    return ratio > 1 and total_esw > 3\n",
    "\n",
    "def lemmatize(article):\n",
    "    arti_lower = article.lower()\n",
    "    arti_2words = re.sub(\" [0-z][0-z] \", \" \", arti_lower) # word of length < 2\n",
    "    arti_e = re.sub(\"(é|è|ê)\", \"e\", arti_2words)\n",
    "    arti_o = re.sub(\"à\", \"a\", arti_e)\n",
    "    arti_i = re.sub(\"ô\", \"o\", arti_o)\n",
    "    artiregex = re.sub(\"î\", \"i\", arti_i)\n",
    "    output = []\n",
    "    outPonc = artiregex.translate(artiregex.maketrans(\"\",\"\", string.punctuation))\n",
    "    outLem = nlp(outPonc)\n",
    "    for token in outLem:\n",
    "        if token.lemma_ not in sourceFST and [x for x in token.lemma_ if x not in \"0123456789\"] != []:\n",
    "            output.append(token.lemma_)\n",
    "    res = ' '.join(output)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    "data = pd.read_csv('export_articles_EGC_2004_2018.csv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process our corpus, and determine a limit to split it in partitions\n",
    "\n",
    "# usable[] correspond to our corpus processed\n",
    "# limits[] let us know when to delimit partitions\n",
    "limits = []\n",
    "usable = []\n",
    "\n",
    "prev_year = data['year'][0]\n",
    "numArti = 0\n",
    "for i in range(0, len(data['abstract']), 1):\n",
    "    #if not null, empty, or whatever (so if there is a abstract):\n",
    "    if not isinstance(data['abstract'][i], float) and not isEnglish(data['abstract'][i]):\n",
    "        text = data['abstract'][i]\n",
    "        if not isinstance(data['title'][i], float):\n",
    "            text += \" \"+data['title'][i]\n",
    "\n",
    "        numArti+=1\n",
    "        usable.append(re.sub(\" [0-z][0-z] \", \" \", stemmer.stem(lemmatize(text))))\n",
    "        year = data['year'][i]\n",
    "        if year != prev_year:\n",
    "            prev_year = year\n",
    "            if year in limit_years:\n",
    "                limits.append(numArti)\n",
    "limits.append(numArti)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process word removal\n",
    "post_words = [x.replace('\\n', '') for x in open('post_process_words-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]\n",
    "\n",
    "for i in range(0, len(usable)):\n",
    "    arti = usable[i].split()\n",
    "    res = []\n",
    "    for word in arti:\n",
    "        if word not in post_words:\n",
    "            res.append(word)\n",
    "    usable[i] = ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'articles = 991\n",
      "nombre de mots = 2179\n",
      "limits = [114, 301, 468, 694, 991]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'plateforme objectif permettre citoyen euxmemer tweet politique devenement specifiqu francepour lelection presidentiell ideo2017 analyser quasitemps reel message candidat fournir principal caracteristiqueslusage lexiqu politique comparaison candidat ideo2017 plateforme citoyen dediee lanalyse tweet evenement polit'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display pre-processed datas\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=sourceFST, use_idf=True, ngram_range=(min_gram, max_gram), max_df=max_frequ, min_df=min_appear)\n",
    "tfidf = vectorizer.fit_transform(usable)\n",
    "\n",
    "print(\"nombre d'articles =\", len(usable))\n",
    "print(\"nombre de mots =\", len(tfidf.toarray()[0]))\n",
    "print(\"limits =\", limits)\n",
    "\n",
    "usable[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of partitions_tfidf[], which give us the TFIDF of each cluster of each partition\n",
    "# partitions_tfidf[num_partition][num_doc][num_word]\n",
    "# Beware, num_doc can't be equals to 1091 (max). You have partitions, so every doc aren't in every partitions\n",
    "# num_word can be found via vectorizer.get_feature_name()\n",
    "partitions_tfidf = []\n",
    "beg = 0\n",
    "for l in limits:\n",
    "    last = l\n",
    "    partitions_tfidf.append([list(x) for x in list(tfidf.toarray())[beg:last]])\n",
    "    beg = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acce',\n",
       " 'accessible',\n",
       " 'achat',\n",
       " 'acquisition',\n",
       " 'acquérir',\n",
       " 'acteur',\n",
       " 'actif',\n",
       " 'action',\n",
       " 'activite',\n",
       " 'actuel',\n",
       " 'actuellement',\n",
       " 'adapt',\n",
       " 'adaptatif',\n",
       " 'adaptation',\n",
       " 'adapte',\n",
       " 'adaptee',\n",
       " 'adapter',\n",
       " 'adequat',\n",
       " 'adn',\n",
       " 'adopter',\n",
       " 'afc',\n",
       " 'affiner',\n",
       " 'agent',\n",
       " 'agregation',\n",
       " 'aid',\n",
       " 'aider',\n",
       " 'ainsiqu',\n",
       " 'ajoutee',\n",
       " 'ajouter',\n",
       " 'ala',\n",
       " 'aleatoir',\n",
       " 'algebriqu',\n",
       " 'algorithme',\n",
       " 'algorithme dapprentissage',\n",
       " 'algorithme dextraction',\n",
       " 'algorithme efficace',\n",
       " 'algorithme fouiller',\n",
       " 'algorithme incremental',\n",
       " 'algorithmique',\n",
       " 'alignement',\n",
       " 'alternatif',\n",
       " 'amelior',\n",
       " 'amelioration',\n",
       " 'ameliore',\n",
       " 'amelioree',\n",
       " 'ameliorer',\n",
       " 'ameliorer qualite',\n",
       " 'amene',\n",
       " 'amont',\n",
       " 'analys',\n",
       " 'analyse',\n",
       " 'analyser',\n",
       " 'analyser factoriel',\n",
       " 'analyser semantiqu',\n",
       " 'analytique',\n",
       " 'anne',\n",
       " 'annees',\n",
       " 'annot',\n",
       " 'annotation',\n",
       " 'annotation semantiqu',\n",
       " 'annoter',\n",
       " 'anormal',\n",
       " 'anr',\n",
       " 'apartir',\n",
       " 'apparer',\n",
       " 'appartenir',\n",
       " 'appel',\n",
       " 'appele',\n",
       " 'appelee',\n",
       " 'appeler',\n",
       " 'applicable',\n",
       " 'applicatif',\n",
       " 'application',\n",
       " 'application reell',\n",
       " 'appliqu',\n",
       " 'applique',\n",
       " 'appliquee',\n",
       " 'appliquees',\n",
       " 'appliquer',\n",
       " 'apport',\n",
       " 'apporter',\n",
       " 'apprehender',\n",
       " 'apprendre',\n",
       " 'apprentissage',\n",
       " 'apprentissage automatique',\n",
       " 'apprentissage supervis',\n",
       " 'approche',\n",
       " 'approche existant',\n",
       " 'appropriee',\n",
       " 'approprier',\n",
       " 'approximatif',\n",
       " 'approximation',\n",
       " 'arbitraire',\n",
       " 'arborescent',\n",
       " 'arbre',\n",
       " 'arbre decision',\n",
       " 'architecturer',\n",
       " 'article',\n",
       " 'article classification',\n",
       " 'article decrit',\n",
       " 'article etuder',\n",
       " 'article etudie',\n",
       " 'article interesser',\n",
       " 'article introduire',\n",
       " 'article methode',\n",
       " 'article methode original',\n",
       " 'article methodologie',\n",
       " 'article montrer',\n",
       " 'article nouvel',\n",
       " 'article permettre',\n",
       " 'article present',\n",
       " 'article present methode',\n",
       " 'article presenter',\n",
       " 'article presenton',\n",
       " 'article traire',\n",
       " 'artificiel',\n",
       " 'ascendant',\n",
       " 'ascendant hierarchiqu',\n",
       " 'aspect',\n",
       " 'assister',\n",
       " 'associ',\n",
       " 'association',\n",
       " 'associe',\n",
       " 'associee',\n",
       " 'associeer',\n",
       " 'associees',\n",
       " 'associer',\n",
       " 'assurer',\n",
       " 'attaquer',\n",
       " 'atteindre',\n",
       " 'attention',\n",
       " 'attribu',\n",
       " 'attribut',\n",
       " 'atypique',\n",
       " 'augmenter',\n",
       " 'automat',\n",
       " 'automate',\n",
       " 'automatique',\n",
       " 'automatiquement',\n",
       " 'automatiser',\n",
       " 'autoorganisatrice',\n",
       " 'autour',\n",
       " 'avancee',\n",
       " 'avantage',\n",
       " 'axe',\n",
       " 'axer',\n",
       " 'axiome',\n",
       " 'baptis',\n",
       " 'base',\n",
       " 'base donneer',\n",
       " 'base relationnel',\n",
       " 'baser',\n",
       " 'baser dapprentissage',\n",
       " 'baser donneer',\n",
       " 'baser modele',\n",
       " 'baser relationnel',\n",
       " 'baser technique',\n",
       " 'batch',\n",
       " 'bayesien',\n",
       " 'bayesien naïf',\n",
       " 'bayesienn',\n",
       " 'benchmark',\n",
       " 'beneficier',\n",
       " 'besoin',\n",
       " 'biais',\n",
       " 'bibliographique',\n",
       " 'biclustering',\n",
       " 'binaire',\n",
       " 'bioinformatique',\n",
       " 'biologique',\n",
       " 'biomedical',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'booleenn',\n",
       " 'boosting',\n",
       " 'born',\n",
       " 'bruitees',\n",
       " 'brut',\n",
       " 'cadrer',\n",
       " 'cadrer article',\n",
       " 'cadrer classification',\n",
       " 'cadrer general',\n",
       " 'cadrer lanalyse',\n",
       " 'cadrer projet',\n",
       " 'cadrer rechercher',\n",
       " 'cadrer theoriqu',\n",
       " 'cadrer travail',\n",
       " 'calcul',\n",
       " 'calcul similarite',\n",
       " 'calculee',\n",
       " 'calculer',\n",
       " 'campagne',\n",
       " 'cancer',\n",
       " 'candidat',\n",
       " 'capable',\n",
       " 'capacite',\n",
       " 'capteur',\n",
       " 'capturer',\n",
       " 'caracter',\n",
       " 'caractere',\n",
       " 'caracterisation',\n",
       " 'caracterise',\n",
       " 'caracteriseer',\n",
       " 'caracteriser',\n",
       " 'caracteristiqu',\n",
       " 'caracteristique',\n",
       " 'caracteristiquer',\n",
       " 'cart',\n",
       " 'carte',\n",
       " 'carte autoorganisatrice',\n",
       " 'carte topologique',\n",
       " 'cartographie',\n",
       " 'cartographique',\n",
       " 'categorie',\n",
       " 'categoriel',\n",
       " 'categoriell',\n",
       " 'categorisation',\n",
       " 'causer',\n",
       " 'celer',\n",
       " 'cell',\n",
       " 'cellule',\n",
       " 'centaine',\n",
       " 'central',\n",
       " 'centree',\n",
       " 'centrer',\n",
       " 'cesser',\n",
       " 'cestadir',\n",
       " 'chain',\n",
       " 'chaine',\n",
       " 'chaine markov',\n",
       " 'challenge',\n",
       " 'champ',\n",
       " 'changement',\n",
       " 'charger',\n",
       " 'chemin',\n",
       " 'chercheur',\n",
       " 'choisir',\n",
       " 'choix',\n",
       " 'choix mesurer',\n",
       " 'chronique',\n",
       " 'cibl',\n",
       " 'cibler',\n",
       " 'classe',\n",
       " 'classement',\n",
       " 'classer',\n",
       " 'classificateur',\n",
       " 'classification',\n",
       " 'classification automatique',\n",
       " 'classification document',\n",
       " 'classification hierarchiqu',\n",
       " 'classification multilabel',\n",
       " 'classification supervise',\n",
       " 'classification supervisee',\n",
       " 'classifier',\n",
       " 'classifieur',\n",
       " 'classifieur bayesien',\n",
       " 'classifieur bayesien naïf',\n",
       " 'classique',\n",
       " 'cle',\n",
       " 'clef',\n",
       " 'client',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'coclustering',\n",
       " 'codage',\n",
       " 'coefficient',\n",
       " 'coeur',\n",
       " 'cognitif',\n",
       " 'coherence',\n",
       " 'collaboratif',\n",
       " 'collaboration',\n",
       " 'collecter',\n",
       " 'collectif',\n",
       " 'collection',\n",
       " 'collection document',\n",
       " 'colonne',\n",
       " 'combin',\n",
       " 'combinaison',\n",
       " 'combinatoire',\n",
       " 'combiner',\n",
       " 'commencer',\n",
       " 'commercial',\n",
       " 'commun',\n",
       " 'communaut',\n",
       " 'communautair',\n",
       " 'communautaire',\n",
       " 'communaute',\n",
       " 'communication',\n",
       " 'compact',\n",
       " 'compacter',\n",
       " 'comparaison',\n",
       " 'comparatif',\n",
       " 'comparee',\n",
       " 'comparer',\n",
       " 'comparer resultat',\n",
       " 'compatible',\n",
       " 'competence',\n",
       " 'complementair',\n",
       " 'complementarite',\n",
       " 'complet',\n",
       " 'completer',\n",
       " 'complex',\n",
       " 'complexe',\n",
       " 'complexit',\n",
       " 'complexite',\n",
       " 'comportement',\n",
       " 'comportemer',\n",
       " 'comporter',\n",
       " 'composant',\n",
       " 'compose',\n",
       " 'composer',\n",
       " 'comprehension',\n",
       " 'comprendre',\n",
       " 'compromis',\n",
       " 'compter',\n",
       " 'concentrer',\n",
       " 'concept',\n",
       " 'concept treillis',\n",
       " 'concepteur',\n",
       " 'conception',\n",
       " 'conceptuel',\n",
       " 'concerner',\n",
       " 'concevoir',\n",
       " 'concret',\n",
       " 'condensee',\n",
       " 'condensees',\n",
       " 'condition',\n",
       " 'conditionnel',\n",
       " 'conduire',\n",
       " 'conferenc',\n",
       " 'conference',\n",
       " 'confiance',\n",
       " 'configuration',\n",
       " 'confirmer',\n",
       " 'conflit',\n",
       " 'confronter',\n",
       " 'conjoint',\n",
       " 'conjointement',\n",
       " 'connaissancer',\n",
       " 'connaître',\n",
       " 'connexion',\n",
       " 'connu',\n",
       " 'consequent',\n",
       " 'conserver',\n",
       " 'consider',\n",
       " 'considere',\n",
       " 'consideree',\n",
       " 'considerer',\n",
       " 'consist',\n",
       " 'consister',\n",
       " 'consommation',\n",
       " 'constant',\n",
       " 'constater',\n",
       " 'constituer',\n",
       " 'construction',\n",
       " 'construction automatique',\n",
       " 'construction darbr',\n",
       " 'construction dontologie',\n",
       " 'construir',\n",
       " 'construire',\n",
       " 'construire partir',\n",
       " 'construit',\n",
       " 'construit partir',\n",
       " 'contenir',\n",
       " 'contenir document',\n",
       " 'contenu',\n",
       " 'context',\n",
       " 'contexte',\n",
       " 'contextuel',\n",
       " 'contingence',\n",
       " 'continu',\n",
       " 'continuer',\n",
       " 'contraindre',\n",
       " 'contraint',\n",
       " 'contrainte',\n",
       " 'contrairement',\n",
       " 'contribuer',\n",
       " 'contribution',\n",
       " 'controle',\n",
       " 'controler',\n",
       " 'convergence',\n",
       " 'convier',\n",
       " 'conçu',\n",
       " 'cooperativ',\n",
       " 'corpu',\n",
       " 'corpus',\n",
       " 'correct',\n",
       " 'correctement',\n",
       " 'correlation',\n",
       " 'correspondance',\n",
       " 'correspondance afc',\n",
       " 'correspondant',\n",
       " 'correspondre',\n",
       " 'couleur',\n",
       " 'coupl',\n",
       " 'couple',\n",
       " 'coupler',\n",
       " 'courir',\n",
       " 'courir temps',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'couverture',\n",
       " 'couvrir',\n",
       " 'coût',\n",
       " 'coûteux',\n",
       " 'creation',\n",
       " 'cree',\n",
       " 'creer',\n",
       " 'criter',\n",
       " 'critere',\n",
       " 'critere devaluation',\n",
       " 'croisee',\n",
       " 'croiser',\n",
       " 'croissance',\n",
       " 'croyance',\n",
       " 'croître',\n",
       " 'cube',\n",
       " 'cuber',\n",
       " 'culturel',\n",
       " 'cycle',\n",
       " 'dabord',\n",
       " 'daccelerer',\n",
       " 'dacquisition',\n",
       " 'dadapter',\n",
       " 'dagregation',\n",
       " 'daid',\n",
       " 'daid decision',\n",
       " 'daider',\n",
       " 'dalgorithme',\n",
       " 'dalignemer',\n",
       " 'dameliorer',\n",
       " 'dameliorer performance',\n",
       " 'danalyse',\n",
       " 'danalyser',\n",
       " 'dannotation',\n",
       " 'danscet',\n",
       " 'danscet article',\n",
       " 'dansl',\n",
       " 'dansun',\n",
       " 'dappariemer',\n",
       " 'dapparition',\n",
       " 'dappartenance',\n",
       " 'dapplication',\n",
       " 'dapporter',\n",
       " 'dapprendre',\n",
       " 'dapprentissage',\n",
       " 'dapprentissage automatique',\n",
       " 'dapprentissage supervis',\n",
       " 'darbr',\n",
       " 'darbr decision',\n",
       " 'darticl',\n",
       " 'dassoci',\n",
       " 'dassociation',\n",
       " 'dater',\n",
       " 'dater mining',\n",
       " 'dater stream',\n",
       " 'dattribut',\n",
       " 'dattributs',\n",
       " 'daugmenter',\n",
       " 'dautre',\n",
       " 'dautre partir',\n",
       " 'debut',\n",
       " 'decd',\n",
       " 'decennie',\n",
       " 'dechantillon',\n",
       " 'dechantillonnage',\n",
       " 'decider',\n",
       " 'decideur',\n",
       " 'decis',\n",
       " 'decision',\n",
       " 'decisionnel',\n",
       " 'decisionnell',\n",
       " 'decomposition',\n",
       " 'decoupage',\n",
       " 'decouvert',\n",
       " 'decouverte',\n",
       " 'decouverte motif',\n",
       " 'decouvrir',\n",
       " 'decouvrir motif',\n",
       " 'decrir',\n",
       " 'decrire',\n",
       " 'decrit',\n",
       " 'decrite',\n",
       " 'decrivant',\n",
       " 'decriver',\n",
       " 'decrivons',\n",
       " 'dedie',\n",
       " 'dediee',\n",
       " 'dedition',\n",
       " 'dedonnee',\n",
       " 'deduire',\n",
       " 'defaut',\n",
       " 'deffectuer',\n",
       " 'defi',\n",
       " 'defi egc',\n",
       " 'defini',\n",
       " 'definie',\n",
       " 'definier',\n",
       " 'definir',\n",
       " 'definis',\n",
       " 'definisser',\n",
       " 'definit',\n",
       " 'definition',\n",
       " 'degager',\n",
       " 'degr',\n",
       " 'degre',\n",
       " 'delagage',\n",
       " 'delement',\n",
       " 'demander',\n",
       " 'demarch',\n",
       " 'demonstration',\n",
       " 'denrichir',\n",
       " 'dense',\n",
       " 'densembl',\n",
       " 'densite',\n",
       " 'dentiter',\n",
       " 'dentre',\n",
       " 'dentrepris',\n",
       " 'depart',\n",
       " 'dependanc',\n",
       " 'dependance',\n",
       " 'dependance fonctionnel',\n",
       " 'depender',\n",
       " 'deper',\n",
       " 'dequivalence',\n",
       " 'derive',\n",
       " 'derreur',\n",
       " 'descripteur',\n",
       " 'descriptif',\n",
       " 'description',\n",
       " 'desdonnee',\n",
       " 'desequilibre',\n",
       " 'destimer',\n",
       " 'detablir',\n",
       " 'detailler',\n",
       " 'detat',\n",
       " 'detecter',\n",
       " 'detection',\n",
       " 'detection changement',\n",
       " 'detectiond',\n",
       " 'detendre',\n",
       " 'determination',\n",
       " 'determine',\n",
       " 'determiner',\n",
       " 'detr',\n",
       " 'detre',\n",
       " 'detude',\n",
       " 'detudier',\n",
       " 'deuxieme',\n",
       " 'devaluation',\n",
       " 'devaluer',\n",
       " 'devaluer qualite',\n",
       " 'developp',\n",
       " 'developpe',\n",
       " 'developpee',\n",
       " 'developpement',\n",
       " 'developpemer',\n",
       " 'developper',\n",
       " 'devenement',\n",
       " 'devenir',\n",
       " 'devolution',\n",
       " 'dexecution',\n",
       " 'dexempl',\n",
       " 'dexperience',\n",
       " 'dexperimentation',\n",
       " 'dexploiter',\n",
       " 'dexploration',\n",
       " 'dexplorer',\n",
       " 'dexpression',\n",
       " 'dexprimer',\n",
       " 'dextraction',\n",
       " 'dextraction motif',\n",
       " 'dextraction partir',\n",
       " 'dextrair',\n",
       " 'dextraire',\n",
       " 'dextraire motif',\n",
       " 'dheuristiqu',\n",
       " 'diagnostic',\n",
       " 'dictionnair',\n",
       " 'didentification',\n",
       " 'didentifier',\n",
       " 'difference',\n",
       " 'differenter',\n",
       " 'difficile',\n",
       " 'difficilement',\n",
       " 'difficult',\n",
       " 'difficulte',\n",
       " 'diffusion',\n",
       " 'dimag',\n",
       " 'dimage',\n",
       " 'dimager',\n",
       " 'dimension',\n",
       " 'dincertitude',\n",
       " 'dindexation',\n",
       " 'dindice',\n",
       " 'dindividus',\n",
       " 'dinduction',\n",
       " 'dinference',\n",
       " 'dinferer',\n",
       " 'dinfluence',\n",
       " 'dinform',\n",
       " 'dinformation',\n",
       " 'dintegration',\n",
       " 'dintegrer',\n",
       " 'dinteraction',\n",
       " 'dinteret',\n",
       " 'dinternet',\n",
       " 'dinterpretation',\n",
       " 'dinterrogation',\n",
       " 'dintroduir',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'discret',\n",
       " 'discretisation',\n",
       " 'discriminant',\n",
       " 'discriminanter',\n",
       " 'discrimination',\n",
       " 'discriminer',\n",
       " 'discussion',\n",
       " 'discuter',\n",
       " 'disponible',\n",
       " 'disposer',\n",
       " 'dispositif',\n",
       " 'disposition',\n",
       " 'dissimilarit',\n",
       " 'dissimilarite',\n",
       " 'distance',\n",
       " 'distancer',\n",
       " 'distinct',\n",
       " 'distinguer',\n",
       " 'distribu',\n",
       " 'distribuer',\n",
       " 'distribution',\n",
       " 'ditems',\n",
       " 'ditemset',\n",
       " 'ditemset frequent',\n",
       " 'diversite',\n",
       " 'diviser',\n",
       " 'dizaine',\n",
       " 'dobjet',\n",
       " 'dobjets',\n",
       " 'dobtenir',\n",
       " 'docu',\n",
       " 'document',\n",
       " 'document textuel',\n",
       " 'document xml',\n",
       " 'documentaire',\n",
       " 'doffr',\n",
       " 'domaine',\n",
       " 'domaine dapplication',\n",
       " 'domaine fouiller',\n",
       " 'domaine lapprentissage',\n",
       " 'donneer',\n",
       " 'donneer article',\n",
       " 'donneer luci',\n",
       " 'donneer reell',\n",
       " 'donneer textuel',\n",
       " 'donnees',\n",
       " 'donner',\n",
       " 'donner resultat',\n",
       " 'dontologie',\n",
       " 'dontologie partir',\n",
       " 'dontologier',\n",
       " 'dopinion',\n",
       " 'doptimisation',\n",
       " 'dordre',\n",
       " 'dorigine',\n",
       " 'doter',\n",
       " 'doutil',\n",
       " 'doutils',\n",
       " 'duree',\n",
       " 'durer',\n",
       " 'durer processus',\n",
       " 'dusage',\n",
       " 'dutilisateur',\n",
       " 'dutilisation',\n",
       " 'dutiliser',\n",
       " 'dynam',\n",
       " 'dynamique',\n",
       " 'ecd',\n",
       " 'echantillon',\n",
       " 'echantillonnage',\n",
       " 'echell',\n",
       " 'echelle',\n",
       " 'eclairage',\n",
       " 'economiqu',\n",
       " 'effectu',\n",
       " 'efficace',\n",
       " 'efficacement',\n",
       " 'efficacite',\n",
       " 'effort',\n",
       " 'egc',\n",
       " 'element',\n",
       " 'elev',\n",
       " 'eleve',\n",
       " 'elevee',\n",
       " 'emergent',\n",
       " 'empirique',\n",
       " 'empiriquement',\n",
       " 'employer',\n",
       " 'encompte',\n",
       " 'encourageant',\n",
       " 'encourageant prometteur',\n",
       " 'engendrer',\n",
       " 'enjeu',\n",
       " 'enjeu majeur',\n",
       " 'enregistrement',\n",
       " 'enrichir',\n",
       " 'enrichissement',\n",
       " 'ensembl',\n",
       " 'ensembl donneer',\n",
       " 'ensembl mesure',\n",
       " 'ensemble',\n",
       " 'ensemble donneer',\n",
       " 'ensemble regl',\n",
       " 'ensembliste',\n",
       " 'entite',\n",
       " 'entrainer',\n",
       " 'entrepot',\n",
       " 'entreprendre',\n",
       " 'entreprise',\n",
       " 'environnement',\n",
       " 'envisageable',\n",
       " 'equivalent',\n",
       " 'erreur',\n",
       " 'espac',\n",
       " 'espace',\n",
       " 'espacer',\n",
       " 'essentiel',\n",
       " 'essentiellement',\n",
       " 'estim',\n",
       " 'estimateur',\n",
       " 'estimation',\n",
       " 'estimation densite',\n",
       " 'estimee',\n",
       " 'estimer',\n",
       " 'etablie',\n",
       " 'etablir',\n",
       " 'etablisser',\n",
       " 'etape',\n",
       " 'etat',\n",
       " 'etde',\n",
       " 'etendu',\n",
       " 'eter',\n",
       " 'etiquetage',\n",
       " 'etiquete',\n",
       " 'etl',\n",
       " 'etle',\n",
       " 'etroitement',\n",
       " 'etude',\n",
       " 'etude comparatif',\n",
       " 'etude experimental',\n",
       " 'etuder',\n",
       " 'etudie',\n",
       " 'etudiee',\n",
       " 'etudier',\n",
       " 'euclidien',\n",
       " 'evalu',\n",
       " 'evaluation',\n",
       " 'evalue',\n",
       " 'evaluee',\n",
       " 'evaluees',\n",
       " 'evaluer',\n",
       " 'evenement',\n",
       " 'evidence',\n",
       " 'eviter',\n",
       " 'evoluer',\n",
       " 'evolution',\n",
       " 'evolutiv',\n",
       " 'exact',\n",
       " 'examiner',\n",
       " 'exemple',\n",
       " 'exhaustif',\n",
       " 'exhiber',\n",
       " 'existant',\n",
       " 'exister',\n",
       " 'experience',\n",
       " 'experience meneer',\n",
       " 'experience montrer',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experimentalement',\n",
       " 'experimentation',\n",
       " 'experimentation jeu',\n",
       " 'experimentation menee',\n",
       " 'experimentation montrer',\n",
       " 'experimentaux',\n",
       " 'experimentaux montrer',\n",
       " 'expert',\n",
       " 'expert domaine',\n",
       " 'explicatif',\n",
       " 'expliciter',\n",
       " 'expliquer',\n",
       " 'exploitable',\n",
       " 'exploitation',\n",
       " 'exploiter',\n",
       " 'exploration',\n",
       " 'exploratoire',\n",
       " 'explorer',\n",
       " 'exponentiel',\n",
       " 'exposer',\n",
       " 'expression',\n",
       " 'exprimeer',\n",
       " 'exprimer',\n",
       " 'extension',\n",
       " 'extraction',\n",
       " 'extraction motif',\n",
       " 'extraction regl',\n",
       " 'extraire',\n",
       " 'extraire motif',\n",
       " 'extrait',\n",
       " 'extraite',\n",
       " 'face',\n",
       " 'facile',\n",
       " 'facilement',\n",
       " 'faciliter',\n",
       " 'facteur',\n",
       " 'factoriel',\n",
       " 'factoriel correspondance',\n",
       " 'factoriel correspondance afc',\n",
       " 'factorisation',\n",
       " 'faible',\n",
       " 'faire',\n",
       " 'faire appel',\n",
       " 'faire face',\n",
       " 'faire lobjet',\n",
       " 'faire partir',\n",
       " 'faisabilite',\n",
       " 'famille',\n",
       " 'favoriser',\n",
       " 'feature',\n",
       " 'ferme',\n",
       " 'ferme frequent',\n",
       " 'fiabilite',\n",
       " 'fiable',\n",
       " 'fichier',\n",
       " 'filtrage',\n",
       " 'filtrer',\n",
       " 'fin',\n",
       " 'final',\n",
       " 'finalement',\n",
       " 'financier',\n",
       " 'fixe',\n",
       " 'fixer',\n",
       " 'flexible',\n",
       " 'flot',\n",
       " 'flot donneer',\n",
       " 'flou',\n",
       " 'flouer',\n",
       " 'flux',\n",
       " 'flux donneer',\n",
       " 'focaliser',\n",
       " 'fonction',\n",
       " 'fonction croyance',\n",
       " 'fonctionnalite',\n",
       " 'fonctionnel',\n",
       " 'fonctionnement',\n",
       " 'fonctionner',\n",
       " 'fond',\n",
       " 'fondamental',\n",
       " 'fondee',\n",
       " 'fondre',\n",
       " 'foret',\n",
       " 'foret aleatoir',\n",
       " 'formalisation',\n",
       " 'formaliser',\n",
       " 'formalisme',\n",
       " 'format',\n",
       " 'formation',\n",
       " 'forme',\n",
       " 'formel',\n",
       " 'formel concept',\n",
       " 'former',\n",
       " 'former regl',\n",
       " 'formulation',\n",
       " 'formuler',\n",
       " 'fort',\n",
       " 'fortement',\n",
       " 'fouill',\n",
       " 'fouill donneer',\n",
       " 'fouiller',\n",
       " 'fouiller donneer',\n",
       " 'fouiller grand',\n",
       " 'fouiller texter',\n",
       " 'fournir',\n",
       " 'framework',\n",
       " 'france',\n",
       " 'français',\n",
       " 'frequence',\n",
       " 'frequent',\n",
       " 'frequente',\n",
       " 'fusion',\n",
       " 'futur',\n",
       " 'gain',\n",
       " 'galoi',\n",
       " 'garantir',\n",
       " 'gene',\n",
       " 'gener',\n",
       " 'general',\n",
       " 'generalement',\n",
       " 'generalisation',\n",
       " 'generalise',\n",
       " 'generaliser',\n",
       " 'generalist',\n",
       " 'generateur',\n",
       " 'generatif',\n",
       " 'generation',\n",
       " 'genere',\n",
       " 'generee',\n",
       " 'generees',\n",
       " 'generer',\n",
       " 'generiqu',\n",
       " 'genetiqu',\n",
       " 'genre',\n",
       " 'geographiqu',\n",
       " 'gerer',\n",
       " 'gestion',\n",
       " 'gestion flux',\n",
       " 'gestion flux donneer',\n",
       " 'global',\n",
       " 'graduel',\n",
       " 'grammaire',\n",
       " 'grand',\n",
       " 'grand base',\n",
       " 'grand base donneer',\n",
       " 'grand echelle',\n",
       " 'grand ensembl',\n",
       " 'grand graphe',\n",
       " 'grand nombre',\n",
       " 'grand quantite',\n",
       " 'grand tailler',\n",
       " 'grand volume',\n",
       " 'granularite',\n",
       " 'graph',\n",
       " 'graph voisinage',\n",
       " 'graphe',\n",
       " 'graphe conceptuel',\n",
       " 'graphe voisinage',\n",
       " 'grapher',\n",
       " 'graphique',\n",
       " 'griller',\n",
       " 'gros',\n",
       " 'groupe',\n",
       " 'groupement',\n",
       " 'grouper',\n",
       " 'grâce',\n",
       " 'grâce algorithme',\n",
       " 'guid',\n",
       " 'guidee',\n",
       " 'guider',\n",
       " 'habituellement',\n",
       " 'heterogen',\n",
       " 'heterogener',\n",
       " 'heuristique',\n",
       " 'hierarchi',\n",
       " 'hierarchie',\n",
       " 'hierarchiqu',\n",
       " 'historique',\n",
       " 'homogen',\n",
       " 'humain',\n",
       " 'hybride',\n",
       " 'hypothese',\n",
       " 'idee',\n",
       " 'identification',\n",
       " 'identifier',\n",
       " 'ignorer',\n",
       " 'iii',\n",
       " 'illustree',\n",
       " 'illustrer',\n",
       " 'image',\n",
       " 'imager',\n",
       " 'impact',\n",
       " 'implement',\n",
       " 'implementation',\n",
       " 'implemente',\n",
       " 'implicatif',\n",
       " 'implicitement',\n",
       " 'impliqu',\n",
       " 'impliquer',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'importer',\n",
       " 'imposer',\n",
       " 'impossible',\n",
       " 'inclure',\n",
       " 'inconvenient',\n",
       " 'incremental',\n",
       " 'independamment',\n",
       " 'independant',\n",
       " 'index',\n",
       " 'indicateur',\n",
       " 'indice',\n",
       " 'indiquer',\n",
       " 'indispensable',\n",
       " 'individu',\n",
       " 'individuel',\n",
       " 'inductif',\n",
       " 'induire',\n",
       " 'induit',\n",
       " 'industriel',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans & Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeans on tfidf\n",
    "# the labels_ give assignment of doc to the cluster number \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_clustering is a dictionnary \n",
    "# it looks like -> { doc_number : [partition_number, cluster_number] }\n",
    "# This is used to reassign doc number to their respective partition and and cluster\n",
    "\n",
    "def kmeans(nb_clusters):\n",
    "    doc_clustering = {}\n",
    "    \n",
    "    km = KMeans(n_clusters=nb_clusters, max_iter=max_iter)\n",
    "\n",
    "    # Silhouette score mean\n",
    "    silhouette_mean = 0\n",
    "\n",
    "    numDoc = 0\n",
    "    for i in range(0, len(limits)):\n",
    "        dash = km.fit(partitions_tfidf[i])\n",
    "\n",
    "        # Silhouette\n",
    "        silhouette_mean += silhouette_score(partitions_tfidf[i], dash.labels_)\n",
    "\n",
    "        previousBound = 0\n",
    "        if i > 0:\n",
    "            previousBound = limits[i-1]\n",
    "        for numDocItern in range(0, limits[i]-previousBound):\n",
    "            doc_clustering[numDoc] = [i, dash.labels_[numDocItern]]\n",
    "            numDoc+=1\n",
    "\n",
    "    silhouette_mean = silhouette_mean / len(limits)\n",
    "    res = {}\n",
    "    res[\"silhouette\"] = silhouette_mean\n",
    "    res[\"clustering\"] = doc_clustering\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for  2 clusters\n",
      "Computing for  3 clusters\n",
      "Computing for  4 clusters\n",
      "Computing for  5 clusters\n",
      "Computing for  6 clusters\n",
      "Computing for  7 clusters\n",
      "Computing for  8 clusters\n",
      "Computing for  9 clusters\n",
      "Computing for  10 clusters\n",
      "Computing for  11 clusters\n",
      "Computing for  12 clusters\n",
      "Computing for  13 clusters\n",
      "Computing for  14 clusters\n",
      "Computing for  15 clusters\n",
      "Computing for  16 clusters\n",
      "Computing for  17 clusters\n",
      "Computing for  18 clusters\n",
      "Computing for  19 clusters\n",
      "Computing for  20 clusters\n",
      "Computing for  21 clusters\n",
      "Computing for  22 clusters\n",
      "Computing for  23 clusters\n",
      "Computing for  24 clusters\n",
      "Computing for  25 clusters\n",
      "Computing for  26 clusters\n",
      "Computing for  27 clusters\n",
      "Computing for  28 clusters\n",
      "Computing for  29 clusters\n"
     ]
    }
   ],
   "source": [
    "# Compute Silhouette Score for each number of cluster\n",
    "\n",
    "silhouette_by_cluster_nb = {}\n",
    "\n",
    "for nbClusters in cluster_ranges:\n",
    "    print(\"Computing for\", nbClusters, \"clusters...\")\n",
    "    silhouette_avg = 0\n",
    "    for trial in range(0, nb_trial_by_test):\n",
    "        km = kmeans(nbClusters)\n",
    "        silhouette_avg += km[\"silhouette\"]\n",
    "    silhouette_avg = silhouette_avg / nb_trial_by_test\n",
    "    silhouette_by_cluster_nb[nb_clusters] = silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.005410570209443134,\n",
       " 3: 0.006187564487044067,\n",
       " 4: 0.00685720147411483,\n",
       " 5: 0.008150191380431104,\n",
       " 6: 0.008704565403188164,\n",
       " 7: 0.009000500668185118,\n",
       " 8: 0.010777420429916355,\n",
       " 9: 0.011451913110778053,\n",
       " 10: 0.012022667276738048,\n",
       " 11: 0.013108222172617624,\n",
       " 12: 0.013522613422691176,\n",
       " 13: 0.014588560600138986,\n",
       " 14: 0.015610055690953343,\n",
       " 15: 0.016555568462439354,\n",
       " 16: 0.01636134801724312,\n",
       " 17: 0.017897108298325512,\n",
       " 18: 0.017655434085125255,\n",
       " 19: 0.01885256852553832,\n",
       " 20: 0.019543648720926968,\n",
       " 21: 0.02065440013808222,\n",
       " 22: 0.021778124560471887,\n",
       " 23: 0.023321975917530446,\n",
       " 24: 0.022329278939527696,\n",
       " 25: 0.022648310093930774,\n",
       " 26: 0.023402410092019568,\n",
       " 27: 0.024736841405944784,\n",
       " 28: 0.025736564437768523,\n",
       " 29: 0.02577226177039991}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want silhouette scores to be high\n",
    "silhouette_by_cluster_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clustering = kmeans(nb_cluster)[\"clustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to get list of documents number\n",
    "# return [dou numbers]\n",
    "# params : partition_number , cluster number\n",
    "def get_doc(part, clust):\n",
    "    docs = []\n",
    "    for i in range(0,len(doc_clustering)):\n",
    "        if doc_clustering[i][0] == part and doc_clustering[i][1] == clust:\n",
    "            docs.append(i)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the partitions variable\n",
    "# Here partitions[part][cluster] = list of docs numbe\n",
    "partitions = []\n",
    "for i in range(0, len(limits)):\n",
    "    clusters = []\n",
    "    for j in range(0, nb_clusters):\n",
    "        clusters.append(get_doc(i,j))\n",
    "    partitions.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[17, 106],\n",
       "  [2, 29, 51, 95, 104],\n",
       "  [7, 62, 67, 97, 112],\n",
       "  [33, 39, 40, 45, 52, 72, 91, 101],\n",
       "  [6, 12, 41, 92, 108],\n",
       "  [49, 74, 78, 103, 109],\n",
       "  [22, 53, 79, 96, 113],\n",
       "  [3, 13, 28, 42, 47, 64, 75, 83, 90],\n",
       "  [14, 48, 54, 66, 82, 84, 100],\n",
       "  [59, 60],\n",
       "  [36, 37, 71],\n",
       "  [0, 25, 26, 38, 73, 76, 77, 81],\n",
       "  [15, 63, 70, 87],\n",
       "  [24, 27, 30, 35, 44, 89, 110],\n",
       "  [8, 19, 43, 57, 61, 107, 111],\n",
       "  [9, 32, 34, 94, 98],\n",
       "  [4, 23, 56, 58, 65],\n",
       "  [5, 10, 16, 18, 86, 105],\n",
       "  [11, 20, 21, 31, 46, 55, 80, 93, 99],\n",
       "  [1, 50, 68, 69, 85, 88, 102],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[133, 134, 155, 156, 199, 209, 217, 225, 268, 273, 281],\n",
       "  [114,\n",
       "   136,\n",
       "   139,\n",
       "   143,\n",
       "   158,\n",
       "   163,\n",
       "   165,\n",
       "   168,\n",
       "   174,\n",
       "   184,\n",
       "   194,\n",
       "   196,\n",
       "   212,\n",
       "   224,\n",
       "   226,\n",
       "   230,\n",
       "   296],\n",
       "  [125,\n",
       "   128,\n",
       "   146,\n",
       "   162,\n",
       "   171,\n",
       "   185,\n",
       "   192,\n",
       "   204,\n",
       "   231,\n",
       "   255,\n",
       "   257,\n",
       "   259,\n",
       "   262,\n",
       "   274,\n",
       "   286,\n",
       "   300],\n",
       "  [116, 117, 126, 127, 131, 144, 161, 164, 166, 221, 294],\n",
       "  [129, 154, 172, 180, 218, 282, 283, 287, 295],\n",
       "  [135, 141, 150, 169, 173, 181, 193, 198, 202, 241, 243, 252],\n",
       "  [121, 123, 240, 253],\n",
       "  [115, 177, 178, 205, 213, 248, 267, 270, 279, 298, 299],\n",
       "  [118, 145, 167, 176, 189, 190, 201, 249, 271, 292, 297],\n",
       "  [130, 132, 152, 183, 187, 206, 227, 233, 263, 272, 275, 277, 285],\n",
       "  [119, 122, 149, 215, 219, 232, 247, 251, 260, 265],\n",
       "  [138, 147, 200, 244, 258, 289],\n",
       "  [197, 214, 237, 264, 293],\n",
       "  [120, 140, 188, 203, 235, 236, 239, 290, 291],\n",
       "  [137, 195, 208, 222, 284],\n",
       "  [157, 160, 207, 216, 246, 250, 254, 261, 266, 280],\n",
       "  [151, 153, 170, 175, 186, 223, 242],\n",
       "  [148, 191, 238, 256, 269, 278],\n",
       "  [159, 179, 210, 220, 229, 276, 288],\n",
       "  [124, 142, 182, 211, 228, 234, 245],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[309, 317, 327, 388, 396, 404, 433, 459],\n",
       "  [314, 401],\n",
       "  [311, 335, 338, 350, 361, 379, 383, 391, 395, 422, 432, 437, 449, 454],\n",
       "  [321, 330, 345, 357, 358, 366, 389, 403, 412, 414, 416, 424, 463],\n",
       "  [322, 334, 339, 342, 352, 382, 384, 411, 444],\n",
       "  [332, 336, 341, 348, 355, 380, 385, 399, 450, 453, 462],\n",
       "  [363, 367, 402, 426, 435, 438, 458],\n",
       "  [305, 312, 319, 320, 369, 376, 398, 423, 427, 428, 431, 443, 461],\n",
       "  [328, 329, 340, 371, 425, 429],\n",
       "  [301, 333, 343, 430, 445, 446, 465],\n",
       "  [304, 306, 313, 353, 354, 374, 387, 405, 408, 413, 456],\n",
       "  [307, 316, 337, 346, 360, 362, 364, 466],\n",
       "  [303, 310, 368, 393, 397, 400, 417, 441],\n",
       "  [315, 331, 344, 373, 375, 381, 386, 394, 406, 442, 455, 460, 464],\n",
       "  [324, 351, 365, 409, 420],\n",
       "  [302, 359, 390, 392, 448],\n",
       "  [323, 326, 377, 378, 407, 410, 415, 436, 447, 457],\n",
       "  [308, 349, 372, 440, 451, 452, 467],\n",
       "  [356, 418, 434],\n",
       "  [318, 325, 347, 370, 419, 421, 439],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[471,\n",
       "   481,\n",
       "   486,\n",
       "   502,\n",
       "   508,\n",
       "   522,\n",
       "   525,\n",
       "   536,\n",
       "   539,\n",
       "   545,\n",
       "   559,\n",
       "   561,\n",
       "   562,\n",
       "   564,\n",
       "   583,\n",
       "   595,\n",
       "   641,\n",
       "   648,\n",
       "   651,\n",
       "   666,\n",
       "   679,\n",
       "   681,\n",
       "   686,\n",
       "   689,\n",
       "   693],\n",
       "  [482, 497, 511, 520, 565, 575, 622, 627, 637, 640, 662],\n",
       "  [483,\n",
       "   485,\n",
       "   517,\n",
       "   532,\n",
       "   553,\n",
       "   558,\n",
       "   560,\n",
       "   566,\n",
       "   568,\n",
       "   569,\n",
       "   576,\n",
       "   578,\n",
       "   581,\n",
       "   584,\n",
       "   596,\n",
       "   605,\n",
       "   606,\n",
       "   609,\n",
       "   610,\n",
       "   625,\n",
       "   631,\n",
       "   647,\n",
       "   649,\n",
       "   656,\n",
       "   658,\n",
       "   678,\n",
       "   680,\n",
       "   682,\n",
       "   684,\n",
       "   691],\n",
       "  [498, 516, 573, 592, 621, 644, 663],\n",
       "  [493, 499, 503, 513, 515, 518, 554],\n",
       "  [474, 500, 535, 552, 556, 571, 574, 577, 600, 607, 629, 667, 685],\n",
       "  [472, 512, 544, 548, 551, 582, 635, 659, 664, 692],\n",
       "  [470, 526, 528, 563, 590, 615, 620, 628, 690],\n",
       "  [487, 488, 490, 557, 587, 589, 617, 624, 646, 674],\n",
       "  [492, 541, 626, 630, 643, 670],\n",
       "  [478, 480, 495, 530, 538, 540, 585, 586, 633, 660, 675],\n",
       "  [504, 549, 591, 598, 650, 653, 661],\n",
       "  [477, 484, 491, 523, 567, 616],\n",
       "  [476, 521, 527, 531, 547, 555, 597, 623, 639, 669, 672, 676],\n",
       "  [494, 496, 602, 603, 611, 618, 652, 687],\n",
       "  [489, 542, 546, 614, 657, 677, 688],\n",
       "  [479, 509, 529, 580, 588, 594, 601, 604, 683],\n",
       "  [475,\n",
       "   501,\n",
       "   505,\n",
       "   507,\n",
       "   519,\n",
       "   524,\n",
       "   533,\n",
       "   543,\n",
       "   550,\n",
       "   570,\n",
       "   599,\n",
       "   612,\n",
       "   613,\n",
       "   619,\n",
       "   642,\n",
       "   655,\n",
       "   673],\n",
       "  [473, 514, 537, 579, 608, 634, 636, 645, 654, 665, 668],\n",
       "  [468, 469, 506, 510, 534, 572, 593, 632, 638, 671],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[700, 712, 716, 752, 780, 794, 810, 822, 830, 872, 930, 967, 981, 987],\n",
       "  [699,\n",
       "   721,\n",
       "   722,\n",
       "   732,\n",
       "   742,\n",
       "   751,\n",
       "   759,\n",
       "   769,\n",
       "   770,\n",
       "   797,\n",
       "   799,\n",
       "   807,\n",
       "   817,\n",
       "   831,\n",
       "   835,\n",
       "   870,\n",
       "   874,\n",
       "   875,\n",
       "   880,\n",
       "   885,\n",
       "   894,\n",
       "   916,\n",
       "   924,\n",
       "   936,\n",
       "   944,\n",
       "   950,\n",
       "   959,\n",
       "   961,\n",
       "   974],\n",
       "  [711,\n",
       "   744,\n",
       "   745,\n",
       "   762,\n",
       "   766,\n",
       "   774,\n",
       "   775,\n",
       "   800,\n",
       "   802,\n",
       "   816,\n",
       "   856,\n",
       "   892,\n",
       "   917,\n",
       "   919,\n",
       "   926,\n",
       "   933,\n",
       "   952,\n",
       "   958,\n",
       "   972],\n",
       "  [695,\n",
       "   707,\n",
       "   724,\n",
       "   725,\n",
       "   748,\n",
       "   749,\n",
       "   756,\n",
       "   767,\n",
       "   773,\n",
       "   782,\n",
       "   798,\n",
       "   812,\n",
       "   815,\n",
       "   823,\n",
       "   824,\n",
       "   846,\n",
       "   865,\n",
       "   876,\n",
       "   879,\n",
       "   881,\n",
       "   887,\n",
       "   895,\n",
       "   910,\n",
       "   913,\n",
       "   914,\n",
       "   915,\n",
       "   939,\n",
       "   942,\n",
       "   943,\n",
       "   955,\n",
       "   968,\n",
       "   973],\n",
       "  [694, 788, 811, 829, 836, 903, 925, 932, 937, 940, 953, 964, 969],\n",
       "  [710, 726, 728, 736, 755, 791, 813, 825, 841, 845, 889, 935, 983],\n",
       "  [697, 698, 723, 727, 789, 808, 857, 882, 912, 927, 929],\n",
       "  [741, 796, 805, 951, 960, 989],\n",
       "  [703,\n",
       "   718,\n",
       "   719,\n",
       "   720,\n",
       "   734,\n",
       "   743,\n",
       "   750,\n",
       "   753,\n",
       "   771,\n",
       "   852,\n",
       "   861,\n",
       "   869,\n",
       "   898,\n",
       "   901,\n",
       "   908,\n",
       "   954,\n",
       "   957,\n",
       "   982,\n",
       "   984,\n",
       "   990],\n",
       "  [714, 733, 737, 761, 827, 832, 837, 844, 850, 851, 899, 923, 985],\n",
       "  [704, 715, 730, 738, 747, 758, 804, 858, 909, 921, 931, 947, 962],\n",
       "  [705, 713, 757, 777, 818, 842, 886, 896, 904, 911, 966, 977],\n",
       "  [702,\n",
       "   706,\n",
       "   754,\n",
       "   772,\n",
       "   779,\n",
       "   806,\n",
       "   819,\n",
       "   826,\n",
       "   828,\n",
       "   838,\n",
       "   839,\n",
       "   849,\n",
       "   862,\n",
       "   873,\n",
       "   883,\n",
       "   888,\n",
       "   890,\n",
       "   893,\n",
       "   897,\n",
       "   907,\n",
       "   941,\n",
       "   948,\n",
       "   963,\n",
       "   975,\n",
       "   976],\n",
       "  [731, 746, 763, 765, 768, 776, 786, 803, 855, 866, 891, 938, 949, 988],\n",
       "  [696,\n",
       "   701,\n",
       "   760,\n",
       "   764,\n",
       "   783,\n",
       "   787,\n",
       "   790,\n",
       "   795,\n",
       "   820,\n",
       "   834,\n",
       "   843,\n",
       "   848,\n",
       "   853,\n",
       "   854,\n",
       "   867,\n",
       "   868,\n",
       "   922,\n",
       "   979,\n",
       "   980],\n",
       "  [717, 729, 778, 793, 801, 809, 814, 884, 900, 906, 945, 970],\n",
       "  [708, 709, 785, 833, 840, 877, 878, 920, 946, 956, 965, 978],\n",
       "  [739, 740, 781, 784, 792, 821, 871, 918, 928, 934],\n",
       "  [735, 860, 971, 986],\n",
       "  [847, 859, 863, 864, 902, 905],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khi²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_of_your_word = tf[numDoc][strWord]\n",
    "tf = []\n",
    "for doc in usable:\n",
    "    tf_doc = {}\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        tf_doc[word] = doc.count(word)\n",
    "    tf.append(tf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number total of words\n",
    "# nb_total_word[numPartition]\n",
    "nb_total_word = []\n",
    "nb = 0\n",
    "\n",
    "for numDoc in range(0, len(usable)):\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        nb += tf[numDoc][word]\n",
    "    if numDoc+1 in limits:\n",
    "        nb_total_word.append(nb)\n",
    "        nb=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10917, 17349, 16649, 21289, 28637]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_total_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noyau': 0,\n",
       " 'danalyse': 0,\n",
       " 'apparer': 0,\n",
       " 'reell issu': 0,\n",
       " 'tou': 0,\n",
       " 'frequente': 0,\n",
       " 'dexprimer': 0,\n",
       " 'prediction': 0,\n",
       " 'systeme dinformation': 0,\n",
       " 'decrivons': 0,\n",
       " 'evaluer': 0,\n",
       " 'algorithme': 0,\n",
       " 'tenter': 0,\n",
       " 'article classification': 0,\n",
       " 'programmer': 0,\n",
       " 'contribuer': 0,\n",
       " 'proposon': 0,\n",
       " 'segmentation': 0,\n",
       " 'classement': 0,\n",
       " 'jeu': 0,\n",
       " 'scor': 0,\n",
       " 'lextraction motif': 0,\n",
       " 'classe': 0,\n",
       " 'transformer': 0,\n",
       " 'organisation': 0,\n",
       " 'trouver': 0,\n",
       " 'plan': 0,\n",
       " 'knowledge': 0,\n",
       " 'papier presente': 0,\n",
       " 'disposer': 0,\n",
       " 'base donneer': 0,\n",
       " 'lautomatisation': 0,\n",
       " 'constant': 0,\n",
       " 'nombre': 0,\n",
       " 'rappel': 0,\n",
       " 'traduire': 0,\n",
       " 'induire': 0,\n",
       " 'conference': 0,\n",
       " 'determine': 0,\n",
       " 'region': 0,\n",
       " 'article methode original': 0,\n",
       " 'rapport': 0,\n",
       " 'bruitees': 0,\n",
       " 'efficacite': 0,\n",
       " 'detude': 0,\n",
       " 'article decrit': 0,\n",
       " 'dedonnee': 0,\n",
       " 'comprendre': 0,\n",
       " 'collaboratif': 0,\n",
       " 'relatif': 0,\n",
       " 'decouverte motif': 0,\n",
       " 'convergence': 0,\n",
       " 'proposees': 0,\n",
       " 'dense': 0,\n",
       " 'individu': 0,\n",
       " 'graph voisinage': 0,\n",
       " 'nommees': 0,\n",
       " 'cell': 0,\n",
       " 'nommer': 0,\n",
       " 'caracteristiquer': 0,\n",
       " 'attribu': 0,\n",
       " 'reconnaitre': 0,\n",
       " 'synthes': 0,\n",
       " 'capacite': 0,\n",
       " 'comprehension': 0,\n",
       " 'partager': 0,\n",
       " 'interactif': 0,\n",
       " 'volumetrie': 0,\n",
       " 'parametriqu': 0,\n",
       " 'modelisee': 0,\n",
       " 'probabiliste': 0,\n",
       " 'million': 0,\n",
       " 'presentons': 0,\n",
       " 'caracteristique': 1,\n",
       " 'pallier': 0,\n",
       " 'parametre': 0,\n",
       " 'heuristique': 0,\n",
       " 'symbolique': 0,\n",
       " 'donnees': 0,\n",
       " 'syntaxe': 0,\n",
       " 'selection modele': 0,\n",
       " 'ordonne': 0,\n",
       " 'larbr': 0,\n",
       " 'detat': 0,\n",
       " 'tweet': 2,\n",
       " 'symetriqu': 0,\n",
       " 'taux': 0,\n",
       " 'empiriquement': 0,\n",
       " 'presentation': 0,\n",
       " 'litterature': 0,\n",
       " 'probabilit': 0,\n",
       " 'permettre dameliorer': 0,\n",
       " 'estimation': 0,\n",
       " 'grand quantite': 0,\n",
       " 'system': 0,\n",
       " 'mieux comprendre': 0,\n",
       " 'besoin': 0,\n",
       " 'ascendant': 0,\n",
       " 'faire lobjet': 0,\n",
       " 'faisabilite': 0,\n",
       " 'p2p': 0,\n",
       " 'determiner': 0,\n",
       " 'exploration': 0,\n",
       " 'acquérir': 0,\n",
       " 'regl': 0,\n",
       " 'venir': 0,\n",
       " 'etude comparatif': 0,\n",
       " 'graphe voisinage': 0,\n",
       " 'utiliser modele': 0,\n",
       " 'large': 0,\n",
       " 'demarch': 0,\n",
       " 'linformation': 0,\n",
       " 'demander': 0,\n",
       " 'projection': 0,\n",
       " 'factoriel correspondance': 0,\n",
       " 'dentrepris': 0,\n",
       " 'scenario': 0,\n",
       " 'fondre': 0,\n",
       " 'usuel': 0,\n",
       " 'arbre decision': 0,\n",
       " 'iterativ': 0,\n",
       " 'ordre': 0,\n",
       " 'terminologie': 0,\n",
       " 'degr': 0,\n",
       " 'contexte': 0,\n",
       " 'etde': 0,\n",
       " 'performance predictiv': 0,\n",
       " 'partir corpus': 0,\n",
       " 'moduler': 0,\n",
       " 'egc': 0,\n",
       " 'maniere': 0,\n",
       " 'agregation': 0,\n",
       " 'posseder': 0,\n",
       " 'jeu reell': 0,\n",
       " 'utiliser algorithme': 0,\n",
       " 'mapping': 0,\n",
       " 'didentifier': 0,\n",
       " 'relier': 0,\n",
       " 'incremental': 0,\n",
       " 'fixe': 0,\n",
       " 'programmation logique inductif': 0,\n",
       " 'explicatif': 0,\n",
       " 'premiere': 0,\n",
       " 'letat': 0,\n",
       " 'lutilisation': 0,\n",
       " 'capteur': 0,\n",
       " 'resultat obtenir': 0,\n",
       " 'dapprentissage': 0,\n",
       " 'etape': 0,\n",
       " 'choix mesurer': 0,\n",
       " 'resultatsobtenu': 0,\n",
       " 'miser': 0,\n",
       " 'doffr': 0,\n",
       " 'jeu reel': 0,\n",
       " 'interpretation': 0,\n",
       " 'elev': 0,\n",
       " 'integre': 0,\n",
       " 'cadrer theoriqu': 0,\n",
       " 'propre': 0,\n",
       " 'fouiller texter': 0,\n",
       " 'lextraction': 0,\n",
       " 'instant': 0,\n",
       " 'miser jour': 0,\n",
       " 'markov': 0,\n",
       " 'cuber': 0,\n",
       " 'descripteur': 0,\n",
       " 'partir sequence': 0,\n",
       " 'resumer': 0,\n",
       " 'menee': 0,\n",
       " 'predictif': 0,\n",
       " 'moment': 0,\n",
       " 'connaissancer': 0,\n",
       " 'leweb': 0,\n",
       " 'decrite': 0,\n",
       " 'ligne': 0,\n",
       " 'maximisation': 0,\n",
       " 'ensembl donneer': 0,\n",
       " 'construir': 0,\n",
       " 'grammaire': 0,\n",
       " 'formaliser': 0,\n",
       " 'favoriser': 0,\n",
       " 'utilisation': 0,\n",
       " 'fouill': 0,\n",
       " 'apprendre': 0,\n",
       " 'decennie': 0,\n",
       " 'champ': 0,\n",
       " 'enjeu': 0,\n",
       " 'perspective': 0,\n",
       " 'permettre caracteriser': 0,\n",
       " 'distinguer': 0,\n",
       " 'calculer': 0,\n",
       " 'phase': 0,\n",
       " 'dextrair': 0,\n",
       " 'benchmark': 0,\n",
       " 'lart': 0,\n",
       " 'inductif': 0,\n",
       " 'montrer faisabilite': 0,\n",
       " 'visualisation interactif': 0,\n",
       " 'associer': 0,\n",
       " 'duree': 0,\n",
       " 'maximum': 0,\n",
       " 'devenir': 0,\n",
       " 'modification': 0,\n",
       " 'amelioration': 0,\n",
       " 'terminologique': 0,\n",
       " 'etiquetage': 0,\n",
       " 'gener': 0,\n",
       " 'context': 0,\n",
       " 'proposition': 0,\n",
       " 'iteratif': 0,\n",
       " 'ferme': 0,\n",
       " 'heterogener': 0,\n",
       " 'presenter article': 0,\n",
       " 'localement': 0,\n",
       " 'traiter grand': 0,\n",
       " 'partir': 0,\n",
       " 'lextraction dinformation': 0,\n",
       " 'ligne colonne': 0,\n",
       " 'structure': 0,\n",
       " 'kmoyenne': 0,\n",
       " 'informatique': 0,\n",
       " 'exprimer': 0,\n",
       " 'caracterise': 0,\n",
       " 'pouvoir utilise': 0,\n",
       " 'ensembl mesure': 0,\n",
       " 'estimer': 0,\n",
       " 'definie': 0,\n",
       " 'dater mining': 0,\n",
       " 'reconstruction': 0,\n",
       " 'grand tailler': 0,\n",
       " 'defini': 0,\n",
       " 'encompte': 0,\n",
       " 'montrer linteret': 0,\n",
       " 'loi': 0,\n",
       " 'population': 0,\n",
       " 'colonne': 0,\n",
       " 'tabler': 0,\n",
       " 'couple': 0,\n",
       " 'exister': 0,\n",
       " 'retrouver': 0,\n",
       " 'dimag': 0,\n",
       " 'decouvrir motif': 0,\n",
       " 'luire': 0,\n",
       " 'eviter': 0,\n",
       " 'dexecution': 0,\n",
       " 'structuration': 0,\n",
       " 'lontologie': 0,\n",
       " 'prendre decision': 0,\n",
       " 'linguistique': 0,\n",
       " 'implement': 0,\n",
       " 'letude': 0,\n",
       " 'paire': 0,\n",
       " 'offrir': 0,\n",
       " 'recours': 0,\n",
       " 'sembler': 0,\n",
       " 'vie': 0,\n",
       " 'fichier': 0,\n",
       " 'analytique': 0,\n",
       " 'methode': 0,\n",
       " 'lumiere': 0,\n",
       " 'voisin': 0,\n",
       " 'distribution': 0,\n",
       " 'presenter': 0,\n",
       " 'ruer': 0,\n",
       " 'letape': 0,\n",
       " 'permettre danalyser': 0,\n",
       " 'baptis': 0,\n",
       " 'passage': 0,\n",
       " 'bayesien naïf': 0,\n",
       " 'multilingue': 0,\n",
       " 'desequilibre': 0,\n",
       " 'lexpert': 0,\n",
       " 'appliquer': 0,\n",
       " 'pourtant': 0,\n",
       " 'garantir': 0,\n",
       " 'idee': 0,\n",
       " 'lindustrie': 0,\n",
       " 'semiautomatique': 0,\n",
       " 'reell montrer': 0,\n",
       " 'cestadir': 0,\n",
       " 'necessitent': 0,\n",
       " 'presenter nouvel algorithme': 0,\n",
       " 'detection': 0,\n",
       " 'correspondance afc': 0,\n",
       " 'dintroduir': 0,\n",
       " 'larticle': 0,\n",
       " 'meilleur resultat': 0,\n",
       " 'identifier': 0,\n",
       " 'quil': 0,\n",
       " 'bloc': 0,\n",
       " 'souhaiter': 0,\n",
       " 'problem classification': 0,\n",
       " 'devaluer': 0,\n",
       " 'automate': 0,\n",
       " 'taille': 0,\n",
       " 'svm': 0,\n",
       " 'twitter': 0,\n",
       " 'simplifier': 0,\n",
       " 'faible': 0,\n",
       " 'patron': 0,\n",
       " 'dexpression': 0,\n",
       " 'partir ensembl': 0,\n",
       " 'dater stream': 0,\n",
       " 'dincertitude': 0,\n",
       " 'dependanc': 0,\n",
       " 'base': 0,\n",
       " 'dinteraction': 0,\n",
       " 'approprier': 0,\n",
       " 'deper': 0,\n",
       " 'bioinformatique': 0,\n",
       " 'maximal': 0,\n",
       " 'daid': 0,\n",
       " 'travail recent': 0,\n",
       " 'resultat obtenu': 0,\n",
       " 'nest': 0,\n",
       " 'letat lart': 0,\n",
       " 'arbre': 0,\n",
       " 'amelioree': 0,\n",
       " 'graphe': 0,\n",
       " 'extraire': 0,\n",
       " 'necessite': 0,\n",
       " 'alignement': 0,\n",
       " 'couvrir': 0,\n",
       " 'algorithme dextraction': 0,\n",
       " 'permettre lextraction': 0,\n",
       " 'sagit': 0,\n",
       " 'exhaustif': 0,\n",
       " 'etendu': 0,\n",
       " 'coeur': 0,\n",
       " 'cree': 0,\n",
       " 'protein': 0,\n",
       " 'perspectif': 0,\n",
       " 'kmean': 0,\n",
       " 'resultat issu': 0,\n",
       " 'specificite': 0,\n",
       " 'algorithme incremental': 0,\n",
       " 'guid': 0,\n",
       " 'chaine': 0,\n",
       " 'modele': 0,\n",
       " 'probabilite': 0,\n",
       " 'illustree': 0,\n",
       " 'nom': 0,\n",
       " 'remedier probleme': 0,\n",
       " 'nonsupervis': 0,\n",
       " 'automatiquement': 0,\n",
       " 'demonstration': 0,\n",
       " 'permettre dobtenir': 0,\n",
       " 'annees': 0,\n",
       " 'construction': 0,\n",
       " 'theorie fonction': 0,\n",
       " 'cadrer projet': 0,\n",
       " 'ameliore': 0,\n",
       " 'dextraction partir': 0,\n",
       " 'lun': 0,\n",
       " 'dimension': 0,\n",
       " 'possede': 0,\n",
       " 'derreur': 0,\n",
       " 'utiliser methode': 0,\n",
       " 'dexempl': 0,\n",
       " 'lineair': 0,\n",
       " 'methode fouiller donneer': 0,\n",
       " 'decoupage': 0,\n",
       " 'definis': 0,\n",
       " 'tir': 0,\n",
       " 'nouvel': 0,\n",
       " 'comparaison': 1,\n",
       " 'politique': 2,\n",
       " 'statistique implicatif': 0,\n",
       " 'developper': 0,\n",
       " 'difficile': 0,\n",
       " 'tâcher important': 0,\n",
       " 'concerner': 0,\n",
       " 'finalement': 0,\n",
       " 'oeuvrer': 0,\n",
       " 'nondisjoint': 0,\n",
       " 'classification document': 0,\n",
       " 'observee': 0,\n",
       " 'optimal': 0,\n",
       " 'contingence': 0,\n",
       " 'expliciter': 0,\n",
       " 'erreur': 0,\n",
       " 'evolutiv': 0,\n",
       " 'repondre': 0,\n",
       " 'stockeer': 0,\n",
       " 'guidee': 0,\n",
       " 'machiner': 0,\n",
       " 'resultant': 0,\n",
       " 'representent': 0,\n",
       " 'voir': 0,\n",
       " 'dapparition': 0,\n",
       " 'definit': 0,\n",
       " 'raisonnement': 0,\n",
       " 'former regl': 0,\n",
       " 'extraction': 0,\n",
       " 'meneer': 0,\n",
       " 'modelisation': 0,\n",
       " 'nettement': 0,\n",
       " 'dexperimentation': 0,\n",
       " 'dizaine': 0,\n",
       " 'pedagogiqu': 0,\n",
       " 'sequentiel': 0,\n",
       " 'classification multilabel': 0,\n",
       " 'pratiquer': 0,\n",
       " 'causer': 0,\n",
       " 'prevision': 0,\n",
       " 'creer': 0,\n",
       " 'linference': 0,\n",
       " 'sinscrit': 0,\n",
       " 'methode dextraction': 0,\n",
       " 'parallel': 0,\n",
       " 'structurer donneer': 0,\n",
       " 'quon': 0,\n",
       " 'presentee': 0,\n",
       " 'lintegration': 0,\n",
       " 'lier': 0,\n",
       " 'personnalisation': 0,\n",
       " 'liste': 0,\n",
       " 'loin': 0,\n",
       " 'interface': 0,\n",
       " 'raison': 1,\n",
       " 'dinteret': 0,\n",
       " 'preciser': 0,\n",
       " 'global': 0,\n",
       " 'dameliorer performance': 0,\n",
       " 'detectiond': 0,\n",
       " 'automatiser': 0,\n",
       " 'parcours': 0,\n",
       " 'descriptif': 0,\n",
       " 'site': 1,\n",
       " 'regle': 0,\n",
       " 'depender': 0,\n",
       " 'decomposition': 0,\n",
       " 'poser probleme': 0,\n",
       " 'article present': 0,\n",
       " 'dutilisateur': 0,\n",
       " 'maximiser': 0,\n",
       " 'mixte': 0,\n",
       " 'lexemple': 0,\n",
       " 'definisser': 0,\n",
       " 'combin': 0,\n",
       " 'point dinteret': 0,\n",
       " 'conflit': 0,\n",
       " 'resultat experimentaux': 0,\n",
       " 'text': 0,\n",
       " 'ditemset': 0,\n",
       " 'coûteux': 0,\n",
       " 'surla': 0,\n",
       " 'linteret': 0,\n",
       " 'skyline': 0,\n",
       " 'lapplication': 0,\n",
       " 'suite': 0,\n",
       " 'collectif': 0,\n",
       " 'lavantage': 0,\n",
       " 'theorie': 0,\n",
       " 'proposonsune': 0,\n",
       " 'rechercher dinformation': 0,\n",
       " 'lespace': 0,\n",
       " 'graphique': 0,\n",
       " 'factorisation': 0,\n",
       " 'annotation': 0,\n",
       " 'devenement': 1,\n",
       " 'reduction': 0,\n",
       " 'supervisee': 0,\n",
       " 'complexit': 0,\n",
       " 'complexe': 0,\n",
       " 'generalisation': 0,\n",
       " 'represent': 0,\n",
       " 'devaluation': 0,\n",
       " 'methodologiqu': 0,\n",
       " 'algebriqu': 0,\n",
       " 'spatiotemporell': 0,\n",
       " 'factoriel correspondance afc': 0,\n",
       " 'difficult': 0,\n",
       " 'participatif': 0,\n",
       " 'etat': 0,\n",
       " 'svm support': 0,\n",
       " 'generalise': 0,\n",
       " 'chain': 0,\n",
       " 'evidence': 0,\n",
       " 'accessible': 0,\n",
       " 'disponible': 0,\n",
       " 'intervall': 0,\n",
       " 'lexperience': 0,\n",
       " 'attaquer': 0,\n",
       " 'question important': 0,\n",
       " 'verification': 0,\n",
       " 'entreprise': 0,\n",
       " 'reseaux dynamique': 0,\n",
       " 'online': 0,\n",
       " 'significatif': 0,\n",
       " 'cooperativ': 0,\n",
       " 'lecture': 0,\n",
       " 'mesurer similarit': 0,\n",
       " 'synthetiqu reell': 0,\n",
       " 'reduite': 0,\n",
       " 'dinterrogation': 0,\n",
       " 'quantite': 0,\n",
       " 'repartition': 0,\n",
       " 'partition': 0,\n",
       " 'lutilisateur pouvoir': 0,\n",
       " 'defi': 0,\n",
       " 'article presenter': 0,\n",
       " 'comporter': 0,\n",
       " 'mem': 1,\n",
       " 'centree': 0,\n",
       " 'brut': 0,\n",
       " 'decrir': 0,\n",
       " 'prevention': 0,\n",
       " 'distance': 0,\n",
       " 'lheure actuel': 0,\n",
       " 'approche existant': 0,\n",
       " 'logique': 0,\n",
       " 'domaine': 0,\n",
       " 'dinternet': 0,\n",
       " 'programmation': 0,\n",
       " 'lacquisition': 0,\n",
       " 'systeme': 0,\n",
       " 'fortement': 0,\n",
       " 'papier present': 0,\n",
       " 'terme qualite': 0,\n",
       " 'didentification': 0,\n",
       " 'considere': 0,\n",
       " 'optimisation': 0,\n",
       " 'minimal': 0,\n",
       " 'generer': 0,\n",
       " 'diviser': 0,\n",
       " 'indice': 0,\n",
       " 'propager': 0,\n",
       " 'cesser': 0,\n",
       " 'grâce algorithme': 0,\n",
       " 'outil visualisation': 0,\n",
       " 'experience montrer': 0,\n",
       " 'technique permettre': 0,\n",
       " 'creation': 0,\n",
       " 'acquisition': 0,\n",
       " 'modele prediction': 0,\n",
       " 'uniforme': 0,\n",
       " 'papier presenter': 0,\n",
       " 'conduire': 0,\n",
       " 'deuxieme': 0,\n",
       " 'role': 0,\n",
       " 'serveur': 0,\n",
       " 'prototype': 0,\n",
       " 'syntaxique': 0,\n",
       " 'significativement': 0,\n",
       " 'contribution': 0,\n",
       " 'etude experimental': 0,\n",
       " 'discussion': 0,\n",
       " 'eclairage': 0,\n",
       " 'problematique': 0,\n",
       " 'lexical': 0,\n",
       " 'lamelioration': 0,\n",
       " 'caracteriseer': 0,\n",
       " 'impossible': 0,\n",
       " 'mouvement': 0,\n",
       " 'lien': 0,\n",
       " 'indicateur': 0,\n",
       " 'ladaptation': 0,\n",
       " 'booleenn': 0,\n",
       " 'prealabl': 0,\n",
       " 'gestion flux donneer': 0,\n",
       " 'manquant': 0,\n",
       " 'campagne': 0,\n",
       " 'parametr': 0,\n",
       " 'moindre': 0,\n",
       " 'decd': 0,\n",
       " 'construction darbr': 0,\n",
       " 'grand': 0,\n",
       " 'fonction': 0,\n",
       " 'fixer': 0,\n",
       " 'sequence': 0,\n",
       " 'permettre dutiliser': 0,\n",
       " 'treillis galoi': 0,\n",
       " 'methode existant': 0,\n",
       " 'batch': 0,\n",
       " 'present article': 0,\n",
       " 'formalisation': 0,\n",
       " 'coût': 0,\n",
       " 'arborescent': 0,\n",
       " 'pouvoir traiter': 0,\n",
       " 'decision': 0,\n",
       " 'quadratique': 0,\n",
       " 'manipuler': 0,\n",
       " 'faciliter': 0,\n",
       " 'lorganisation': 0,\n",
       " 'resultat experimentaux montrer': 0,\n",
       " 'lanalys formel concept': 0,\n",
       " 'integr': 0,\n",
       " 'surune': 0,\n",
       " 'importance': 0,\n",
       " 'article nouvel': 0,\n",
       " 'defi egc': 0,\n",
       " 'multiagent': 0,\n",
       " 'segment': 0,\n",
       " 'diagnostic': 0,\n",
       " 'xml': 0,\n",
       " 'fin': 0,\n",
       " 'centrer': 0,\n",
       " 'wikipedia': 0,\n",
       " 'caracter': 1,\n",
       " 'maintenir': 0,\n",
       " 'considerer': 0,\n",
       " 'presenter resultat': 0,\n",
       " 'echantillonnage': 0,\n",
       " 'specifiquement': 0,\n",
       " 'multicriter': 0,\n",
       " 'lorsquil': 0,\n",
       " 'dagregation': 0,\n",
       " 'desdonnee': 0,\n",
       " 'aider': 0,\n",
       " 'base relationnel': 0,\n",
       " 'imager': 0,\n",
       " 'numeriqu': 0,\n",
       " 'comparee': 0,\n",
       " 'terme': 0,\n",
       " 'dappariemer': 0,\n",
       " 'analyser factoriel': 0,\n",
       " 'source': 0,\n",
       " 'general': 0,\n",
       " 'situation': 0,\n",
       " 'mene': 0,\n",
       " 'reponse': 0,\n",
       " 'contenir': 0,\n",
       " 'sinteresse': 0,\n",
       " 'uniquement': 0,\n",
       " 'mis': 0,\n",
       " 'standard': 0,\n",
       " 'national': 0,\n",
       " 'frequent': 0,\n",
       " 'hybride': 0,\n",
       " 'cart': 0,\n",
       " 'topolog': 0,\n",
       " 'adapter': 0,\n",
       " 'structur': 0,\n",
       " 'avancee': 0,\n",
       " 'elevee': 0,\n",
       " 'efficace': 0,\n",
       " 'choisir': 0,\n",
       " 'dinform': 0,\n",
       " 'profit': 0,\n",
       " 'party': 0,\n",
       " 'ditems': 0,\n",
       " 'information': 0,\n",
       " 'filtrer': 0,\n",
       " 'generiqu': 0,\n",
       " 'continuer': 0,\n",
       " 'lindice': 0,\n",
       " 'index': 0,\n",
       " 'dequivalence': 0,\n",
       " 'modalite': 0,\n",
       " 'signature': 0,\n",
       " 'communautaire': 0,\n",
       " 'binaire': 0,\n",
       " 'variabilite': 0,\n",
       " 'hierarchi': 0,\n",
       " 'couleur': 0,\n",
       " 'construit': 0,\n",
       " 'paradigm': 0,\n",
       " 'permettre representer': 0,\n",
       " 'resume': 0,\n",
       " 'regroupement': 0,\n",
       " 'classificateur': 0,\n",
       " 'porter': 0,\n",
       " 'faire face': 0,\n",
       " 'principalement': 0,\n",
       " 'lextractionde': 0,\n",
       " 'connexion': 0,\n",
       " 'robustesse': 0,\n",
       " 'fouill donneer': 0,\n",
       " 'reseau': 0,\n",
       " 'problematiqu': 0,\n",
       " 'flot': 0,\n",
       " 'correspondance': 0,\n",
       " 'ontolog': 0,\n",
       " 'lapproche propose': 0,\n",
       " 'dinduction': 0,\n",
       " 'carte topologique': 0,\n",
       " 'occurrence': 0,\n",
       " 'topographique': 0,\n",
       " 'numeriquer': 0,\n",
       " 'lapprentissage automatique': 0,\n",
       " 'adapt': 0,\n",
       " 'validation': 0,\n",
       " 'mass': 0,\n",
       " 'particularite': 0,\n",
       " 'traditionnel': 0,\n",
       " 'valider': 0,\n",
       " 'kohonen': 0,\n",
       " 'papier': 0,\n",
       " 'lexploitation': 0,\n",
       " 'retenir': 0,\n",
       " 'perception': 0,\n",
       " 'decrit': 0,\n",
       " 'initial': 0,\n",
       " 'lextraction regl': 0,\n",
       " 'pixel': 0,\n",
       " 'dattributs': 0,\n",
       " 'localisation': 0,\n",
       " 'dautre': 0,\n",
       " 'issu': 0,\n",
       " 'reference': 0,\n",
       " 'emergent': 0,\n",
       " 'description': 0,\n",
       " 'priser': 0,\n",
       " 'graphe conceptuel': 0,\n",
       " 'prendre': 0,\n",
       " 'effort': 0,\n",
       " 'flot donneer': 0,\n",
       " 'ignorer': 0,\n",
       " 'inferieur': 0,\n",
       " 'selectionn': 0,\n",
       " 'model': 0,\n",
       " 'estimation densite': 0,\n",
       " 'communautair': 0,\n",
       " 'topologique': 0,\n",
       " 'taxonomie': 0,\n",
       " 'recevoir': 0,\n",
       " 'letiquetage': 0,\n",
       " 'problem': 0,\n",
       " 'lhypothese': 0,\n",
       " 'processus dapprentissage': 0,\n",
       " 'adapte': 0,\n",
       " 'jour': 0,\n",
       " 'mesurer qualite': 0,\n",
       " 'anne': 0,\n",
       " 'voire': 0,\n",
       " 'pendre': 0,\n",
       " 'viser': 0,\n",
       " 'article traire': 0,\n",
       " 'regle dassociation': 0,\n",
       " 'document textuel': 0,\n",
       " 'technologie': 0,\n",
       " 'developpemer': 0,\n",
       " 'decideur': 0,\n",
       " 'definition': 0,\n",
       " 'dynam': 0,\n",
       " 'resoudre probleme': 0,\n",
       " 'international': 0,\n",
       " 'generalement': 0,\n",
       " 'lemergence': 0,\n",
       " 'commencer': 0,\n",
       " 'machine': 0,\n",
       " 'limage': 0,\n",
       " 'reel': 1,\n",
       " 'outil': 0,\n",
       " 'mener': 0,\n",
       " 'evenement': 2,\n",
       " 'grand graphe': 0,\n",
       " 'classification hierarchiqu': 0,\n",
       " 'panel': 0,\n",
       " 'minoritaire': 0,\n",
       " 'expert': 0,\n",
       " 'lextraction regl dassociation': 0,\n",
       " 'matier': 0,\n",
       " 'decis': 0,\n",
       " 'actuel': 0,\n",
       " 'dexploration': 0,\n",
       " 'prendre compter': 0,\n",
       " 'performant': 0,\n",
       " 'montrer lapproche': 0,\n",
       " 'associee': 0,\n",
       " 'iteration': 0,\n",
       " 'lanalys formel': 0,\n",
       " 'laspect': 0,\n",
       " 'lanalyse': 1,\n",
       " 'français': 0,\n",
       " 'metrique': 0,\n",
       " 'virtuel': 0,\n",
       " 'perdre': 0,\n",
       " 'nexist': 0,\n",
       " 'decisionnell': 0,\n",
       " 'processus': 0,\n",
       " 'exposer': 0,\n",
       " 'aleatoir': 0,\n",
       " 'lenrichissement': 0,\n",
       " 'serie': 0,\n",
       " 'linteret methode': 0,\n",
       " 'tirer': 0,\n",
       " 'sparql': 0,\n",
       " 'format': 0,\n",
       " 'generees': 0,\n",
       " 'traiter': 0,\n",
       " 'formel': 0,\n",
       " 'strategie': 0,\n",
       " 'entrepot': 0,\n",
       " 'donner resultat': 0,\n",
       " 'pertinence': 0,\n",
       " 'combinaison': 0,\n",
       " 'detendre': 0,\n",
       " 'algorithmique': 0,\n",
       " 'former': 0,\n",
       " 'experimental': 0,\n",
       " 'arbitraire': 0,\n",
       " 'precision rappel': 0,\n",
       " 'munir': 0,\n",
       " 'mobilite': 0,\n",
       " 'vouloir': 0,\n",
       " 'ouvrir': 0,\n",
       " 'structurer document': 0,\n",
       " 'domaine fouiller': 0,\n",
       " 'sappuyer': 0,\n",
       " 'lusage': 1,\n",
       " 'decisionnel': 0,\n",
       " 'introduire': 0,\n",
       " 'perte dinformation': 0,\n",
       " 'relever': 0,\n",
       " 'distribuer': 0,\n",
       " 'local': 0,\n",
       " 'supplementair': 0,\n",
       " 'critere': 0,\n",
       " 'observer': 0,\n",
       " 'consist': 0,\n",
       " 'precision': 0,\n",
       " 'mieux': 0,\n",
       " 'cycle': 0,\n",
       " 'quantifier': 0,\n",
       " 'particulierement': 0,\n",
       " 'linterrogation': 0,\n",
       " 'regrouper': 0,\n",
       " 'groupe': 0,\n",
       " 'permettre construire': 0,\n",
       " 'inconvenient': 0,\n",
       " 'etudier': 0,\n",
       " 'grand echelle': 0,\n",
       " 'famille': 0,\n",
       " 'expression': 0,\n",
       " 'structurel': 0,\n",
       " 'cluster': 0,\n",
       " 'focaliser': 0,\n",
       " 'utilisateur': 0,\n",
       " 'discret': 0,\n",
       " 'vecteur support': 0,\n",
       " 'variant': 0,\n",
       " 'mediation': 0,\n",
       " 'interpreter': 0,\n",
       " 'internaute': 0,\n",
       " 'referent': 0,\n",
       " 'modele permettre': 0,\n",
       " 'stream': 0,\n",
       " 'autour': 0,\n",
       " 'laugmentation': 0,\n",
       " 'multilabel': 0,\n",
       " 'interessant': 0,\n",
       " 'nont': 0,\n",
       " 'lensembl dapprentissage': 0,\n",
       " 'chercheur': 0,\n",
       " 'collection': 0,\n",
       " 'instance': 0,\n",
       " 'regression': 0,\n",
       " 'biologique': 0,\n",
       " 'dansl': 0,\n",
       " 'validite': 0,\n",
       " 'choix': 0,\n",
       " 'analyser semantiqu': 0,\n",
       " 'definir': 0,\n",
       " 'article presenton': 0,\n",
       " 'loptimisation': 0,\n",
       " 'produire': 0,\n",
       " 'decouverte': 0,\n",
       " 'experiment': 0,\n",
       " 'lapproch': 0,\n",
       " 'lerreur': 0,\n",
       " 'equivalent': 0,\n",
       " 'ladequation': 0,\n",
       " 'generee': 0,\n",
       " 'candidat': 2,\n",
       " 'utiliser': 0,\n",
       " 'revenir': 0,\n",
       " 'libre': 0,\n",
       " 'grand nombre': 0,\n",
       " 'griller': 0,\n",
       " 'theoriqu': 0,\n",
       " 'experimentation': 0,\n",
       " 'facteur': 0,\n",
       " 'enrichissement': 0,\n",
       " 'semantique': 0,\n",
       " 'obtenu': 0,\n",
       " 'nouvel operateur': 0,\n",
       " 'composer': 0,\n",
       " 'methode original': 0,\n",
       " 'perte': 0,\n",
       " 'predire': 0,\n",
       " 'danalyser': 0,\n",
       " 'differenter': 0,\n",
       " 'darticl': 0,\n",
       " 'inspiree': 0,\n",
       " 'dapprendre': 0,\n",
       " 'probleme dapprentissage': 0,\n",
       " 'densembl': 0,\n",
       " 'memoir': 0,\n",
       " 'utiliser technique': 0,\n",
       " 'typer': 0,\n",
       " 'commun': 0,\n",
       " 'interrogation': 0,\n",
       " 'expert domaine': 0,\n",
       " 'etl': 0,\n",
       " 'sig': 0,\n",
       " 'patient': 0,\n",
       " 'production': 0,\n",
       " 'predictiv': 0,\n",
       " 'conjoint': 0,\n",
       " 'lintroduction': 0,\n",
       " 'realisation': 0,\n",
       " 'partir texte': 0,\n",
       " 'nouspresenton': 0,\n",
       " 'communication': 0,\n",
       " 'successif': 0,\n",
       " 'meilleur qualite': 0,\n",
       " 'informatif': 0,\n",
       " 'daccelerer': 0,\n",
       " 'servir': 0,\n",
       " 'lalgorithm': 0,\n",
       " 'automatique': 0,\n",
       " 'item': 1,\n",
       " 'signatur': 0,\n",
       " 'melange': 0,\n",
       " 'decriver': 0,\n",
       " 'implicatif': 0,\n",
       " 'exprimeer': 0,\n",
       " 'lieu': 0,\n",
       " 'pretraitemer': 0,\n",
       " 'lagregation': 0,\n",
       " 'satellit': 0,\n",
       " 'reell': 0,\n",
       " 'reduire': 0,\n",
       " 'lanalyse formel': 0,\n",
       " 'dacquisition': 0,\n",
       " 'experimentaux': 0,\n",
       " 'localiser': 0,\n",
       " 'proliferation': 0,\n",
       " 'permettre reduir': 0,\n",
       " 'construire': 0,\n",
       " 'reseau social': 0,\n",
       " 'phrase': 0,\n",
       " 'survenir': 0,\n",
       " 'dexperience': 0,\n",
       " 'exponentiel': 0,\n",
       " 'compacter': 0,\n",
       " 'carte autoorganisatrice': 0,\n",
       " 'ensemble donneer': 0,\n",
       " 'independamment': 0,\n",
       " 'transaction': 0,\n",
       " 'mond': 0,\n",
       " 'grâce': 0,\n",
       " 'souffrir': 0,\n",
       " 'flouer': 0,\n",
       " 'supposer': 0,\n",
       " 'vaste': 0,\n",
       " 'condensee': 0,\n",
       " 'particuliere': 0,\n",
       " 'complex': 0,\n",
       " 'system dinformation': 0,\n",
       " 'confirmer': 0,\n",
       " 'intelligible': 0,\n",
       " 'effectu': 0,\n",
       " 'associeer': 0,\n",
       " 'version': 0,\n",
       " 'construire partir': 0,\n",
       " 'vaste marge': 0,\n",
       " 'classifieur': 0,\n",
       " 'lexpression': 0,\n",
       " 'second': 0,\n",
       " 'coupl': 0,\n",
       " 'formation': 0,\n",
       " 'precedemment': 0,\n",
       " 'optimiser': 0,\n",
       " 'grand volume': 0,\n",
       " 'segmenter': 0,\n",
       " 'plateform': 2,\n",
       " 'axiome': 0,\n",
       " 'qualite regle': 0,\n",
       " 'langage': 0,\n",
       " 'fouiller grand': 0,\n",
       " 'fondee': 0,\n",
       " 'scientifique': 0,\n",
       " 'miser oeuvrer': 0,\n",
       " 'permettre partir': 0,\n",
       " 'initialement': 0,\n",
       " 'representation': 0,\n",
       " 'dimager': 0,\n",
       " 'intensif': 0,\n",
       " 'lidentification': 0,\n",
       " 'modele graphe': 0,\n",
       " 'article interesser': 0,\n",
       " 'danscet': 0,\n",
       " 'dextraction motif': 0,\n",
       " 'reecriture': 0,\n",
       " 'presenter papier': 0,\n",
       " 'daid decision': 0,\n",
       " 'partir baser': 0,\n",
       " 'dannotation': 0,\n",
       " 'adaptee': 0,\n",
       " 'adequat': 0,\n",
       " 'proximite': 0,\n",
       " 'rapidement': 0,\n",
       " 'fournir': 1,\n",
       " 'collection document': 0,\n",
       " 'ensembl': 0,\n",
       " 'densite': 0,\n",
       " 'durer processus': 0,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_word[num_partition][word]\n",
    "nb_word = []\n",
    "\n",
    "word_in_this_parti = {}\n",
    "for word in vectorizer.get_feature_names():\n",
    "    word_in_this_parti[word] = 0\n",
    "\n",
    "for numDoc in range(0, len(usable)):\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        word_in_this_parti[word] += tf[numDoc][word]\n",
    "    if numDoc+1 in limits:\n",
    "        nb_word.append(word_in_this_parti)\n",
    "        word_in_this_parti = {}\n",
    "        for word in vectorizer.get_feature_names():\n",
    "            word_in_this_parti[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nb_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_word_by_cluster[numPartition][numCluster]\n",
    "nb_word_by_cluster = []\n",
    "for parti in partitions:\n",
    "    nb_word_clus = []\n",
    "    for cluster in parti:\n",
    "        nb = 0\n",
    "        for numDoc in cluster:\n",
    "            for word in vectorizer.get_feature_names():\n",
    "                nb += tf[numDoc][word]\n",
    "        nb_word_clus.append(nb)\n",
    "    nb_word_by_cluster.append(nb_word_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_of_khi2 = khi2[numPartition][numCluster][word]\n",
    "khi2 = []\n",
    "\n",
    "for numParti in range(0, len(partitions)):\n",
    "    khi2parti = []\n",
    "    for numCluster in range(0, len(partitions[numParti])):\n",
    "        khi2cluster = {}\n",
    "        \n",
    "        for word in vectorizer.get_feature_names():\n",
    "            if nb_word_by_cluster[numParti][numCluster] == 0:\n",
    "                khi2cluster[word] = 0\n",
    "            else:\n",
    "                word_in_this_parti[word] = 0\n",
    "                E = nb_word[numParti][word]\n",
    "                E =+ nb_word_by_cluster[numParti][numCluster]\n",
    "                E = E/ nb_total_word[numParti]\n",
    "                N = 0\n",
    "                for numDoc in partitions[numParti][numCluster]:\n",
    "                    N += tf[numDoc][word]\n",
    "                khi2cluster[word] = (pow(N - E, 2)/E)        \n",
    "        khi2parti.append(khi2cluster)\n",
    "    khi2.append(khi2parti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of your labels = labels[numPartition][numCluster]\n",
    "labels = []\n",
    "\n",
    "for numPartition in range(0, len(nb_word_by_cluster)):\n",
    "    label_clus = []\n",
    "    for numCluster in range(0, len(nb_word_by_cluster[numPartition])):\n",
    "        label_clus.append(Counter(khi2[numPartition][numCluster]).most_common(5))\n",
    "    labels.append(label_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some clusters can be empty\n",
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diachronic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inter(listA, listB):\n",
    "    return np.intersect1d(listA, listB)\n",
    "    \n",
    "# cluster_t and cluster_s must be in two different partitions\n",
    "def proba(num_cluster_t, num_cluster_s, num_partition_T, num_partition_S):\n",
    "    total_inter = 0\n",
    "    total_t = 0\n",
    "    for f in range(0, len(labels[num_partition_T][num_cluster_t])):\n",
    "        for f_s in labels[num_partition_S][num_cluster_s]:\n",
    "            if labels[num_partition_T][num_cluster_t][f][0] == f_s[0]:\n",
    "                total_inter += labels[num_partition_T][num_cluster_t][f][1]\n",
    "                break\n",
    "        total_t += labels[num_partition_T][num_cluster_t][f][1]\n",
    "    if total_t == 0:\n",
    "        return 0\n",
    "    return total_inter / total_t\n",
    "    \n",
    "\n",
    "def P_A(num_cluster_s, num_partition_T, num_partition_S):\n",
    "    # first, we have to know what are the cluster which got the label\n",
    "    total = 0\n",
    "    nb_computation = 0\n",
    "    for label_s in labels[num_partition_S][num_cluster_s]:\n",
    "        for num_cluster_t in range(0, len(partitions[num_partition_T])):\n",
    "            if label_s in labels[num_partition_T][num_cluster_t]:\n",
    "                total += proba(num_cluster_t, num_cluster_s, num_partition_T, num_partition_S)\n",
    "                nb_computation += 1\n",
    "    if nb_computation == 0:\n",
    "        return 0\n",
    "    return total / nb_computation\n",
    "\n",
    "# Define a coeficient for the activity \n",
    "def activity(num_partition_S, num_partition_T):\n",
    "    res = 0\n",
    "    for num_cluster_s in range(0, len(partitions[num_partition_S])):\n",
    "        res += P_A(num_cluster_s, num_partition_T, num_partition_S)\n",
    "    return res / len(partitions[num_partition_S])\n",
    "\n",
    "# Ecart-type, but it isn't very usefull xD\n",
    "sigma_t = 0.01\n",
    "sigma_s = 0.01\n",
    "\n",
    "# Our Graal\n",
    "def similar(num_cluster_t, num_partition_T, num_cluster_s, num_partition_S):\n",
    "    cond1 = proba(num_cluster_t, num_cluster_s, num_partition_T, num_partition_S) > P_A(num_cluster_s, num_partition_T, num_partition_S)\n",
    "    cond2 = proba(num_cluster_t, num_cluster_s, num_partition_T, num_partition_S) > activity(num_partition_S, num_partition_T) + sigma_s\n",
    "    \n",
    "    cond3 = proba(num_cluster_t, num_cluster_s, num_partition_T, num_partition_S) > P_A(num_cluster_s, num_partition_T, num_partition_S)\n",
    "    cond4 = proba(num_cluster_t, num_cluster_s, num_partition_T, num_partition_S) > activity(num_partition_T, num_partition_S) + sigma_t\n",
    "    return cond1 and cond2 and cond3 and cond4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,0) est similaire à (11,1)\n",
      "(0,0) est similaire à (15,1)\n",
      "(1,0) est similaire à (5,1)\n",
      "(1,0) est similaire à (6,1)\n",
      "(1,0) est similaire à (9,1)\n",
      "(1,0) est similaire à (10,1)\n",
      "(1,0) est similaire à (19,1)\n",
      "(2,0) est similaire à (4,1)\n",
      "(2,0) est similaire à (9,1)\n",
      "(3,0) est similaire à (9,1)\n",
      "(3,0) est similaire à (10,1)\n",
      "(3,0) est similaire à (19,1)\n",
      "(4,0) est similaire à (1,1)\n",
      "(4,0) est similaire à (5,1)\n",
      "(4,0) est similaire à (6,1)\n",
      "(4,0) est similaire à (9,1)\n",
      "(4,0) est similaire à (11,1)\n",
      "(4,0) est similaire à (16,1)\n",
      "(5,0) est similaire à (2,1)\n",
      "(5,0) est similaire à (7,1)\n",
      "(5,0) est similaire à (12,1)\n",
      "(5,0) est similaire à (15,1)\n",
      "(5,0) est similaire à (18,1)\n",
      "(6,0) est similaire à (1,1)\n",
      "(6,0) est similaire à (2,1)\n",
      "(6,0) est similaire à (5,1)\n",
      "(6,0) est similaire à (6,1)\n",
      "(6,0) est similaire à (9,1)\n",
      "(6,0) est similaire à (10,1)\n",
      "(6,0) est similaire à (11,1)\n",
      "(6,0) est similaire à (16,1)\n",
      "(6,0) est similaire à (19,1)\n",
      "(7,0) est similaire à (5,1)\n",
      "(7,0) est similaire à (8,1)\n",
      "(7,0) est similaire à (17,1)\n",
      "(8,0) est similaire à (17,1)\n",
      "(9,0) est similaire à (7,1)\n",
      "(10,0) est similaire à (2,1)\n",
      "(10,0) est similaire à (4,1)\n",
      "(11,0) est similaire à (2,1)\n",
      "(11,0) est similaire à (5,1)\n",
      "(12,0) est similaire à (18,1)\n",
      "(13,0) est similaire à (17,1)\n",
      "(14,0) est similaire à (1,1)\n",
      "(14,0) est similaire à (5,1)\n",
      "(14,0) est similaire à (6,1)\n",
      "(14,0) est similaire à (11,1)\n",
      "(14,0) est similaire à (16,1)\n",
      "(15,0) est similaire à (3,1)\n",
      "(15,0) est similaire à (6,1)\n",
      "(15,0) est similaire à (7,1)\n",
      "(15,0) est similaire à (13,1)\n",
      "(16,0) est similaire à (1,1)\n",
      "(16,0) est similaire à (4,1)\n",
      "(16,0) est similaire à (5,1)\n",
      "(16,0) est similaire à (6,1)\n",
      "(16,0) est similaire à (8,1)\n",
      "(16,0) est similaire à (10,1)\n",
      "(16,0) est similaire à (11,1)\n",
      "(16,0) est similaire à (16,1)\n",
      "(17,0) est similaire à (2,1)\n",
      "(17,0) est similaire à (11,1)\n",
      "(17,0) est similaire à (17,1)\n",
      "(17,0) est similaire à (19,1)\n",
      "(18,0) est similaire à (3,1)\n",
      "(18,0) est similaire à (7,1)\n",
      "(18,0) est similaire à (10,1)\n",
      "(18,0) est similaire à (12,1)\n",
      "(19,0) est similaire à (6,1)\n",
      "(19,0) est similaire à (9,1)\n",
      "(19,0) est similaire à (10,1)\n",
      "(19,0) est similaire à (13,1)\n",
      "(19,0) est similaire à (19,1)\n",
      "(0,1) est similaire à (6,2)\n",
      "(1,1) est similaire à (2,2)\n",
      "(1,1) est similaire à (3,2)\n",
      "(1,1) est similaire à (6,2)\n",
      "(1,1) est similaire à (10,2)\n",
      "(1,1) est similaire à (13,2)\n",
      "(1,1) est similaire à (14,2)\n",
      "(1,1) est similaire à (17,2)\n",
      "(1,1) est similaire à (19,2)\n",
      "(2,1) est similaire à (0,2)\n",
      "(2,1) est similaire à (7,2)\n",
      "(2,1) est similaire à (8,2)\n",
      "(2,1) est similaire à (9,2)\n",
      "(2,1) est similaire à (16,2)\n",
      "(2,1) est similaire à (17,2)\n",
      "(3,1) est similaire à (1,2)\n",
      "(3,1) est similaire à (7,2)\n",
      "(4,1) est similaire à (11,2)\n",
      "(4,1) est similaire à (15,2)\n",
      "(4,1) est similaire à (18,2)\n",
      "(5,1) est similaire à (0,2)\n",
      "(5,1) est similaire à (2,2)\n",
      "(5,1) est similaire à (7,2)\n",
      "(5,1) est similaire à (10,2)\n",
      "(5,1) est similaire à (14,2)\n",
      "(5,1) est similaire à (16,2)\n",
      "(5,1) est similaire à (17,2)\n",
      "(5,1) est similaire à (19,2)\n",
      "(6,1) est similaire à (2,2)\n",
      "(6,1) est similaire à (10,2)\n",
      "(6,1) est similaire à (11,2)\n",
      "(6,1) est similaire à (14,2)\n",
      "(6,1) est similaire à (19,2)\n",
      "(7,1) est similaire à (0,2)\n",
      "(7,1) est similaire à (1,2)\n",
      "(7,1) est similaire à (2,2)\n",
      "(7,1) est similaire à (7,2)\n",
      "(7,1) est similaire à (8,2)\n",
      "(7,1) est similaire à (9,2)\n",
      "(7,1) est similaire à (10,2)\n",
      "(8,1) est similaire à (0,2)\n",
      "(8,1) est similaire à (1,2)\n",
      "(8,1) est similaire à (2,2)\n",
      "(8,1) est similaire à (6,2)\n",
      "(8,1) est similaire à (14,2)\n",
      "(9,1) est similaire à (11,2)\n",
      "(9,1) est similaire à (15,2)\n",
      "(9,1) est similaire à (18,2)\n",
      "(10,1) est similaire à (0,2)\n",
      "(10,1) est similaire à (8,2)\n",
      "(10,1) est similaire à (13,2)\n",
      "(10,1) est similaire à (14,2)\n",
      "(11,1) est similaire à (2,2)\n",
      "(11,1) est similaire à (9,2)\n",
      "(11,1) est similaire à (10,2)\n",
      "(11,1) est similaire à (14,2)\n",
      "(11,1) est similaire à (19,2)\n",
      "(12,1) est similaire à (0,2)\n",
      "(12,1) est similaire à (8,2)\n",
      "(13,1) est similaire à (3,2)\n",
      "(13,1) est similaire à (6,2)\n",
      "(13,1) est similaire à (10,2)\n",
      "(13,1) est similaire à (11,2)\n",
      "(13,1) est similaire à (13,2)\n",
      "(13,1) est similaire à (17,2)\n",
      "(13,1) est similaire à (19,2)\n",
      "(14,1) est similaire à (17,2)\n",
      "(15,1) est similaire à (0,2)\n",
      "(15,1) est similaire à (8,2)\n",
      "(15,1) est similaire à (9,2)\n",
      "(15,1) est similaire à (16,2)\n",
      "(16,1) est similaire à (2,2)\n",
      "(16,1) est similaire à (6,2)\n",
      "(16,1) est similaire à (10,2)\n",
      "(16,1) est similaire à (14,2)\n",
      "(16,1) est similaire à (19,2)\n",
      "(17,1) est similaire à (2,2)\n",
      "(17,1) est similaire à (4,2)\n",
      "(17,1) est similaire à (12,2)\n",
      "(18,1) est similaire à (3,2)\n",
      "(18,1) est similaire à (6,2)\n",
      "(18,1) est similaire à (10,2)\n",
      "(18,1) est similaire à (13,2)\n",
      "(18,1) est similaire à (16,2)\n",
      "(18,1) est similaire à (17,2)\n",
      "(18,1) est similaire à (19,2)\n",
      "(0,2) est similaire à (3,3)\n",
      "(0,2) est similaire à (17,3)\n",
      "(0,2) est similaire à (19,3)\n",
      "(2,2) est similaire à (0,3)\n",
      "(2,2) est similaire à (6,3)\n",
      "(2,2) est similaire à (15,3)\n",
      "(2,2) est similaire à (16,3)\n",
      "(2,2) est similaire à (17,3)\n",
      "(3,2) est similaire à (0,3)\n",
      "(3,2) est similaire à (5,3)\n",
      "(3,2) est similaire à (10,3)\n",
      "(3,2) est similaire à (18,3)\n",
      "(4,2) est similaire à (1,3)\n",
      "(4,2) est similaire à (11,3)\n",
      "(4,2) est similaire à (15,3)\n",
      "(5,2) est similaire à (2,3)\n",
      "(6,2) est similaire à (0,3)\n",
      "(6,2) est similaire à (5,3)\n",
      "(6,2) est similaire à (10,3)\n",
      "(7,2) est similaire à (3,3)\n",
      "(7,2) est similaire à (7,3)\n",
      "(7,2) est similaire à (17,3)\n",
      "(8,2) est similaire à (3,3)\n",
      "(8,2) est similaire à (17,3)\n",
      "(9,2) est similaire à (17,3)\n",
      "(10,2) est similaire à (0,3)\n",
      "(10,2) est similaire à (2,3)\n",
      "(10,2) est similaire à (3,3)\n",
      "(10,2) est similaire à (5,3)\n",
      "(10,2) est similaire à (6,3)\n",
      "(10,2) est similaire à (10,3)\n",
      "(10,2) est similaire à (16,3)\n",
      "(10,2) est similaire à (17,3)\n",
      "(11,2) est similaire à (2,3)\n",
      "(11,2) est similaire à (13,3)\n",
      "(11,2) est similaire à (14,3)\n",
      "(12,2) est similaire à (2,3)\n",
      "(12,2) est similaire à (15,3)\n",
      "(13,2) est similaire à (0,3)\n",
      "(13,2) est similaire à (2,3)\n",
      "(13,2) est similaire à (5,3)\n",
      "(13,2) est similaire à (10,3)\n",
      "(13,2) est similaire à (13,3)\n",
      "(13,2) est similaire à (14,3)\n",
      "(14,2) est similaire à (0,3)\n",
      "(14,2) est similaire à (2,3)\n",
      "(14,2) est similaire à (6,3)\n",
      "(14,2) est similaire à (13,3)\n",
      "(14,2) est similaire à (14,3)\n",
      "(14,2) est similaire à (16,3)\n",
      "(14,2) est similaire à (17,3)\n",
      "(15,2) est similaire à (2,3)\n",
      "(15,2) est similaire à (8,3)\n",
      "(15,2) est similaire à (13,3)\n",
      "(16,2) est similaire à (4,3)\n",
      "(16,2) est similaire à (7,3)\n",
      "(16,2) est similaire à (8,3)\n",
      "(16,2) est similaire à (17,3)\n",
      "(17,2) est similaire à (0,3)\n",
      "(17,2) est similaire à (5,3)\n",
      "(17,2) est similaire à (7,3)\n",
      "(17,2) est similaire à (10,3)\n",
      "(17,2) est similaire à (17,3)\n",
      "(18,2) est similaire à (2,3)\n",
      "(18,2) est similaire à (13,3)\n",
      "(18,2) est similaire à (19,3)\n",
      "(19,2) est similaire à (0,3)\n",
      "(19,2) est similaire à (5,3)\n",
      "(19,2) est similaire à (6,3)\n",
      "(19,2) est similaire à (10,3)\n",
      "(19,2) est similaire à (16,3)\n",
      "(19,2) est similaire à (17,3)\n",
      "(0,3) est similaire à (0,4)\n",
      "(0,3) est similaire à (1,4)\n",
      "(0,3) est similaire à (3,4)\n",
      "(0,3) est similaire à (4,4)\n",
      "(0,3) est similaire à (6,4)\n",
      "(0,3) est similaire à (7,4)\n",
      "(0,3) est similaire à (8,4)\n",
      "(0,3) est similaire à (9,4)\n",
      "(0,3) est similaire à (10,4)\n",
      "(0,3) est similaire à (11,4)\n",
      "(0,3) est similaire à (13,4)\n",
      "(0,3) est similaire à (14,4)\n",
      "(0,3) est similaire à (17,4)\n",
      "(0,3) est similaire à (18,4)\n",
      "(1,3) est similaire à (0,4)\n",
      "(1,3) est similaire à (4,4)\n",
      "(1,3) est similaire à (11,4)\n",
      "(1,3) est similaire à (13,4)\n",
      "(1,3) est similaire à (19,4)\n",
      "(2,3) est similaire à (1,4)\n",
      "(2,3) est similaire à (2,4)\n",
      "(2,3) est similaire à (9,4)\n",
      "(2,3) est similaire à (10,4)\n",
      "(2,3) est similaire à (14,4)\n",
      "(3,3) est similaire à (14,4)\n",
      "(3,3) est similaire à (15,4)\n",
      "(4,3) est similaire à (12,4)\n",
      "(5,3) est similaire à (1,4)\n",
      "(5,3) est similaire à (6,4)\n",
      "(5,3) est similaire à (7,4)\n",
      "(5,3) est similaire à (8,4)\n",
      "(5,3) est similaire à (9,4)\n",
      "(5,3) est similaire à (10,4)\n",
      "(5,3) est similaire à (11,4)\n",
      "(6,3) est similaire à (0,4)\n",
      "(6,3) est similaire à (1,4)\n",
      "(6,3) est similaire à (4,4)\n",
      "(6,3) est similaire à (8,4)\n",
      "(6,3) est similaire à (9,4)\n",
      "(6,3) est similaire à (13,4)\n",
      "(6,3) est similaire à (14,4)\n",
      "(6,3) est similaire à (17,4)\n",
      "(6,3) est similaire à (18,4)\n",
      "(7,3) est similaire à (5,4)\n",
      "(7,3) est similaire à (14,4)\n",
      "(7,3) est similaire à (15,4)\n",
      "(8,3) est similaire à (7,4)\n",
      "(8,3) est similaire à (16,4)\n",
      "(10,3) est similaire à (1,4)\n",
      "(10,3) est similaire à (6,4)\n",
      "(10,3) est similaire à (7,4)\n",
      "(10,3) est similaire à (8,4)\n",
      "(10,3) est similaire à (9,4)\n",
      "(10,3) est similaire à (10,4)\n",
      "(10,3) est similaire à (11,4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,3) est similaire à (7,4)\n",
      "(13,3) est similaire à (1,4)\n",
      "(13,3) est similaire à (2,4)\n",
      "(14,3) est similaire à (1,4)\n",
      "(14,3) est similaire à (2,4)\n",
      "(14,3) est similaire à (16,4)\n",
      "(15,3) est similaire à (3,4)\n",
      "(15,3) est similaire à (4,4)\n",
      "(15,3) est similaire à (5,4)\n",
      "(15,3) est similaire à (10,4)\n",
      "(16,3) est similaire à (0,4)\n",
      "(16,3) est similaire à (1,4)\n",
      "(16,3) est similaire à (4,4)\n",
      "(16,3) est similaire à (8,4)\n",
      "(16,3) est similaire à (9,4)\n",
      "(16,3) est similaire à (13,4)\n",
      "(16,3) est similaire à (14,4)\n",
      "(16,3) est similaire à (16,4)\n",
      "(16,3) est similaire à (17,4)\n",
      "(16,3) est similaire à (18,4)\n",
      "(17,3) est similaire à (0,4)\n",
      "(17,3) est similaire à (1,4)\n",
      "(17,3) est similaire à (4,4)\n",
      "(17,3) est similaire à (5,4)\n",
      "(17,3) est similaire à (8,4)\n",
      "(17,3) est similaire à (9,4)\n",
      "(17,3) est similaire à (13,4)\n",
      "(17,3) est similaire à (14,4)\n",
      "(17,3) est similaire à (15,4)\n",
      "(17,3) est similaire à (17,4)\n",
      "(17,3) est similaire à (18,4)\n",
      "(18,3) est similaire à (0,4)\n",
      "(18,3) est similaire à (4,4)\n",
      "(18,3) est similaire à (11,4)\n",
      "(18,3) est similaire à (13,4)\n",
      "(18,3) est similaire à (19,4)\n",
      "(19,3) est similaire à (0,4)\n",
      "(19,3) est similaire à (4,4)\n",
      "(19,3) est similaire à (11,4)\n",
      "(19,3) est similaire à (13,4)\n",
      "(19,3) est similaire à (17,4)\n",
      "(19,3) est similaire à (19,4)\n"
     ]
    }
   ],
   "source": [
    "for numParti in range(0, len(partitions)-1):\n",
    "    for num_cluster_t in range(0, nb_cluster):\n",
    "        for num_cluster_s in range(0, nb_cluster):\n",
    "            if similar(num_cluster_t, numParti, num_cluster_s, numParti+1):\n",
    "                print(\"(\"+str(num_cluster_t)+\",\"+str(numParti)+\") est similaire à (\"+str(num_cluster_s)+\",\"+str(numParti+1)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('recommandation', 12379.303266725825), ('utilisateur', 1043.2261916270124), ('model', 764.7499070420321), ('article', 764.7499070420321), ('interet', 764.7499070420321)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12379.303266725825"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels[0][1])\n",
    "labels[0][1][0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
