{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "from gensim import corpora, models, utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
    "from gensim.models import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy lib\n",
    "# On https://spacy.io/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas preprocessing methods.\n",
    "# Lemmatisation without poncutations\n",
    "\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()\n",
    "fstw = stopwords.words('french')\n",
    "\n",
    "# French Stop Words, extraits depuis le fichier stopwords-fr.txt + stopwords french de nltk\n",
    "sourceFST = [x.replace('\\n', '') for x in open('stopwords-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]+fstw\n",
    "\n",
    "def lemmatize(article):\n",
    "    output = []\n",
    "    outPonc = article.translate(article.maketrans(\"\",\"\", string.punctuation))\n",
    "    outLem = nlp(outPonc)\n",
    "    for token in outLem:\n",
    "        if token.lemma_ not in sourceFST:\n",
    "            output.append(token.lemma_)\n",
    "    res = ' '.join(output)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    "data = pd.read_csv('export_articles_EGC_2004_2018.csv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process our corpus, and determine a limit to split it in partitions\n",
    "\n",
    "# usable[] correspond to our corpus processed\n",
    "# limits[] let us know when to delimit partitions\n",
    "limits = []\n",
    "usable = []\n",
    "\n",
    "# To create ours delimiters, we must first know the years which will be the limits\n",
    "limit_years = [2007, 2010, 2014]\n",
    "\n",
    "prev_year = data['year'][0]\n",
    "numArti = 0\n",
    "for i in range(0, len(data['abstract']), 1):\n",
    "    if not isinstance(data['abstract'][i], float): #if not null, empty, or whatever (so if there is a abstract)\n",
    "        year = data['year'][i]\n",
    "        if year != prev_year:\n",
    "            prev_year = year\n",
    "            if year in limit_years:\n",
    "                limits.append(numArti)\n",
    "        numArti+=1\n",
    "        usable.append(stemmer.stem(lemmatize(data['abstract'][i])))\n",
    "limits.append(numArti)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'articles = 1096\n",
      "limits = [267, 543, 790, 1096]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'plateforme objectif permettre citoyen danalyserpar euxmême tweet politique dévénement spécifique francepour cas lélection présidentiel 2017 idéo2017 analyser quasitemp réel message candidat fournir principal caractéristiqueslusage lexiqu politique comparaison entrer candidat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display pre-processed datas\n",
    "print(\"nombre d'articles =\", len(usable))\n",
    "print(\"limits =\", limits)\n",
    "\n",
    "usable[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "nb_concepts = 30\n",
    "min_gram = 1\n",
    "max_gram = 3\n",
    "\n",
    "# Creation of cleandocs, which is usable[] with ngrams\n",
    "cleandocs = []\n",
    "for t in usable:\n",
    "    doc = []\n",
    "    for n in range(min_gram, max_gram+1):\n",
    "        for gram in ngrams(t.split(), n):\n",
    "            doc.append(\" \".join(gram))\n",
    "    cleandocs.append(doc)\n",
    "\n",
    "# Creation of tfidf model, a tool to create ours tfidf\n",
    "corpus = []\n",
    "dictionary = corpora.Dictionary(cleandocs)\n",
    "for doc in cleandocs:\n",
    "    newVec = dictionary.doc2bow(doc)\n",
    "    corpus.append(newVec)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "# Creation of partitions_lsa[], which give us the LSA of each partition\n",
    "partitions_lsa = []\n",
    "beg = 0\n",
    "for l in limits:\n",
    "    last = l\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    lsi = models.LsiModel(corpus_tfidf, num_topics=nb_concepts, id2word=dictionary)\n",
    "    corpus_lsi = lsi[corpus_tfidf[beg:last]]\n",
    "    partitions_lsa.append(corpus_lsi)\n",
    "    beg = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition numéro: 0\n",
      "document number  0\n",
      "[(0, 0.005489804287081122), (1, -0.02791722928535486), (2, 0.02128972433959377), (3, 0.021841665064694406), (4, 0.00866254034448971), (5, -0.015127524434327607), (6, -0.009415870565543535), (7, -0.0031278095778846573), (8, -0.0053132244009419256), (9, 0.012568609869497625), (10, 0.021823790495537867), (11, 0.03172812311482545), (12, 0.008646554273059718), (13, 0.0060853445937769), (14, 0.02066749567828601), (15, -0.0062804065234330405), (16, -0.03698914111220524), (17, -0.0008958618367283544), (18, -0.045212595741772894), (19, -0.02626303794496773), (20, 0.028286125043894047), (21, 0.004543855206786278), (22, -0.007202135463788318), (23, 0.02690517534503017), (24, 0.001453461443122326), (25, 0.01672230382157509), (26, -0.02686823685900035), (27, -0.012687905648606007), (28, -0.00830627582391572), (29, -0.004038838092350947)]\n",
      "document number  1\n",
      "[(0, 0.0114591714404101), (1, -0.09594275228517507), (2, 0.001832348586869282), (3, -0.07118575251456316), (4, 0.02032127196847914), (5, 0.006085136890410933), (6, 0.14878147535809533), (7, -0.020680170370242765), (8, -7.940116873631663e-05), (9, -0.026276269088094734), (10, -0.021743830920543935), (11, -0.0071444378315403834), (12, 0.07696398077085083), (13, 0.034524312866235383), (14, 0.02934809767508017), (15, 0.027146881420825702), (16, 0.026744212544550686), (17, -0.04665180777207247), (18, 0.04856552573606678), (19, 0.07832425947601149), (20, 0.03709423606147599), (21, -0.008290949055877381), (22, 0.006061225832510026), (23, -0.04061630222100079), (24, -0.03589333728574674), (25, -0.024821620946156794), (26, -0.005193673071191367), (27, -0.030734367191491523), (28, 0.004831531902104751), (29, -0.05913111585620194)]\n",
      "document number  2\n",
      "[(0, 0.008920074119913605), (1, -0.06700380550269897), (2, 0.003400272404485424), (3, 0.03517684316237265), (4, 0.018177807156434637), (5, -0.09262953595372715), (6, 0.07379502881091386), (7, 0.041796944818804374), (8, 0.01000835642769862), (9, 0.09241073360970577), (10, -0.04055110987466603), (11, 0.0020629608021212388), (12, 0.002547654837492416), (13, 0.05950153480025192), (14, 0.028686600812353247), (15, -0.03663259914035238), (16, -0.035615035978784404), (17, 0.0010608579730440675), (18, 0.04662624534503568), (19, -0.01763610307000516), (20, 0.002503565993901994), (21, -0.027783197333874014), (22, 0.05352947843296999), (23, 0.031027715663172018), (24, -0.006458205930271482), (25, -0.05533519401935011), (26, 0.017961295089133144), (27, -0.014161143578376226), (28, 0.004671647663601651), (29, 0.0031659233334378504)]\n",
      "Partition numéro: 1\n",
      "document number  0\n",
      "[(0, 0.006074355916652245), (1, -0.03938217029144158), (2, 0.009978136194898676), (3, 0.011407562851530684), (4, 0.018913557276929494), (5, -0.004034700439952467), (6, 0.005276190895853255), (7, 0.012541952972884818), (8, 0.0058290255206575586), (9, -0.06247393362113066), (10, -0.0006910748077118415), (11, 0.023715915433597818), (12, -0.01604560113369425), (13, 0.023387240649328754), (14, 0.06847768647010598), (15, 0.04029169935025095), (16, -0.018771406694999177), (17, -0.02334323983828696), (18, -0.009051035458252765), (19, 0.0792705235029363), (20, -0.0014563065827835205), (21, -0.003049534997416767), (22, -0.016140935098049425), (23, 0.019378570114313407), (24, 0.04289528113240785), (25, -0.012921114725269639), (26, -0.07297880348586419), (27, 0.05782082084262181), (28, -0.00661564762268061), (29, 0.01523946254900535)]\n",
      "document number  1\n",
      "[(0, 0.007149775344661968), (1, -0.06209332354929704), (2, 0.013800766726897647), (3, -0.015868049321216264), (4, -0.012993235780828642), (5, -0.051833977738336035), (6, -0.030297140903756285), (7, -0.032423033197072036), (8, -0.016045397481352808), (9, 0.08073241879447264), (10, 0.014894471826726723), (11, -0.03591261647014374), (12, 0.018538760338593106), (13, 0.04257452976457773), (14, 0.023361367496717116), (15, -0.02382121273284871), (16, -0.011957958136219747), (17, -0.03866132905201936), (18, -0.0503501543788577), (19, 0.027988296107415055), (20, 0.0013065205658090078), (21, 0.04577915909038548), (22, -0.05386929624677439), (23, 0.028307352486124093), (24, -0.002322262333504582), (25, 0.05921322860701739), (26, 0.02604148993711188), (27, 0.012787178089477498), (28, 0.007148639676685035), (29, 0.04075066122042398)]\n",
      "document number  2\n",
      "[(0, 0.004903199120240925), (1, -0.04655434337065296), (2, 0.017654954524297287), (3, -0.023519824093477568), (4, 0.015242363298032573), (5, -0.008958972017485828), (6, 0.00675510828321123), (7, -0.00786811534516421), (8, 0.004713118742706483), (9, -0.015135823423623017), (10, 0.05506764402288021), (11, 0.015129798873129352), (12, 0.018062366649570734), (13, -0.051554581811331705), (14, -0.018378788066736977), (15, -0.036021853433204576), (16, -0.011611452356112608), (17, -0.03549038033671536), (18, 0.01842715473732944), (19, 0.0020409135063541753), (20, -0.025350587413796106), (21, 0.013778646489051017), (22, 0.026933287857997652), (23, 0.011879357276419613), (24, -0.04749341301267661), (25, -0.015530734264971806), (26, -0.0189231968427292), (27, 0.029613665753466523), (28, -0.03992622836725643), (29, 0.020077133109015148)]\n",
      "Partition numéro: 2\n",
      "document number  0\n",
      "[(0, -0.007112833299976488), (1, 0.027862939534682402), (2, -0.0359360425138451), (3, 0.0047619163056925986), (4, -0.01950283467774205), (5, 0.0022713964782745282), (6, 0.015831159015261706), (7, -0.007799344488527931), (8, -0.012819121101586558), (9, 0.019345107615573925), (10, 0.04536786709018456), (11, 0.02825869489136282), (12, -0.01320917589015851), (13, 0.016621336747979498), (14, 0.06722685982358884), (15, -0.057815107709912286), (16, 0.004793455678477857), (17, 0.02503934075054881), (18, -0.018506676842563193), (19, -0.007614740179001745), (20, -0.01582615848400135), (21, 0.023448045449188482), (22, -0.014627253210538071), (23, 0.025750289384440544), (24, 0.00941549457118644), (25, -0.06085072572466527), (26, 0.02032839235767844), (27, 0.004584170006374261), (28, 0.019833755679216362), (29, 0.0006964443590082112)]\n",
      "document number  1\n",
      "[(0, -0.010398464251979218), (1, 0.056801407251559646), (2, -0.008768191158293677), (3, 0.013802887961708966), (4, -0.02010016217301281), (5, -0.0009443972153264481), (6, 0.0051963910967519795), (7, 0.016149134645349214), (8, 0.000918532236026531), (9, 0.012488951561219305), (10, 0.027241928201445404), (11, -0.00025080655303196913), (12, 0.03783076237715459), (13, 0.0016160825549957753), (14, 0.013846212015873603), (15, 0.01275204893828336), (16, -0.012478033895792467), (17, -0.03229607195451482), (18, -0.011555967464845832), (19, 0.013272200021837032), (20, -0.004062716257345591), (21, 0.023882007281064734), (22, -0.04108934974190261), (23, 0.0057379953900832635), (24, 0.04838455695324251), (25, -0.03065372982217791), (26, 0.026443566558756723), (27, 0.012000909705530277), (28, 0.02416074114167988), (29, 0.037970354078231544)]\n",
      "document number  2\n",
      "[(0, -0.005962068785584227), (1, 0.03576324175095623), (2, 0.0040337464218651), (3, -0.03222531866733393), (4, -0.02194518250443307), (5, -0.022281761209702083), (6, 0.03345524829342655), (7, -0.03487013810676394), (8, 0.019180505249441822), (9, 0.011290580424396684), (10, 0.008737159436550382), (11, -0.015343958456126298), (12, -0.01043274517637667), (13, 0.03027493607298176), (14, -0.011577839317663877), (15, 0.005594683410958572), (16, -0.010177110391171895), (17, -0.003485051497498485), (18, 0.03371938391994175), (19, -0.014695484140906743), (20, 0.0064644739620871566), (21, 0.023073887982310443), (22, -0.0647584066490243), (23, -0.011241144381363677), (24, -0.0006994092688122532), (25, -0.011761144913438732), (26, -0.06811187853004745), (27, 0.037786796242428096), (28, 0.019504879986309943), (29, 0.02230071914362142)]\n",
      "Partition numéro: 3\n",
      "document number  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.00821155489185676), (1, 0.0931840468424834), (2, 0.021496445063474003), (3, 0.0070277465744208656), (4, -0.08830669975940213), (5, -0.05639368396998693), (6, 0.006352822742294887), (7, -0.027995691999516105), (8, 0.0167255694609459), (9, -0.019275608941014308), (10, -0.004150847459637002), (11, -0.003424102652262867), (12, -0.003002531757179119), (13, -0.017849262512527893), (14, 0.021865306569477917), (15, -0.04812813992077054), (16, 0.025100052428343875), (17, 0.015335984955540546), (18, -0.0015579561259903667), (19, 0.021156813874777903), (20, 0.016609335199838048), (21, -0.03373740437020239), (22, -0.02801475048262389), (23, -0.04812077108695218), (24, 0.02269044989211623), (25, 0.02293032246293893), (26, -0.07260096955309343), (27, -0.027525695563188863), (28, 0.018467804408471795), (29, 0.0672554944576633)]\n",
      "document number  1\n",
      "[(0, 0.007260481442496487), (1, 0.07291021263132706), (2, 0.010633989807097507), (3, 0.005415712810193173), (4, -0.006375105231577169), (5, -0.012289757105509728), (6, 0.029817017298243303), (7, -0.013599707700917143), (8, 0.007715739703427438), (9, 0.016870342637467128), (10, 0.033610013702008404), (11, 0.03022623231148003), (12, -0.038552727439643296), (13, 0.021280578296387968), (14, 0.04773966506638921), (15, -0.001947619043673166), (16, -0.03292381248330996), (17, 0.0007722189034116769), (18, 0.01886889674953878), (19, -0.007063644405167738), (20, -0.0053225382324847605), (21, -0.012651572905656562), (22, -0.005688260534867502), (23, -0.060689626698800764), (24, 0.0004699631525648464), (25, -0.014067129576608363), (26, -0.025600786702713464), (27, -0.027607641565399594), (28, 0.03222156221637523), (29, 0.022339928877983247)]\n",
      "document number  2\n",
      "[(0, 0.007383022798842198), (1, 0.07203431511549774), (2, 0.014567594348118825), (3, -0.029742567297206774), (4, -0.017019665783800878), (5, -0.047217854149495954), (6, 0.06493895251003018), (7, 0.019791675402849138), (8, -0.021487698716509778), (9, 0.08165363104959442), (10, -0.02789928232410779), (11, -0.015590380538427765), (12, 0.058030899917822724), (13, -0.015145213630663268), (14, -0.0254123701815702), (15, -0.02668757907021228), (16, -0.0074298794715773634), (17, -0.03431148273595266), (18, 0.06650837359961922), (19, 0.01086350252547706), (20, 0.041511530715554114), (21, 0.01739418536743757), (22, -0.018308571388376386), (23, -0.033010444701633536), (24, -0.003970468894610672), (25, -0.0010859955726864959), (26, 0.01592451186906751), (27, 0.0211631276751761), (28, -0.01794068339174009), (29, 0.030032748187319987)]\n"
     ]
    }
   ],
   "source": [
    "num_partition = 0\n",
    "for lsa in partitions_lsa:\n",
    "    print(\"Partition numéro:\",num_partition)\n",
    "    num_partition+=1\n",
    "    i=0\n",
    "    for doc in lsa:\n",
    "        if (i<3):\n",
    "            print(\"document number \", i)\n",
    "            i+=1\n",
    "            print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create ours partitions\n",
    "partitions = []\n",
    "\n",
    "# You must specify a treshold, to know what are the doc you keep, and what are the doc you drop\n",
    "tresh = 0.03\n",
    "\n",
    "for corpus_lsi in partitions_lsa:\n",
    "    # Let's create ours clusters\n",
    "    clusters = []\n",
    "\n",
    "    for i in range(0, nb_concepts):\n",
    "        dic = {}\n",
    "        num_doc = 0\n",
    "        for doc in corpus_lsi:\n",
    "            if abs(doc[i][1]) > tresh:\n",
    "                dic[num_doc] = doc[i][1]\n",
    "            num_doc+=1\n",
    "        clusters.append(dic)\n",
    "    partitions.append(clusters)\n",
    "    \n",
    "# TODO: it would be nice to know how many articles are in no cluster anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -0.07118575251456316,\n",
       " 2: 0.03517684316237265,\n",
       " 4: 0.030949588077932168,\n",
       " 6: -0.03903031658883216,\n",
       " 10: -0.042122287867876196,\n",
       " 13: 0.03199465425799143,\n",
       " 15: 0.05696508686371263,\n",
       " 19: 0.03070633463928613,\n",
       " 21: 0.044167731599077685,\n",
       " 27: 0.07214586367724328,\n",
       " 30: 0.0489790056285975,\n",
       " 35: 0.03491735862798161,\n",
       " 39: -0.04648167279744784,\n",
       " 44: 0.06719455009309083,\n",
       " 45: -0.03236240075430082,\n",
       " 50: -0.07234008899732827,\n",
       " 55: 0.046952221602755286,\n",
       " 56: 0.07284638968514465,\n",
       " 59: -0.0426280183106404,\n",
       " 60: -0.10906514237008724,\n",
       " 69: -0.09380809963696331,\n",
       " 76: 0.03664858548972769,\n",
       " 78: 0.05091243581423806,\n",
       " 82: 0.04197132864238727,\n",
       " 83: 0.03764239541212245,\n",
       " 86: -0.04441379782253787,\n",
       " 88: 0.030454056151978385,\n",
       " 93: -0.0364870257285272,\n",
       " 97: 0.06521992853113161,\n",
       " 99: -0.10578249336226304,\n",
       " 100: -0.07286352803549878,\n",
       " 101: 0.03651901036362523,\n",
       " 105: 0.057555840428314284,\n",
       " 111: -0.03295084517195956,\n",
       " 112: 0.06425700594567908,\n",
       " 113: 0.046872105666898,\n",
       " 117: 0.0426939060544083,\n",
       " 119: -0.1108814292661865,\n",
       " 128: -0.03594660556254839,\n",
       " 136: 0.04425455015291466,\n",
       " 137: 0.045083273706141506,\n",
       " 142: 0.040606934990626974,\n",
       " 147: 0.04339343511426318,\n",
       " 157: -0.18940390015731573,\n",
       " 168: -0.042036014631604036,\n",
       " 169: 0.06935912731004695,\n",
       " 171: 0.04023509789102576,\n",
       " 173: -0.06389461785952075,\n",
       " 179: -0.10226740414752637,\n",
       " 181: -0.05049129851530371,\n",
       " 184: 0.04270191554029172,\n",
       " 190: 0.036160474041250945,\n",
       " 192: 0.06589604857308874,\n",
       " 195: 0.03375434594588441,\n",
       " 199: 0.03689747427041441,\n",
       " 201: 0.06177835350694148,\n",
       " 211: -0.0845455234672126,\n",
       " 212: -0.045527476763759955,\n",
       " 214: -0.05052906056951596,\n",
       " 216: -0.05015287676881251,\n",
       " 222: 0.046553153997295,\n",
       " 227: 0.058662954633652786,\n",
       " 228: -0.031060842251455636,\n",
       " 231: 0.05991008237758588,\n",
       " 233: 0.046886101543324295,\n",
       " 245: -0.031340429040742,\n",
       " 253: -0.030299940996224455,\n",
       " 254: -0.0354256961755193,\n",
       " 255: -0.03485798716436765,\n",
       " 258: 0.05384966179786111,\n",
       " 259: 0.031479205986775664,\n",
       " 262: 0.03265355170948764}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display clusters 3 of partition 0 \n",
    "partitions[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_labels_by_cluster = 5\n",
    "\n",
    "# Let's labelize our clusters\n",
    "# For this, we will use the tfidf matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=sourceFST, use_idf=True, ngram_range=(min_gram, max_gram))\n",
    "tfidf = vectorizer.fit_transform(usable)\n",
    "\n",
    "# We can access the value in the tfidf using:\n",
    "#tfidf.toarray().item(num_doc, num_word)\n",
    "# To know the number of the word searched, we will use:\n",
    "#vectorizer.vocabulary_[word]\n",
    "\n",
    "# take less than 8h to compute x)\n",
    "labels = []\n",
    "for clusters in partitions:\n",
    "    l = []\n",
    "    for clus in clusters:\n",
    "        first_arti = True\n",
    "        for article in clus:\n",
    "            link = abs(clus[article])\n",
    "            if first_arti:\n",
    "                coef_list = (tfidf.toarray()[article] * link)\n",
    "                first = False\n",
    "            else:\n",
    "                # the more an article have a high coeficient, the more he is implied in the labeling step\n",
    "                coef_list += (tfidf.toarray()[article] * link)\n",
    "        # Now we have coef_list filled by every coeficient in the multiple tfidf\n",
    "        # Let's find the best ones, to finally get the labels\n",
    "        res = dict(zip(vectorizer.get_feature_names(), coef_list))\n",
    "\n",
    "        l.append(Counter(res).most_common(nb_labels_by_cluster))\n",
    "    labels.append(l)\n",
    "\n",
    "# TODO: on observe beaucoup de labels identiques entre deux clusters\n",
    "# Je pense que c'est parce que l'on a trop de clusters, mais j'aimerais en être sûr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display labels\n",
    "# labels is composed by an array for each partition\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
