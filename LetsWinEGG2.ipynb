{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "from gensim import corpora, models, utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
    "from gensim.models import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy lib\n",
    "# On https://spacy.io/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Parameters #\n",
    "##############\n",
    "\n",
    "min_gram = 1\n",
    "max_gram = 3\n",
    "\n",
    "# To create ours partitions, we must first know the years which will be the limits\n",
    "limit_years = [2007, 2010, 2014]\n",
    "\n",
    "# Ignore words that appear at a frequency less than tresh_freq in the corpus\n",
    "tresh_freq = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas preprocessing methods.\n",
    "\n",
    "# Lemmatisation without poncutations\n",
    "\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()\n",
    "fstw = stopwords.words('french')\n",
    "\n",
    "# French Stop Words, extraits depuis le fichier stopwords-fr.txt + stopwords french de nltk\n",
    "sourceFST = [x.replace('\\n', '') for x in open('stopwords-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]+fstw\n",
    "\n",
    "# Based on ration of french and english stopwords\n",
    "def isEnglish(article):\n",
    "    total_fsw = len([x for x in article.split() if x in sourceFST])\n",
    "    total_esw = len([x for x in article.split() if x in stopwords.words('english')])\n",
    "    ratio = 100\n",
    "    if total_fsw != 0:\n",
    "        ratio = total_esw/total_fsw\n",
    "    return ratio > 1 and total_esw > 3\n",
    "\n",
    "def lemmatize(article):\n",
    "    artiregex = re.sub(\" [0-z][0-z] \", \" \", article) # word of length < 2\n",
    "    artiregex = artiregex.lower()\n",
    "    artiregex = re.sub(\"(é|è|ê)\", \"e\", artiregex)\n",
    "    output = []\n",
    "    outPonc = artiregex.translate(artiregex.maketrans(\"\",\"\", string.punctuation))\n",
    "    outLem = nlp(outPonc)\n",
    "    for token in outLem:\n",
    "        if token.lemma_ not in sourceFST and [x for x in token.lemma_ if x not in \"0123456789\"] != []:\n",
    "            output.append(token.lemma_)\n",
    "    res = ' '.join(output)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    "data = pd.read_csv('export_articles_EGC_2004_2018.csv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process our corpus, and determine a limit to split it in partitions\n",
    "\n",
    "# usable[] correspond to our corpus processed\n",
    "# limits[] let us know when to delimit partitions\n",
    "limits = []\n",
    "usable = []\n",
    "\n",
    "prev_year = data['year'][0]\n",
    "numArti = 0\n",
    "for i in range(0, len(data['abstract']), 1):\n",
    "    #if not null, empty, or whatever (so if there is a abstract):\n",
    "    if not isinstance(data['abstract'][i], float) and not isEnglish(data['abstract'][i]):\n",
    "        text = data['abstract'][i]\n",
    "        if not isinstance(data['title'][i], float):\n",
    "            text += \" \"+data['title'][i]\n",
    "\n",
    "        numArti+=1\n",
    "        usable.append(stemmer.stem(lemmatize(text)))\n",
    "        year = data['year'][i]\n",
    "        if year != prev_year:\n",
    "            prev_year = year\n",
    "            if year in limit_years:\n",
    "                limits.append(numArti)\n",
    "limits.append(numArti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display pre-processed datas\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=sourceFST, use_idf=True, ngram_range=(min_gram, max_gram), max_df=tresh_freq)\n",
    "tfidf = vectorizer.fit_transform(usable)\n",
    "\n",
    "print(\"nombre d'articles =\", len(usable))\n",
    "print(\"nombre de mots =\", len(tfidf.toarray()[0]))\n",
    "print(\"limits =\", limits)\n",
    "\n",
    "usable[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of partitions_tfidf[], which give us the TFIDF of each cluster of each partition\n",
    "# partitions_tfidf[num_partition][num_doc][num_word]\n",
    "# Beware, num_doc can't be equals to 1091 (max). You have partitions, so every doc aren't in every partitions\n",
    "# num_word can be found via vectorizer.get_feature_name()\n",
    "partitions_tfidf = []\n",
    "beg = 0\n",
    "for l in limits:\n",
    "    last = l\n",
    "    partitions_tfidf.append([list(x) for x in list(tfidf.toarray())[beg:last]])\n",
    "    beg = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['066046pour',\n",
       " '066046pour prediction',\n",
       " '066046pour prediction multilabel',\n",
       " '0subsompt',\n",
       " '125ˆˆxsddecimalder',\n",
       " '125ˆˆxsddecimalder dat',\n",
       " '125ˆˆxsddecimalder dat 20170126t235715ˆˆxsddatetime',\n",
       " '15cmnou',\n",
       " '15cmnou employon',\n",
       " '15cmnou employon hog',\n",
       " '17eme',\n",
       " '17eme siecle',\n",
       " '17eme siecle entrer',\n",
       " '1999a',\n",
       " '1999a 1999b',\n",
       " '1999a 1999b prendre',\n",
       " '1999b',\n",
       " '1999b prendre',\n",
       " '1999b prendre lechelle',\n",
       " '19x19',\n",
       " '19x19 representation',\n",
       " '19x19 representation utilise',\n",
       " '1d',\n",
       " '1d lespace',\n",
       " '1d lespace geographiquede',\n",
       " '1dsax',\n",
       " '1dsax ameliore',\n",
       " '1dsax ameliore taux',\n",
       " '1dsax methode',\n",
       " '1dsax methode representer',\n",
       " '1dsax representation',\n",
       " '1dsax representation symbolique',\n",
       " '1dsax sax',\n",
       " '1dsax sax dan',\n",
       " '1km2',\n",
       " '1km2 carreau',\n",
       " '1km2 carreau guidee',\n",
       " '2005a',\n",
       " '2005a utiliser',\n",
       " '2005a utiliser modele',\n",
       " '2006heikinheimo',\n",
       " '2006heikinheimo al',\n",
       " '2006heikinheimo al solution',\n",
       " '2007montre',\n",
       " '2007montre typer',\n",
       " '2007montre typer dexploration',\n",
       " '2009lidee',\n",
       " '2009lidee dutiliser',\n",
       " '2009lidee dutiliser soussurface',\n",
       " '20170126t235715ˆˆxsddatetime',\n",
       " '20170126t235715ˆˆxsddatetime typer',\n",
       " '20170126t235715ˆˆxsddatetime typer dinformationvert',\n",
       " '20dimensions',\n",
       " '20dimensions classe',\n",
       " '20dimensions classe seconde',\n",
       " '212segment',\n",
       " '212segment folio',\n",
       " '212segment folio codex',\n",
       " '21eme',\n",
       " '21eme siecle',\n",
       " '21eme siecle accompagner',\n",
       " '21eme siecle organisation',\n",
       " '2424actu',\n",
       " '2424actu laspect',\n",
       " '2424actu laspect qualitatif',\n",
       " '24inventaires',\n",
       " '24inventaires dhabitat',\n",
       " '24inventaires dhabitat corallien',\n",
       " '24procedures',\n",
       " '24procedures chirurgical',\n",
       " '24procedures chirurgical dhernie',\n",
       " '25ans',\n",
       " '25ans utilisateur',\n",
       " '25ans utilisateur permettre',\n",
       " '2d',\n",
       " '2d cellule',\n",
       " '2d cellule griller',\n",
       " '2d grâce',\n",
       " '2d grâce contrôle',\n",
       " '2les',\n",
       " '2les resultat',\n",
       " '2les resultat qualite',\n",
       " '2modlouvain',\n",
       " '2modlouvain detecter',\n",
       " '2modlouvain detecter plaire',\n",
       " '2modlouvain method',\n",
       " '2modlouvain method utilisantc',\n",
       " '3d',\n",
       " '3d approcher',\n",
       " '3d approcher classique',\n",
       " '3d debat',\n",
       " '3d debat dan',\n",
       " '3d gestion',\n",
       " '3d gestion dinformation',\n",
       " '3d monoscopiqu',\n",
       " '3d monoscopiqu stereoscopique',\n",
       " '3d presenter',\n",
       " '3d presenter etude',\n",
       " '3d realite',\n",
       " '3d realite virtuel',\n",
       " '3d stereoscopique',\n",
       " '3d stereoscopique difference',\n",
       " '3dce',\n",
       " '3dce propriete',\n",
       " '3dce propriete illustreer',\n",
       " '3det',\n",
       " '3det raisonnement',\n",
       " '3det raisonnement associ',\n",
       " '3ghz',\n",
       " '3ghz ram',\n",
       " '3ghz ram classification',\n",
       " '3grammes',\n",
       " '3grammes pertinence',\n",
       " '3grammes pertinence rapport',\n",
       " '3way',\n",
       " '3way dextraction',\n",
       " '3way dextraction dun',\n",
       " '3way dumeme',\n",
       " '3way dumeme typer',\n",
       " '500signes',\n",
       " '500signes partir',\n",
       " '500signes partir dechiffree',\n",
       " '5ieme',\n",
       " '5ieme rang',\n",
       " '5ieme rang competitioninternationale1',\n",
       " '7e',\n",
       " '7e etape',\n",
       " '7e etape ver',\n",
       " '7e faire',\n",
       " '7e faire intervenir',\n",
       " '7e suzuki',\n",
       " '7e suzuki yu',\n",
       " '7eme',\n",
       " '7eme version',\n",
       " '7eme version carter',\n",
       " 'a8594c',\n",
       " 'a8594c b8594c',\n",
       " 'a8594c b8594c pourcela',\n",
       " 'aapporte',\n",
       " 'aapporte meilleur',\n",
       " 'aapporte meilleur comprehension',\n",
       " 'ab',\n",
       " 'ab procedure',\n",
       " 'ab procedure utilise',\n",
       " 'ab8594c',\n",
       " 'ab8594c quiapportent',\n",
       " 'ab8594c quiapportent information',\n",
       " 'aberrant',\n",
       " 'aberrant outlier',\n",
       " 'aberrant outlier consister',\n",
       " 'aberrant partir',\n",
       " 'aberrant partir motif',\n",
       " 'aberration',\n",
       " 'aberration chromosomique',\n",
       " 'aberration chromosomique variant',\n",
       " 'abondammer',\n",
       " 'abondammer abordee',\n",
       " 'abondammer abordee outil',\n",
       " 'abonne',\n",
       " 'abonne telephonie',\n",
       " 'abonne telephonie mobile',\n",
       " 'aborde',\n",
       " 'aborde fouill',\n",
       " 'aborde fouill donneer',\n",
       " 'aborde maniere',\n",
       " 'aborde maniere discussion',\n",
       " 'aborde premierement',\n",
       " 'aborde premierement analyser',\n",
       " 'abordee',\n",
       " 'abordee lapproximation',\n",
       " 'abordee lapproximation parcimonieux',\n",
       " 'abordee loptimisation',\n",
       " 'abordee loptimisation dun',\n",
       " 'abordee onrest',\n",
       " 'abordee onrest dan',\n",
       " 'abordee outil',\n",
       " 'abordee outil veill',\n",
       " 'abordee proposer',\n",
       " 'abordee proposer representation',\n",
       " 'abordee travers',\n",
       " 'abordee travers caracteristique',\n",
       " 'abordeer',\n",
       " 'abordeer dan',\n",
       " 'abordeer dan collection',\n",
       " 'aborder',\n",
       " 'aborder dan',\n",
       " 'aborder dan papier',\n",
       " 'aborder efficacement',\n",
       " 'aborder efficacement probleme',\n",
       " 'aborder mentionnerqu',\n",
       " 'aborder mentionnerqu grand',\n",
       " 'aborder problematiqu',\n",
       " 'aborder problematiqu dextraction',\n",
       " 'aborder probleme',\n",
       " 'aborder probleme classement',\n",
       " 'aborder probleme classification',\n",
       " 'aborder probleme lutilisation',\n",
       " 'aborder probleme selection',\n",
       " 'aborder probleme uneapproche',\n",
       " 'aborder secondprobleme',\n",
       " 'aborder secondprobleme proposer',\n",
       " 'aborder tâch',\n",
       " 'aborder tâch problematiqu',\n",
       " 'aboutir',\n",
       " 'aboutir connaissance',\n",
       " 'aboutir connaissance actionnable',\n",
       " 'aboutir definition',\n",
       " 'aboutir definition expiration',\n",
       " 'aboutir groupage',\n",
       " 'aboutir groupage performant',\n",
       " 'aboutir incoherence',\n",
       " 'aboutir incoherence dan',\n",
       " 'aboutir meilleur',\n",
       " 'aboutir meilleur performance',\n",
       " 'aboutir meilleure',\n",
       " 'aboutir meilleure recommandation',\n",
       " 'aboutir paradoxe',\n",
       " 'aboutir paradoxe puisquil',\n",
       " 'aboutir representation',\n",
       " 'aboutir representation condense',\n",
       " 'aboutir resultat',\n",
       " 'aboutir resultat extremement',\n",
       " 'aboutir solution',\n",
       " 'aboutir solution differenter',\n",
       " 'aboutir taux',\n",
       " 'aboutir taux derreur',\n",
       " 'aboutir àlacceptation',\n",
       " 'aboutir àlacceptation regle',\n",
       " 'absent',\n",
       " 'absent representationcomplexe',\n",
       " 'absent representationcomplexe possede',\n",
       " 'absolut',\n",
       " 'absolut habituel',\n",
       " 'absolut habituel idee',\n",
       " 'abstopk',\n",
       " 'abstopk algorithm',\n",
       " 'abstopk algorithm dextraction',\n",
       " 'abstraction',\n",
       " 'abstraction ditems',\n",
       " 'abstraction ditems etentre',\n",
       " 'abstrait',\n",
       " 'abstrait dinterrogation',\n",
       " 'abstrait dinterrogation graphe',\n",
       " 'abstrait graphe',\n",
       " 'abstrait graphe connaiss',\n",
       " 'abstrait grapher',\n",
       " 'abstrait grapher connaissancekgram',\n",
       " 'abstrait hautement',\n",
       " 'abstrait hautement correle',\n",
       " 'abstrait kgram',\n",
       " 'abstrait kgram concevoir',\n",
       " 'abstrait lindexation',\n",
       " 'abstrait lindexation automatique',\n",
       " 'abstrait repondant',\n",
       " 'abstrait repondant probleme',\n",
       " 'ac',\n",
       " 'ac fin',\n",
       " 'ac fin combler',\n",
       " 'acab',\n",
       " 'acabit',\n",
       " 'acabit plaire',\n",
       " 'acabit plaire connaître',\n",
       " 'acabit quezao',\n",
       " 'acabit quezao acabit',\n",
       " 'academiqu',\n",
       " 'academiqu monder',\n",
       " 'academiqu monder industriel',\n",
       " 'academiqu raisonnement',\n",
       " 'academiqu raisonnement gestion',\n",
       " 'academiqu reel',\n",
       " 'academiqu reel resultat',\n",
       " 'academique',\n",
       " 'academique qualit',\n",
       " 'academique qualit representation',\n",
       " 'acc',\n",
       " 'acc document',\n",
       " 'acc document potentiellement',\n",
       " 'acc rapideet',\n",
       " 'acc rapideet cibl',\n",
       " 'acce',\n",
       " 'acce accroître',\n",
       " 'acce accroître system',\n",
       " 'acce donnee',\n",
       " 'acce donnee disposer',\n",
       " 'acce donnee methode',\n",
       " 'acce jeu',\n",
       " 'acce jeu donnee',\n",
       " 'acce uniforme',\n",
       " 'acce uniforme metadonneer',\n",
       " 'acce utilisateur',\n",
       " 'acce utilisateur faire',\n",
       " 'acceder',\n",
       " 'acceder baser',\n",
       " 'acceder baser engendrer',\n",
       " 'acceder donnee',\n",
       " 'acceder donnee plaire',\n",
       " 'acceder information',\n",
       " 'acceder information lutilisateur',\n",
       " 'acceler',\n",
       " 'acceler convergence',\n",
       " 'acceler convergence delestimation',\n",
       " 'acceleration',\n",
       " 'acceleration em',\n",
       " 'acceleration em donnee',\n",
       " 'acceleration fort',\n",
       " 'acceleration fort processus',\n",
       " 'acceleration methode',\n",
       " 'acceleration methode plaire',\n",
       " 'acceleratrice',\n",
       " 'acceleratrice generent',\n",
       " 'acceleratrice generent nombre',\n",
       " 'accelere',\n",
       " 'accelere enidentifiant',\n",
       " 'accelere enidentifiant molecul',\n",
       " 'accelerer',\n",
       " 'accelerer temps',\n",
       " 'accelerer temps reponse',\n",
       " 'accentuee',\n",
       " 'accentuee dan',\n",
       " 'accentuee dan application',\n",
       " 'accentuer',\n",
       " 'accentuer baisser',\n",
       " 'accentuer baisser qualitenos',\n",
       " 'accentuer necessite',\n",
       " 'accentuer necessite proposer',\n",
       " 'acceptable',\n",
       " 'acceptable compar',\n",
       " 'acceptable compar coût',\n",
       " 'acceptable comparaison',\n",
       " 'acceptable comparaison techniquesnonincrementale',\n",
       " 'acceptable objectif',\n",
       " 'acceptable objectif atteindre',\n",
       " 'accepter',\n",
       " 'accepter marge',\n",
       " 'accepter marge derreur',\n",
       " 'accepter unjournal',\n",
       " 'accepter unjournal international',\n",
       " 'accer',\n",
       " 'accer connaissance',\n",
       " 'accer connaissance oral',\n",
       " 'accer internet',\n",
       " 'accer internet nesignifie',\n",
       " 'accer linformation',\n",
       " 'accer linformation manqu',\n",
       " 'acces',\n",
       " 'acces efficace',\n",
       " 'acces efficace donnee',\n",
       " 'accessibilite',\n",
       " 'accessibilite mobilite',\n",
       " 'accessibilite mobilite reduite',\n",
       " 'accessible',\n",
       " 'accessible acteur',\n",
       " 'accessible acteur connaissance',\n",
       " 'accessible ensuite',\n",
       " 'accessible ensuite etuder',\n",
       " 'accessible ligne',\n",
       " 'accessible ligne sou',\n",
       " 'accessible machine',\n",
       " 'accessible machine dan',\n",
       " 'accessible motif',\n",
       " 'accessible motif sequentiel',\n",
       " 'accessible recherchetextuelle',\n",
       " 'accessible recherchetextuelle registre',\n",
       " 'accessible utilisateur',\n",
       " 'accessible utilisateur proposer',\n",
       " 'accessible utilisateur specialist',\n",
       " 'accessible web',\n",
       " 'accessible web cest',\n",
       " 'accessible web interactifet',\n",
       " 'accessible web tenter',\n",
       " 'accessiblesur',\n",
       " 'accessiblesur web',\n",
       " 'accessiblesur web lurl',\n",
       " 'accessibleà',\n",
       " 'accessibleà sou',\n",
       " 'accessibleà sou former',\n",
       " 'accessimple',\n",
       " 'accessimple web',\n",
       " 'accessimple web donnee',\n",
       " 'accident',\n",
       " 'accident coûteuxpour',\n",
       " 'accident coûteuxpour lassureur',\n",
       " 'accident maritim',\n",
       " 'accident maritime',\n",
       " 'accident maritime decouverte',\n",
       " 'accident potentiel',\n",
       " 'accident potentiel installation',\n",
       " 'accompagnee',\n",
       " 'accompagnee dillustration',\n",
       " 'accompagnee dillustration graphique',\n",
       " 'accompagnee implementation',\n",
       " 'accompagnee implementation aid',\n",
       " 'accompagnelemergence',\n",
       " 'accompagnelemergence echange',\n",
       " 'accompagnelemergence echange massif',\n",
       " 'accompagner',\n",
       " 'accompagner debut',\n",
       " 'accompagner debut 21eme',\n",
       " 'accompagner dune',\n",
       " 'accompagner dune penurie',\n",
       " 'accompagner travail',\n",
       " 'accompagner travail lanalyst',\n",
       " 'accomplir',\n",
       " 'accomplir montrer',\n",
       " 'accomplir montrer performance',\n",
       " 'accord',\n",
       " 'accord besoin',\n",
       " 'accord besoin lutilisateurpourter',\n",
       " 'accord commercial',\n",
       " 'accord commercial entrer',\n",
       " 'accord commercial reposer',\n",
       " 'accord entresystem',\n",
       " 'accord entresystem autonome',\n",
       " 'accord hierarchie',\n",
       " 'accord hierarchie desvariabl',\n",
       " 'accord structurer',\n",
       " 'accord structurer combin',\n",
       " 'accord treillis',\n",
       " 'accord treillis concept',\n",
       " 'accord typer',\n",
       " 'accord typer peering',\n",
       " 'accordde',\n",
       " 'accordde typer',\n",
       " 'accordde typer clientfournisseur',\n",
       " 'accorder',\n",
       " 'accorder information',\n",
       " 'accorder information source',\n",
       " 'accorder quantite',\n",
       " 'accorder quantite memoir',\n",
       " 'accorder serie',\n",
       " 'accorder serie mem',\n",
       " 'accordsqui',\n",
       " 'accordsqui mettre',\n",
       " 'accordsqui mettre oeuvrer',\n",
       " 'accroître',\n",
       " 'accroître system',\n",
       " 'accroître system dinformation',\n",
       " 'accumul',\n",
       " 'accumul dan',\n",
       " 'accumul dan temps',\n",
       " 'accumulation',\n",
       " 'accumulation clustering',\n",
       " 'accumulation clustering local',\n",
       " 'acer',\n",
       " 'acer article',\n",
       " 'acer article proposer',\n",
       " 'acf',\n",
       " 'acf classification',\n",
       " 'acf classification visualisation',\n",
       " 'achat',\n",
       " 'achat client',\n",
       " 'achat client considerer',\n",
       " 'achat client illustrer',\n",
       " 'achat molecule',\n",
       " 'achat molecule atome',\n",
       " 'achat noël',\n",
       " 'achat noël approche',\n",
       " 'achat tabler',\n",
       " 'achat tabler danalyseindividus',\n",
       " 'acheter',\n",
       " 'acheter produire',\n",
       " 'acheter produire probabiliteest',\n",
       " 'acide',\n",
       " 'acide amin',\n",
       " 'acide amin signature',\n",
       " 'acka',\n",
       " 'acka approach',\n",
       " 'acka approach for',\n",
       " 'acka approcher',\n",
       " 'acka approcher dacquisition',\n",
       " 'acka construire',\n",
       " 'acka construire modele',\n",
       " 'acm',\n",
       " 'acm appliquee',\n",
       " 'acm appliquee mem',\n",
       " 'acm clusteringet',\n",
       " 'acm clusteringet supervisees',\n",
       " 'acontribue',\n",
       " 'acontribue popularite',\n",
       " 'acontribue popularite base',\n",
       " 'acoustique',\n",
       " 'acoustique connaissance',\n",
       " 'acoustique connaissance prononciation',\n",
       " 'acoustique meilleur',\n",
       " 'acoustique meilleur prenden',\n",
       " 'acoustique partir',\n",
       " 'acoustique partir grand',\n",
       " 'acoustique permettre',\n",
       " 'acoustique permettre potentiellement',\n",
       " 'acp',\n",
       " 'acp filtree',\n",
       " 'acp filtree tableau',\n",
       " 'acp granulair',\n",
       " 'acp obtenir',\n",
       " 'acp obtenir espacer',\n",
       " 'acp proposer',\n",
       " 'acp proposer dintegrer',\n",
       " 'acp reduire',\n",
       " 'acp reduire dimensionnalite',\n",
       " 'acprojection',\n",
       " 'acprojection baser',\n",
       " 'acprojection baser propriet',\n",
       " 'acquerir',\n",
       " 'acquerir lesconnaissance',\n",
       " 'acquerir lesconnaissance formuler',\n",
       " 'acquerir relation',\n",
       " 'acquerir relation semantiqu',\n",
       " 'acquis',\n",
       " 'acquis aupr',\n",
       " 'acquis aupr expert',\n",
       " 'acquisition',\n",
       " 'acquisition annotation',\n",
       " 'acquisition annotation exploration',\n",
       " 'acquisition donneer',\n",
       " 'acquisition donneer gestion',\n",
       " 'acquisition exploitation',\n",
       " 'acquisition exploitation connaissancer',\n",
       " 'acquisition participatif',\n",
       " 'acquisition participatif cooperativ',\n",
       " 'acquisition schema',\n",
       " 'acquisition schema conceptuel',\n",
       " 'acquisition structur',\n",
       " 'acquisition structur lexicosemantiqu',\n",
       " 'acquisition theorie',\n",
       " 'acquisition theorie ontologique',\n",
       " 'acquérir',\n",
       " 'acquérir apprenant',\n",
       " 'acquérir apprenant appuyer',\n",
       " 'acquérir automatiquement',\n",
       " 'acquérir automatiquement logiciel',\n",
       " 'acquérir pendre',\n",
       " 'acquérir pendre lutilisation',\n",
       " 'acquérir periode',\n",
       " 'acquérir periode an',\n",
       " 'acquérir reposer',\n",
       " 'acquérir reposer ensuite',\n",
       " 'acquérir terrain',\n",
       " 'acquérir terrain expertsdu',\n",
       " 'acr',\n",
       " 'acr travail',\n",
       " 'acr travail present',\n",
       " 'acreduit',\n",
       " 'acreduit decouvert',\n",
       " 'acreduit decouvert approcher',\n",
       " 'acreduit frequent',\n",
       " 'acronyme',\n",
       " 'acronyme gen',\n",
       " 'acronyme gen aberration',\n",
       " 'acte',\n",
       " 'acte conference',\n",
       " 'acte conference egcqui',\n",
       " 'acte desparol',\n",
       " 'acte desparol pouvoir',\n",
       " 'acte langage',\n",
       " 'acte langage travail',\n",
       " 'acte resolutions',\n",
       " 'acte resolutions problem',\n",
       " 'acteur',\n",
       " 'acteur analyser',\n",
       " 'acteur analyser visuel',\n",
       " 'acteur connaissance',\n",
       " 'acteur connaissance detenue',\n",
       " 'acteur dan',\n",
       " 'acteur dan article',\n",
       " 'acteur dan domaine',\n",
       " 'acteur dan organisation',\n",
       " 'acteur decision',\n",
       " 'acteur decision quantitatif',\n",
       " 'acteur droit',\n",
       " 'acteur droit proposer',\n",
       " 'acteur economiqu',\n",
       " 'acteur economiqu dan',\n",
       " 'acteur espacer',\n",
       " 'acteur espacer informationnel',\n",
       " 'acteur humain',\n",
       " 'acteur humain agent',\n",
       " 'acteur lorganisation',\n",
       " 'acteur lorganisation etude',\n",
       " 'acteur lorganisationdan',\n",
       " 'acteur lorganisationdan article',\n",
       " 'acteur marcher',\n",
       " 'acteur marcher methode',\n",
       " 'acteur mediocrer',\n",
       " 'acteur mediocrer dan',\n",
       " 'acteur moyen',\n",
       " 'acteur moyen integration',\n",
       " 'acteur objectif',\n",
       " 'acteur objectif divergentsnecessite',\n",
       " 'acteur problem',\n",
       " 'acteur problem solution',\n",
       " 'acteur reposer',\n",
       " 'acteur reposer dimension',\n",
       " 'acteur terme',\n",
       " 'acteur terme domaine',\n",
       " 'acteur terminologie',\n",
       " 'acteur terminologie concept',\n",
       " 'acteur turnover',\n",
       " 'acteur turnover dan',\n",
       " 'acteur usager',\n",
       " 'acteur usager domaine',\n",
       " 'acteur web',\n",
       " 'acteur web commercial',\n",
       " 'actif',\n",
       " 'actif demoter',\n",
       " 'actif demoter dan',\n",
       " 'actif detection',\n",
       " 'actif detection demoter',\n",
       " 'actif flot',\n",
       " 'actif flot opt',\n",
       " 'actif fouiller',\n",
       " 'actif fouiller donneer',\n",
       " 'actif inclure',\n",
       " 'actif inclure forcer',\n",
       " 'actif lexploration',\n",
       " 'actif lexploration donneer',\n",
       " 'actif moteur',\n",
       " 'actif moteur wiki',\n",
       " 'actif priseen',\n",
       " 'actif priseen compter',\n",
       " 'actif proposee',\n",
       " 'actif proposee strategie',\n",
       " 'actifce',\n",
       " 'actifce annees',\n",
       " 'actifce annees lobjectif',\n",
       " 'action',\n",
       " 'action cibleer',\n",
       " 'action cibleer personnaliser',\n",
       " 'action concreter',\n",
       " 'action concreter dan',\n",
       " 'action effectueer',\n",
       " 'action effectueer humain',\n",
       " 'action humain',\n",
       " 'action humain descripteur',\n",
       " 'action lexpert',\n",
       " 'action lexpert resolution',\n",
       " 'action modification',\n",
       " 'action modification mapping',\n",
       " 'action notreanalyse',\n",
       " 'action notreanalyse indicateur',\n",
       " 'action potentiel',\n",
       " 'action potentiel dan',\n",
       " 'action reconnaître',\n",
       " 'action reconnaître grâce',\n",
       " 'action suggere',\n",
       " 'action suggere proposer',\n",
       " 'action varieer',\n",
       " 'action varieer executees',\n",
       " 'actionnable',\n",
       " 'actionnable approcher',\n",
       " 'actionnable approcher fondee',\n",
       " 'actionnable boire',\n",
       " 'actionnable boire atteindre',\n",
       " 'actionnable laplus',\n",
       " 'actionnable laplus pertinent',\n",
       " 'actionnable regle',\n",
       " 'actionnable regle plaire',\n",
       " 'actionsquil',\n",
       " 'actionsquil effectuer',\n",
       " 'actionsquil effectuer linterface',\n",
       " 'actionsà',\n",
       " 'actionsà mener',\n",
       " 'actionsà mener fondre',\n",
       " 'activer',\n",
       " 'activer contrainte',\n",
       " 'activer contrainte specifiees',\n",
       " 'activer temps',\n",
       " 'activer temps dan',\n",
       " 'activit',\n",
       " 'activit cooperative',\n",
       " 'activit cooperative gestion',\n",
       " 'activit identifiees',\n",
       " 'activit identifiees effectuer',\n",
       " 'activite',\n",
       " 'activite cerebral',\n",
       " 'activite cerebral signal',\n",
       " 'activite commercial',\n",
       " 'activite commercial grand',\n",
       " 'activite dapprentissage',\n",
       " 'activite dapprentissage presentonsenfin',\n",
       " 'activite description',\n",
       " 'activite description acte',\n",
       " 'activite difficile',\n",
       " 'activite difficile complexe',\n",
       " 'activite etroitement',\n",
       " 'activite etroitement liee',\n",
       " 'activite explicite',\n",
       " 'activite explicite formalisable',\n",
       " 'activite garantir',\n",
       " 'activite garantir precision',\n",
       " 'activite negoc',\n",
       " 'activite negoc materiaux',\n",
       " 'activite produit',\n",
       " 'activite produit pouvoir',\n",
       " 'activite represente',\n",
       " 'activite represente jour',\n",
       " 'activite risque',\n",
       " 'activite risque application',\n",
       " 'actuel',\n",
       " 'actuel an',\n",
       " 'actuel an decouverte',\n",
       " 'actuel assist',\n",
       " 'actuel assist laccroissement',\n",
       " 'actuel clustering',\n",
       " 'actuel clustering from',\n",
       " 'actuel conduite',\n",
       " 'actuel conduite inspecteescett',\n",
       " 'actuel dan',\n",
       " 'actuel dan domaine',\n",
       " 'actuel dematerialisationmassiv',\n",
       " 'actuel dematerialisationmassiv document',\n",
       " 'actuel detection',\n",
       " 'actuel detection intrinsequ',\n",
       " 'actuel difficile',\n",
       " 'actuel difficile compromis',\n",
       " 'actuel eg',\n",
       " 'actuel eg rechercher',\n",
       " 'actuel internaute',\n",
       " 'actuel internaute solution',\n",
       " 'actuel lefficacite',\n",
       " 'actuel lefficacite approcher',\n",
       " 'actuel majorite',\n",
       " 'actuel majorite travauxrelatif',\n",
       " 'actuel methode',\n",
       " 'actuel methode exister',\n",
       " 'actuel noffrer',\n",
       " 'actuel noffrer concept',\n",
       " 'actuel passer',\n",
       " 'actuel passer lechell',\n",
       " 'actuel proposer',\n",
       " 'actuel proposer pss',\n",
       " 'actuel raisonneur',\n",
       " 'actuel raisonneur spatiotemporeldefini',\n",
       " 'actuel reordonner',\n",
       " 'actuel reordonner passage',\n",
       " 'actuel representation',\n",
       " 'actuel representation textuel',\n",
       " 'actuel reseau',\n",
       " 'actuel reseau social',\n",
       " 'actuel resultat',\n",
       " 'actuel resultat rechercher',\n",
       " 'actuel science',\n",
       " 'actuel science cognitif',\n",
       " 'actuel travail',\n",
       " 'actuel travail considerent',\n",
       " 'actuel travail rechercher',\n",
       " 'actuel vecteur',\n",
       " 'actuel vecteur progr',\n",
       " 'actuel viser',\n",
       " 'actuel viser enrichir',\n",
       " 'actuellement',\n",
       " 'actuellement capabler',\n",
       " 'actuellement capabler dutiliser',\n",
       " 'actuellement clustering',\n",
       " 'actuellement clustering flux',\n",
       " 'actuellement employe',\n",
       " 'actuellement employe ei',\n",
       " 'actuellement essor',\n",
       " 'actuellement essor dan',\n",
       " 'actuellement fonctionnel',\n",
       " 'actuellement fonctionnel accessiblesur',\n",
       " 'actuellement intraitable',\n",
       " 'actuellement intraitable lechelle',\n",
       " 'actuellement permettre',\n",
       " 'actuellement permettre dintegrerce',\n",
       " 'actuellement tanagra',\n",
       " 'actuellement tanagra logiciel',\n",
       " 'actuellementbaseer',\n",
       " 'actuellementbaseer decoupage',\n",
       " 'actuellementbaseer decoupage donnee',\n",
       " 'actuelsn',\n",
       " 'actuelsn pouvoir',\n",
       " 'actuelsn pouvoir traiter',\n",
       " 'acyclique',\n",
       " 'acyclique attribu',\n",
       " 'acyclique attribu pouvoir',\n",
       " 'acyclique orient',\n",
       " 'acyclique orient dag',\n",
       " 'adaboost',\n",
       " 'adaboost brownboost',\n",
       " 'adaboost brownboost version',\n",
       " 'adag',\n",
       " 'adapt',\n",
       " 'adapt besoin',\n",
       " 'adapt besoin recruteur',\n",
       " 'adapt fusion',\n",
       " 'adapt fusion dinformation',\n",
       " 'adapt modele',\n",
       " 'adapt modele supervision',\n",
       " 'adapt representer',\n",
       " 'adapt representer document',\n",
       " 'adaptable',\n",
       " 'adaptable perception',\n",
       " 'adaptable perception utilis',\n",
       " 'adaptable perception utilisateur',\n",
       " 'adaptateur',\n",
       " 'adaptateur web',\n",
       " 'adaptateur web semantiqu',\n",
       " 'adaptateur web service',\n",
       " 'adaptatif',\n",
       " 'adaptatif application',\n",
       " 'adaptatif application detection',\n",
       " 'adaptatif ast',\n",
       " 'adaptatif chaîn',\n",
       " 'adaptatif chaîn markov',\n",
       " 'adaptatif construitseulemer',\n",
       " 'adaptatif construitseulemer partir',\n",
       " 'adaptatif detectiondintrusion',\n",
       " 'adaptatif detectiondintrusion partir',\n",
       " 'adaptatif dextraction',\n",
       " 'adaptatif dextraction ligne',\n",
       " 'adaptatif diagnostic',\n",
       " 'adaptatif diagnostic surveiller',\n",
       " 'adaptatif dun',\n",
       " 'adaptatif dun algorithmedextraction',\n",
       " 'adaptatif graphe',\n",
       " 'adaptatif graphe voisinage',\n",
       " 'adaptatif hilbert',\n",
       " 'adaptatif hilbert permettre',\n",
       " 'adaptatif indice',\n",
       " 'adaptatif indice dissimilarite',\n",
       " 'adaptatif jeu',\n",
       " 'adaptatif jeu donnee',\n",
       " 'adaptatif lalgorithm',\n",
       " 'adaptatif lalgorithm ete',\n",
       " 'adaptatif maniere',\n",
       " 'adaptatif maniere plaire',\n",
       " 'adaptatif permettre',\n",
       " 'adaptatif permettre compter',\n",
       " 'adaptatif ponderation',\n",
       " 'adaptatif ponderation observation',\n",
       " 'adaptatif serier',\n",
       " 'adaptatif serier temporel',\n",
       " 'adaptatif simulation',\n",
       " 'adaptatif simulation schema',\n",
       " 'adaptatif structur',\n",
       " 'adaptatif structur regulation',\n",
       " 'adaptatif traiter',\n",
       " 'adaptatif traiter typer',\n",
       " 'adaptation',\n",
       " 'adaptation applicable',\n",
       " 'adaptation applicable mapping',\n",
       " 'adaptation approcher',\n",
       " 'adaptation approcher sappui',\n",
       " 'adaptation dune',\n",
       " 'adaptation dune mesurer',\n",
       " 'adaptation lalgorithm',\n",
       " 'adaptation lalgorithm cart',\n",
       " 'adaptation lalgorithmetemporalid3',\n",
       " 'adaptation lalgorithmetemporalid3 consoler',\n",
       " 'adaptation larc',\n",
       " 'adaptation larc explorer',\n",
       " 'adaptation mapping',\n",
       " 'adaptation mapping entrer',\n",
       " 'adaptation metrique',\n",
       " 'adaptation metrique classique',\n",
       " 'adaptation metrique dan',\n",
       " 'adaptation noyau',\n",
       " 'adaptation noyau nousformulon',\n",
       " 'adaptation representation',\n",
       " 'adaptation representation condensee',\n",
       " 'adaptation situer',\n",
       " 'adaptation situer niveau',\n",
       " 'adaptation typer',\n",
       " 'adaptation typer donnee',\n",
       " 'adaptative',\n",
       " 'adaptative distribution',\n",
       " 'adaptative distribution exemple',\n",
       " 'adaptative evaluation',\n",
       " 'adaptative evaluation preliminair',\n",
       " 'adaptative larticle',\n",
       " 'adaptative larticle present',\n",
       " 'adapte',\n",
       " 'adapte approche',\n",
       " 'adapte approche reconciliation',\n",
       " 'adapte aspect',\n",
       " 'adapte aspect spatiotemporel',\n",
       " 'adapte auformat',\n",
       " 'adapte auformat donneer',\n",
       " 'adapte auxstrategier',\n",
       " 'adapte auxstrategier memoir',\n",
       " 'adapte besoin',\n",
       " 'adapte besoin proposon',\n",
       " 'adapte cas',\n",
       " 'adapte cas variable',\n",
       " 'adapte classification',\n",
       " 'adapte classification petit',\n",
       " 'adapte configuration',\n",
       " 'adapte configuration specifiqu',\n",
       " 'adapte demarcheexploratoir',\n",
       " 'adapte demarcheexploratoir necessite',\n",
       " 'adapte donnee',\n",
       " 'adapte donnee bruitees',\n",
       " 'adapte donnee consideree',\n",
       " 'adapte donnee traite',\n",
       " 'adapte evaluer',\n",
       " 'adapte evaluer qualitedune',\n",
       " 'adapte flux',\n",
       " 'adapte flux donneer',\n",
       " 'adapte format',\n",
       " 'adapte format propos',\n",
       " 'adapte graphe',\n",
       " 'adapte graphe connaissance',\n",
       " 'adapte image',\n",
       " 'adapte image medical',\n",
       " 'adapte lamoncellemer',\n",
       " 'adapte lamoncellemer resultatsindependant',\n",
       " 'adapte lapprentissage',\n",
       " 'adapte lapprentissage supervis',\n",
       " 'adapte lespace',\n",
       " 'adapte lespace dimension',\n",
       " 'adapte lextractiond',\n",
       " 'adapte lextractiond terminologie',\n",
       " 'adapte model',\n",
       " 'adapte model voisinage',\n",
       " 'adapte nature',\n",
       " 'adapte nature distribution',\n",
       " 'adapte necessair',\n",
       " 'adapte necessair disposer',\n",
       " 'adapte obtenir',\n",
       " 'adapte obtenir arbre',\n",
       " 'adapte problem',\n",
       " 'adapte problem considere',\n",
       " 'adapte problematiqu',\n",
       " 'adapte problematiqu specifiqu',\n",
       " 'adapte probleme',\n",
       " 'adapte probleme compromis',\n",
       " 'adapte rechercher',\n",
       " 'adapte rechercher dimager',\n",
       " 'adapte rechercher dinformation',\n",
       " 'adapte rechercher dun',\n",
       " 'adapte reconstitution',\n",
       " 'adapte reconstitution typede',\n",
       " 'adapte resumer',\n",
       " 'adapte resumer gros',\n",
       " 'adapte utilisation',\n",
       " 'adapte utilisation cas',\n",
       " 'adapteau',\n",
       " 'adapteau application',\n",
       " 'adapteau application specifiqu',\n",
       " 'adaptee',\n",
       " 'adaptee besoin',\n",
       " 'adaptee besoin conforme',\n",
       " 'adaptee contexte',\n",
       " 'adaptee contexte presenter',\n",
       " 'adaptee dan',\n",
       " 'adaptee dan cas',\n",
       " 'adaptee dautr',\n",
       " 'adaptee dautr domaine',\n",
       " 'adaptee dobtenirde',\n",
       " 'adaptee dobtenirde meilleur',\n",
       " 'adaptee donnee',\n",
       " 'adaptee donnee dimension',\n",
       " 'adaptee expert',\n",
       " 'adaptee lapprentissage',\n",
       " 'adaptee lapprentissage croissance',\n",
       " 'adaptee levaluation',\n",
       " 'adaptee levaluation donne',\n",
       " 'adaptee representation',\n",
       " 'adaptee representation prediction',\n",
       " 'adaptee resolution',\n",
       " 'adaptee resolution dunprobleme',\n",
       " 'adaptee stockage',\n",
       " 'adaptee stockage donnee',\n",
       " 'adaptee typer',\n",
       " 'adaptee typer danalyse',\n",
       " 'adaptee tâche',\n",
       " 'adaptee tâche avonsderive',\n",
       " 'adaptee àleurs',\n",
       " 'adaptee àleurs besoin',\n",
       " 'adapteepour',\n",
       " 'adapteepour algorithme',\n",
       " 'adapteepour algorithme dapprentissage',\n",
       " 'adapteepourmettr',\n",
       " 'adapteepourmettr correspondance',\n",
       " 'adapteepourmettr correspondance champ',\n",
       " 'adapteer',\n",
       " 'adapteer information',\n",
       " 'adapteer information rechercheer',\n",
       " 'adapteer reseaux',\n",
       " 'adapteer reseaux dinform',\n",
       " 'adapteer traitement',\n",
       " 'adapteer traitement image',\n",
       " 'adapteesaux',\n",
       " 'adapteesaux interet',\n",
       " 'adapteesaux interet utilisateur',\n",
       " 'adapteesà',\n",
       " 'adapteesà probleme',\n",
       " 'adapteesà probleme methode',\n",
       " 'adapteesà situation',\n",
       " 'adapteesà situation donnee',\n",
       " 'adapteplusieur',\n",
       " 'adapteplusieur mesure',\n",
       " 'adapteplusieur mesure devaluation',\n",
       " 'adapter',\n",
       " 'adapter algorithme',\n",
       " 'adapter algorithme existant',\n",
       " 'adapter algorithme traitement',\n",
       " 'adapter besoin',\n",
       " 'adapter besoin milieu',\n",
       " 'adapter caractere',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partitions_tfidf[0][0])\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, the end use LSA :P Then the code below isn't important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f56a40bfd21f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcorpus_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mlsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_concepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mcorpus_lsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus_tfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpartitions_lsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_lsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, chunksize, decay, distributed, onepass, power_iters, extra_samples, dtype)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, corpus, chunksize, decay)\u001b[0m\n\u001b[1;32m    485\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'initializing %s workers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"preparing a new chunk of documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mchunkize_serial\u001b[0;34m(iterable, chunksize, as_numpy, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0mwrapped_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mwrapped_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped_chunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/gensim/models/tfidfmodel.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, eps)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mnorm_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mnorm_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_vector\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/gensim/models/tfidfmodel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mnorm_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mnorm_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtermid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_vector\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#params\n",
    "nb_concepts = 30\n",
    "min_gram = 1\n",
    "max_gram = 3\n",
    "\n",
    "# Creation of cleandocs, which is usable[] with ngrams\n",
    "cleandocs = []\n",
    "for t in usable:\n",
    "    doc = []\n",
    "    for n in range(min_gram, max_gram+1):\n",
    "        for gram in ngrams(t.split(), n):\n",
    "            doc.append(\" \".join(gram))\n",
    "    cleandocs.append(doc)\n",
    "\n",
    "# Creation of tfidf model, a tool to create ours tfidf\n",
    "corpus = []\n",
    "dictionary = corpora.Dictionary(cleandocs)\n",
    "for doc in cleandocs:\n",
    "    newVec = dictionary.doc2bow(doc)\n",
    "    corpus.append(newVec)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "# Creation of partitions_lsa[], which give us the LSA of each partition\n",
    "partitions_lsa = []\n",
    "beg = 0\n",
    "for l in limits:\n",
    "    last = l\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    lsi = models.LsiModel(corpus_tfidf, num_topics=nb_concepts, id2word=dictionary)\n",
    "    corpus_lsi = lsi[corpus_tfidf[beg:last]]\n",
    "    partitions_lsa.append(corpus_lsi)\n",
    "    beg = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partition = 0\n",
    "for lsa in partitions_lsa:\n",
    "    print(\"Partition numéro:\",num_partition)\n",
    "    num_partition+=1\n",
    "    i=0\n",
    "    for doc in lsa:\n",
    "        if (i<3):\n",
    "            print(\"document number \", i)\n",
    "            i+=1\n",
    "            print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create ours partitions\n",
    "partitions = []\n",
    "\n",
    "# You must specify a treshold, to know what are the doc you keep, and what are the doc you drop\n",
    "tresh = 0.03\n",
    "\n",
    "for corpus_lsi in partitions_lsa:\n",
    "    # Let's create ours clusters\n",
    "    clusters = []\n",
    "\n",
    "    for i in range(0, nb_concepts):\n",
    "        dic = {}\n",
    "        num_doc = 0\n",
    "        for doc in corpus_lsi:\n",
    "            if abs(doc[i][1]) > tresh:\n",
    "                dic[num_doc] = doc[i][1]\n",
    "            num_doc+=1\n",
    "        clusters.append(dic)\n",
    "    partitions.append(clusters)\n",
    "    \n",
    "# TODO: it would be nice to know how many articles are in no cluster anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display clusters 3 of partition 0 \n",
    "partitions[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_labels_by_cluster = 5\n",
    "\n",
    "# Let's labelize our clusters\n",
    "# For this, we will use the tfidf matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=sourceFST, use_idf=True, ngram_range=(min_gram, max_gram))\n",
    "tfidf = vectorizer.fit_transform(usable)\n",
    "\n",
    "# We can access the value in the tfidf using:\n",
    "#tfidf.toarray().item(num_doc, num_word)\n",
    "# To know the number of the word searched, we will use:\n",
    "#vectorizer.vocabulary_[word]\n",
    "\n",
    "# take less than 8h to compute x)\n",
    "labels = []\n",
    "for clusters in partitions:\n",
    "    l = []\n",
    "    for clus in clusters:\n",
    "        first_arti = True\n",
    "        for article in clus:\n",
    "            link = abs(clus[article])\n",
    "            if first_arti:\n",
    "                coef_list = (tfidf.toarray()[article] * link)\n",
    "                first = False\n",
    "            else:\n",
    "                # the more an article have a high coeficient, the more he is implied in the labeling step\n",
    "                coef_list += (tfidf.toarray()[article] * link)\n",
    "        # Now we have coef_list filled by every coeficient in the multiple tfidf\n",
    "        # Let's find the best ones, to finally get the labels\n",
    "        res = dict(zip(vectorizer.get_feature_names(), coef_list))\n",
    "\n",
    "        l.append(Counter(res).most_common(nb_labels_by_cluster))\n",
    "    labels.append(l)\n",
    "\n",
    "# TODO: on observe beaucoup de labels identiques entre deux clusters\n",
    "# Je pense que c'est parce que l'on a trop de clusters, mais j'aimerais en être sûr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display labels\n",
    "# labels is composed by an array for each partition\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
