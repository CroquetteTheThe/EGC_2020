{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "from gensim import corpora, models, utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
    "from gensim.models import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy lib\n",
    "# On https://spacy.io/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Parameters #\n",
    "##############\n",
    "\n",
    "min_gram = 1\n",
    "max_gram = 3\n",
    "\n",
    "# To create ours partitions, we must first know the years which will be the limits\n",
    "limit_years = [2007, 2010, 2013, 2016]\n",
    "\n",
    "# Ignore words that appear at a frequency less than max_frequ in the corpus\n",
    "max_frequ = 0.8\n",
    "\n",
    "# Ignore words appearing less than min_appear in the whole corpus\n",
    "min_appear = 5\n",
    "\n",
    "# Range fo cluster number you want to test\n",
    "cluster_ranges = range(2, 30)\n",
    "\n",
    "# Number of trial you want to do for each test\n",
    "nb_trial_by_test = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas preprocessing methods.\n",
    "\n",
    "# Lemmatisation without poncutations\n",
    "\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()\n",
    "fstw = stopwords.words('french')\n",
    "\n",
    "# French Stop Words, extraits depuis le fichier stopwords-fr.txt + stopwords french de nltk\n",
    "sourceFST = [x.replace('\\n', '') for x in open('stopwords-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]+fstw\n",
    "sourceFST += [x.replace('\\n', '') for x in open('perso_words-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]\n",
    "\n",
    "# Based on ration of french and english stopwords\n",
    "def isEnglish(article):\n",
    "    total_fsw = len([x for x in article.split() if x in sourceFST])\n",
    "    total_esw = len([x for x in article.split() if x in stopwords.words('english')])\n",
    "    ratio = 100\n",
    "    if total_fsw != 0:\n",
    "        ratio = total_esw/total_fsw\n",
    "    return ratio > 1 and total_esw > 3\n",
    "\n",
    "def lemmatize(article):\n",
    "    arti_lower = article.lower()\n",
    "    arti_2words = re.sub(\" [0-z][0-z] \", \" \", arti_lower) # word of length < 2\n",
    "    arti_e = re.sub(\"(é|è|ê)\", \"e\", arti_2words)\n",
    "    arti_o = re.sub(\"à\", \"a\", arti_e)\n",
    "    arti_i = re.sub(\"ô\", \"o\", arti_o)\n",
    "    artiregex = re.sub(\"î\", \"i\", arti_i)\n",
    "    output = []\n",
    "    outPonc = artiregex.translate(artiregex.maketrans(\"\",\"\", string.punctuation))\n",
    "    outLem = nlp(outPonc)\n",
    "    for token in outLem:\n",
    "        if token.lemma_ not in sourceFST and [x for x in token.lemma_ if x not in \"0123456789\"] != []:\n",
    "            output.append(token.lemma_)\n",
    "    res = ' '.join(output)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    "data = pd.read_csv('export_articles_EGC_2004_2018.csv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process our corpus, and determine a limit to split it in partitions\n",
    "\n",
    "# usable[] correspond to our corpus processed\n",
    "# limits[] let us know when to delimit partitions\n",
    "limits = []\n",
    "usable = []\n",
    "\n",
    "prev_year = data['year'][0]\n",
    "numArti = 0\n",
    "for i in range(0, len(data['abstract']), 1):\n",
    "    #if not null, empty, or whatever (so if there is a abstract):\n",
    "    if not isinstance(data['abstract'][i], float) and not isEnglish(data['abstract'][i]):\n",
    "        text = data['abstract'][i]\n",
    "        if not isinstance(data['title'][i], float):\n",
    "            text += \" \"+data['title'][i]\n",
    "\n",
    "        numArti+=1\n",
    "        usable.append(re.sub(\" [0-z][0-z] \", \" \", stemmer.stem(lemmatize(text))))\n",
    "        year = data['year'][i]\n",
    "        if year != prev_year:\n",
    "            prev_year = year\n",
    "            if year in limit_years:\n",
    "                limits.append(numArti)\n",
    "limits.append(numArti)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process word removal\n",
    "post_words = [x.replace('\\n', '') for x in open('post_process_words-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]\n",
    "\n",
    "for i in range(0, len(usable)):\n",
    "    arti = usable[i].split()\n",
    "    res = []\n",
    "    for word in arti:\n",
    "        if word not in post_words:\n",
    "            res.append(word)\n",
    "    usable[i] = ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'articles = 991\n",
      "nombre de mots = 2385\n",
      "limits = [114, 301, 468, 694, 991]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'plateforme objectif permettre citoyen euxmemer tweet politique devenement specifiqu francepour cas lelection presidentiell ideo2017 analyser quasitemps reel message candidat fournir principal caracteristiqueslusage lexiqu politique comparaison entrer candidat ideo2017 plateforme citoyen dediee lanalyse tweet evenement polit'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display pre-processed datas\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=sourceFST, use_idf=True, ngram_range=(min_gram, max_gram), max_df=max_frequ, min_df=min_appear)\n",
    "tfidf = vectorizer.fit_transform(usable)\n",
    "\n",
    "print(\"nombre d'articles =\", len(usable))\n",
    "print(\"nombre de mots =\", len(tfidf.toarray()[0]))\n",
    "print(\"limits =\", limits)\n",
    "\n",
    "usable[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of partitions_tfidf[], which give us the TFIDF of each cluster of each partition\n",
    "# partitions_tfidf[num_partition][num_doc][num_word]\n",
    "# Beware, num_doc can't be equals to 1091 (max). You have partitions, so every doc aren't in every partitions\n",
    "# num_word can be found via vectorizer.get_feature_name()\n",
    "partitions_tfidf = []\n",
    "beg = 0\n",
    "for l in limits:\n",
    "    last = l\n",
    "    partitions_tfidf.append([list(x) for x in list(tfidf.toarray())[beg:last]])\n",
    "    beg = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acce',\n",
       " 'accessible',\n",
       " 'achat',\n",
       " 'acquisition',\n",
       " 'acquérir',\n",
       " 'acteur',\n",
       " 'actif',\n",
       " 'action',\n",
       " 'activite',\n",
       " 'actuel',\n",
       " 'actuellement',\n",
       " 'adapt',\n",
       " 'adaptatif',\n",
       " 'adaptation',\n",
       " 'adapte',\n",
       " 'adaptee',\n",
       " 'adapter',\n",
       " 'adequat',\n",
       " 'adn',\n",
       " 'adopter',\n",
       " 'afc',\n",
       " 'affiner',\n",
       " 'agent',\n",
       " 'agregation',\n",
       " 'aid',\n",
       " 'aider',\n",
       " 'ainsiqu',\n",
       " 'ajoutee',\n",
       " 'ajouter',\n",
       " 'ala',\n",
       " 'aleatoir',\n",
       " 'algebriqu',\n",
       " 'algorithm',\n",
       " 'algorithm classification',\n",
       " 'algorithm dapprentissage',\n",
       " 'algorithm dextraction',\n",
       " 'algorithm efficace',\n",
       " 'algorithme',\n",
       " 'algorithme dapprentissage',\n",
       " 'algorithme dextraction',\n",
       " 'algorithme fouiller',\n",
       " 'algorithme incremental',\n",
       " 'algorithmique',\n",
       " 'alignement',\n",
       " 'alternatif',\n",
       " 'amelior',\n",
       " 'amelioration',\n",
       " 'ameliore',\n",
       " 'amelioree',\n",
       " 'ameliorer',\n",
       " 'ameliorer qualite',\n",
       " 'amene',\n",
       " 'amont',\n",
       " 'analys',\n",
       " 'analyse',\n",
       " 'analyser',\n",
       " 'analyser donnee',\n",
       " 'analyser factoriel',\n",
       " 'analyser semantiqu',\n",
       " 'analytique',\n",
       " 'anne',\n",
       " 'annees',\n",
       " 'annot',\n",
       " 'annotation',\n",
       " 'annotation semantiqu',\n",
       " 'annoter',\n",
       " 'anormal',\n",
       " 'anr',\n",
       " 'apartir',\n",
       " 'apparer',\n",
       " 'appartenir',\n",
       " 'appel',\n",
       " 'appele',\n",
       " 'appelee',\n",
       " 'appeler',\n",
       " 'applicable',\n",
       " 'applicatif',\n",
       " 'application',\n",
       " 'application donnee',\n",
       " 'application reell',\n",
       " 'appliqu',\n",
       " 'applique',\n",
       " 'appliquee',\n",
       " 'appliquees',\n",
       " 'appliquer',\n",
       " 'apport',\n",
       " 'apporter',\n",
       " 'apprehender',\n",
       " 'apprendre',\n",
       " 'apprentissage',\n",
       " 'apprentissage automatique',\n",
       " 'apprentissage supervis',\n",
       " 'approche',\n",
       " 'approche existant',\n",
       " 'appropriee',\n",
       " 'approprier',\n",
       " 'approximatif',\n",
       " 'approximation',\n",
       " 'apr',\n",
       " 'aprer',\n",
       " 'arbitraire',\n",
       " 'arborescent',\n",
       " 'arbre',\n",
       " 'arbre decision',\n",
       " 'architecturer',\n",
       " 'article',\n",
       " 'article decrit',\n",
       " 'article etuder',\n",
       " 'article etudie',\n",
       " 'article interesser',\n",
       " 'article introduire',\n",
       " 'article method',\n",
       " 'article methode',\n",
       " 'article montrer',\n",
       " 'article present',\n",
       " 'article present method',\n",
       " 'article present methode',\n",
       " 'article presenter',\n",
       " 'article presenter method',\n",
       " 'article presenton',\n",
       " 'article proposer',\n",
       " 'article proposer method',\n",
       " 'article proposer methode',\n",
       " 'article proposer methodologie',\n",
       " 'article traire',\n",
       " 'articlenou',\n",
       " 'artificiel',\n",
       " 'ascendant',\n",
       " 'ascendant hierarchiqu',\n",
       " 'aspect',\n",
       " 'assister',\n",
       " 'associ',\n",
       " 'association',\n",
       " 'associe',\n",
       " 'associee',\n",
       " 'associeer',\n",
       " 'associees',\n",
       " 'associer',\n",
       " 'assurer',\n",
       " 'attaquer',\n",
       " 'atteindre',\n",
       " 'attention',\n",
       " 'attribu',\n",
       " 'attribut',\n",
       " 'atypique',\n",
       " 'augmenter',\n",
       " 'automat',\n",
       " 'automate',\n",
       " 'automatique',\n",
       " 'automatiquement',\n",
       " 'automatiser',\n",
       " 'autoorganisatrice',\n",
       " 'autour',\n",
       " 'avancee',\n",
       " 'avantage',\n",
       " 'axe',\n",
       " 'axer',\n",
       " 'axiome',\n",
       " 'baptis',\n",
       " 'base',\n",
       " 'base donnee',\n",
       " 'base donnee relationnel',\n",
       " 'base donneer',\n",
       " 'baseesur',\n",
       " 'baser',\n",
       " 'baser connaissance',\n",
       " 'baser dapprentissage',\n",
       " 'baser donne',\n",
       " 'baser donneer',\n",
       " 'baser modele',\n",
       " 'baser technique',\n",
       " 'batch',\n",
       " 'bayesien',\n",
       " 'bayesien naïf',\n",
       " 'bayesienn',\n",
       " 'benchmark',\n",
       " 'beneficier',\n",
       " 'besoin',\n",
       " 'biais',\n",
       " 'bibliographique',\n",
       " 'biclustering',\n",
       " 'binaire',\n",
       " 'bioinformatique',\n",
       " 'biologique',\n",
       " 'biomedical',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'booleenn',\n",
       " 'boosting',\n",
       " 'born',\n",
       " 'bruitees',\n",
       " 'brut',\n",
       " 'cadrer',\n",
       " 'cadrer article',\n",
       " 'cadrer classification',\n",
       " 'cadrer general',\n",
       " 'cadrer lanalyse',\n",
       " 'cadrer projet',\n",
       " 'cadrer rechercher',\n",
       " 'cadrer theoriqu',\n",
       " 'cadrer travail',\n",
       " 'calcul',\n",
       " 'calcul similarite',\n",
       " 'calculee',\n",
       " 'calculer',\n",
       " 'campagne',\n",
       " 'cancer',\n",
       " 'candidat',\n",
       " 'capable',\n",
       " 'capacite',\n",
       " 'capteur',\n",
       " 'capturer',\n",
       " 'caracter',\n",
       " 'caractere',\n",
       " 'caracterisation',\n",
       " 'caracterise',\n",
       " 'caracteriseer',\n",
       " 'caracteriser',\n",
       " 'caracteristiqu',\n",
       " 'caracteristique',\n",
       " 'caracteristiquer',\n",
       " 'cart',\n",
       " 'carte',\n",
       " 'carte autoorganisatrice',\n",
       " 'carte topologique',\n",
       " 'cartographie',\n",
       " 'cartographique',\n",
       " 'cas',\n",
       " 'cas donnee',\n",
       " 'categorie',\n",
       " 'categoriel',\n",
       " 'categoriell',\n",
       " 'categorisation',\n",
       " 'causer',\n",
       " 'celer',\n",
       " 'celer proposer',\n",
       " 'cell',\n",
       " 'celleci',\n",
       " 'cellesci',\n",
       " 'cellule',\n",
       " 'celuici',\n",
       " 'centaine',\n",
       " 'central',\n",
       " 'centree',\n",
       " 'centrer',\n",
       " 'cesser',\n",
       " 'cestadir',\n",
       " 'chain',\n",
       " 'chaine',\n",
       " 'chaine markov',\n",
       " 'challenge',\n",
       " 'champ',\n",
       " 'changement',\n",
       " 'changer',\n",
       " 'charger',\n",
       " 'chemin',\n",
       " 'chercher',\n",
       " 'chercheur',\n",
       " 'choisir',\n",
       " 'choix',\n",
       " 'choix mesurer',\n",
       " 'chronique',\n",
       " 'cibl',\n",
       " 'cibler',\n",
       " 'clairement',\n",
       " 'classe',\n",
       " 'classement',\n",
       " 'classer',\n",
       " 'classificateur',\n",
       " 'classification',\n",
       " 'classification automatique',\n",
       " 'classification croise',\n",
       " 'classification document',\n",
       " 'classification donnee',\n",
       " 'classification hierarchiqu',\n",
       " 'classification multilabel',\n",
       " 'classification supervise',\n",
       " 'classification supervisee',\n",
       " 'classifier',\n",
       " 'classifieur',\n",
       " 'classifieur bayesien',\n",
       " 'classifieur bayesien naïf',\n",
       " 'classique',\n",
       " 'cle',\n",
       " 'clef',\n",
       " 'client',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'coclustering',\n",
       " 'codage',\n",
       " 'coefficient',\n",
       " 'coeur',\n",
       " 'cognitif',\n",
       " 'coherence',\n",
       " 'collaboratif',\n",
       " 'collaboration',\n",
       " 'collecter',\n",
       " 'collectif',\n",
       " 'collection',\n",
       " 'collection document',\n",
       " 'colonne',\n",
       " 'combin',\n",
       " 'combinaison',\n",
       " 'combinatoire',\n",
       " 'combiner',\n",
       " 'commencer',\n",
       " 'commercial',\n",
       " 'commun',\n",
       " 'communaut',\n",
       " 'communautair',\n",
       " 'communautaire',\n",
       " 'communaute',\n",
       " 'communication',\n",
       " 'compact',\n",
       " 'compacter',\n",
       " 'comparaison',\n",
       " 'comparaison entrer',\n",
       " 'comparatif',\n",
       " 'comparee',\n",
       " 'comparer',\n",
       " 'comparer resultat',\n",
       " 'compatible',\n",
       " 'competence',\n",
       " 'complementair',\n",
       " 'complementarite',\n",
       " 'complet',\n",
       " 'completer',\n",
       " 'complex',\n",
       " 'complexe',\n",
       " 'complexit',\n",
       " 'complexite',\n",
       " 'comportement',\n",
       " 'comportemer',\n",
       " 'comporter',\n",
       " 'composant',\n",
       " 'compose',\n",
       " 'composer',\n",
       " 'comprehension',\n",
       " 'comprendre',\n",
       " 'compromis',\n",
       " 'compromis entrer',\n",
       " 'compter',\n",
       " 'concentrer',\n",
       " 'concept',\n",
       " 'concept treillis',\n",
       " 'concepteur',\n",
       " 'conception',\n",
       " 'conceptuel',\n",
       " 'concerner',\n",
       " 'concevoir',\n",
       " 'concis',\n",
       " 'conclure',\n",
       " 'conclusion',\n",
       " 'concret',\n",
       " 'condensee',\n",
       " 'condensees',\n",
       " 'condition',\n",
       " 'conditionnel',\n",
       " 'conduire',\n",
       " 'conferenc',\n",
       " 'conference',\n",
       " 'confiance',\n",
       " 'configuration',\n",
       " 'confirmer',\n",
       " 'conflit',\n",
       " 'confronter',\n",
       " 'conjoint',\n",
       " 'conjointement',\n",
       " 'connaiss',\n",
       " 'connaissance',\n",
       " 'connaissance baser',\n",
       " 'connaissance domaine',\n",
       " 'connaissance expert',\n",
       " 'connaissance partir',\n",
       " 'connaissance partir donnee',\n",
       " 'connaissance priori',\n",
       " 'connaissancer',\n",
       " 'connaître',\n",
       " 'connexion',\n",
       " 'connu',\n",
       " 'consequent',\n",
       " 'conserver',\n",
       " 'consider',\n",
       " 'considere',\n",
       " 'consideree',\n",
       " 'considerer',\n",
       " 'consist',\n",
       " 'consister',\n",
       " 'consommation',\n",
       " 'constant',\n",
       " 'constater',\n",
       " 'constituer',\n",
       " 'construction',\n",
       " 'construction automatique',\n",
       " 'construction darbr',\n",
       " 'construction dontologie',\n",
       " 'construir',\n",
       " 'construire',\n",
       " 'construire partir',\n",
       " 'construit',\n",
       " 'construit partir',\n",
       " 'contenir',\n",
       " 'contenir document',\n",
       " 'contenu',\n",
       " 'context',\n",
       " 'contexte',\n",
       " 'contextuel',\n",
       " 'contingence',\n",
       " 'continu',\n",
       " 'continuer',\n",
       " 'contraindre',\n",
       " 'contraint',\n",
       " 'contrainte',\n",
       " 'contrairement',\n",
       " 'contribuer',\n",
       " 'contribution',\n",
       " 'controle',\n",
       " 'controler',\n",
       " 'convergence',\n",
       " 'convier',\n",
       " 'conçu',\n",
       " 'cooperativ',\n",
       " 'corpu',\n",
       " 'corpus',\n",
       " 'correct',\n",
       " 'correctement',\n",
       " 'correlation',\n",
       " 'correlation entrer',\n",
       " 'correspondance',\n",
       " 'correspondance afc',\n",
       " 'correspondance entrer',\n",
       " 'correspondant',\n",
       " 'correspondre',\n",
       " 'couleur',\n",
       " 'coupl',\n",
       " 'couple',\n",
       " 'coupler',\n",
       " 'courir',\n",
       " 'courir temps',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'couverture',\n",
       " 'couvrir',\n",
       " 'coût',\n",
       " 'coûteux',\n",
       " 'creation',\n",
       " 'cree',\n",
       " 'creer',\n",
       " 'criter',\n",
       " 'critere',\n",
       " 'critere devaluation',\n",
       " 'croise',\n",
       " 'croisee',\n",
       " 'croiser',\n",
       " 'croissance',\n",
       " 'croyance',\n",
       " 'croître',\n",
       " 'cube',\n",
       " 'cuber',\n",
       " 'culturel',\n",
       " 'cycle',\n",
       " 'dabord',\n",
       " 'daccelerer',\n",
       " 'dacquisition',\n",
       " 'dadapter',\n",
       " 'dagregation',\n",
       " 'daid',\n",
       " 'daid decision',\n",
       " 'daider',\n",
       " 'dalgorithme',\n",
       " 'dalignemer',\n",
       " 'dameliorer',\n",
       " 'dameliorer performance',\n",
       " 'danalyse',\n",
       " 'danalyser',\n",
       " 'dannotation',\n",
       " 'danscet',\n",
       " 'danscet article',\n",
       " 'danscet article proposer',\n",
       " 'dansl',\n",
       " 'dansun',\n",
       " 'dappariemer',\n",
       " 'dapparition',\n",
       " 'dappartenance',\n",
       " 'dapplication',\n",
       " 'dapporter',\n",
       " 'dapprendre',\n",
       " 'dapprentissage',\n",
       " 'dapprentissage automatique',\n",
       " 'dapprentissage supervis',\n",
       " 'darbr',\n",
       " 'darbr decision',\n",
       " 'darticl',\n",
       " 'dassoci',\n",
       " 'dassociation',\n",
       " 'dater',\n",
       " 'dater mining',\n",
       " 'dater stream',\n",
       " 'dattribut',\n",
       " 'dattributs',\n",
       " 'daugmenter',\n",
       " 'dautre',\n",
       " 'dautre partir',\n",
       " 'debut',\n",
       " 'decd',\n",
       " 'decennie',\n",
       " 'dechantillon',\n",
       " 'dechantillonnage',\n",
       " 'decider',\n",
       " 'decideur',\n",
       " 'decis',\n",
       " 'decision',\n",
       " 'decisionnel',\n",
       " 'decisionnell',\n",
       " 'decomposition',\n",
       " 'decoupage',\n",
       " 'decouvert',\n",
       " 'decouverte',\n",
       " 'decouverte motif',\n",
       " 'decouvrir',\n",
       " 'decouvrir motif',\n",
       " 'decrir',\n",
       " 'decrire',\n",
       " 'decrit',\n",
       " 'decrite',\n",
       " 'decrivant',\n",
       " 'decriver',\n",
       " 'decrivons',\n",
       " 'dedie',\n",
       " 'dediee',\n",
       " 'dedition',\n",
       " 'dedonnee',\n",
       " 'deduire',\n",
       " 'defaut',\n",
       " 'deffectuer',\n",
       " 'defi',\n",
       " 'defi egc',\n",
       " 'defini',\n",
       " 'definie',\n",
       " 'definier',\n",
       " 'definir',\n",
       " 'definis',\n",
       " 'definisser',\n",
       " 'definissons',\n",
       " 'definit',\n",
       " 'definition',\n",
       " 'degager',\n",
       " 'degr',\n",
       " 'degre',\n",
       " 'delagage',\n",
       " 'delement',\n",
       " 'demander',\n",
       " 'demarch',\n",
       " 'demonstration',\n",
       " 'denrichir',\n",
       " 'dense',\n",
       " 'densembl',\n",
       " 'densite',\n",
       " 'dentiter',\n",
       " 'dentre',\n",
       " 'dentrepris',\n",
       " 'depart',\n",
       " 'dependanc',\n",
       " 'dependance',\n",
       " 'dependance fonctionnel',\n",
       " 'depender',\n",
       " 'deper',\n",
       " 'dequivalence',\n",
       " 'derive',\n",
       " 'derreur',\n",
       " 'descripteur',\n",
       " 'descriptif',\n",
       " 'description',\n",
       " 'desdonnee',\n",
       " 'desequilibre',\n",
       " 'destimer',\n",
       " 'detablir',\n",
       " 'detailler',\n",
       " 'detat',\n",
       " 'detecter',\n",
       " 'detection',\n",
       " 'detection changement',\n",
       " 'detectiond',\n",
       " 'detendre',\n",
       " 'determination',\n",
       " 'determine',\n",
       " 'determiner',\n",
       " 'detr',\n",
       " 'detre',\n",
       " 'detude',\n",
       " 'detudier',\n",
       " 'deuxieme',\n",
       " 'devaluation',\n",
       " 'devaluer',\n",
       " 'devaluer qualite',\n",
       " 'developp',\n",
       " 'developpe',\n",
       " 'developpee',\n",
       " 'developpement',\n",
       " 'developpemer',\n",
       " 'developper',\n",
       " 'devenement',\n",
       " 'devenir',\n",
       " 'devenir plaire',\n",
       " 'devoir',\n",
       " 'devoir permettre',\n",
       " 'devolution',\n",
       " 'dexecution',\n",
       " 'dexempl',\n",
       " 'dexperience',\n",
       " 'dexperimentation',\n",
       " 'dexploiter',\n",
       " 'dexploration',\n",
       " 'dexplorer',\n",
       " 'dexpression',\n",
       " 'dexprimer',\n",
       " 'dextraction',\n",
       " 'dextraction connaissance',\n",
       " 'dextraction connaissance partir',\n",
       " 'dextraction motif',\n",
       " 'dextrair',\n",
       " 'dextraire',\n",
       " 'dheuristiqu',\n",
       " 'diagnostic',\n",
       " 'dictionnair',\n",
       " 'didentification',\n",
       " 'didentifier',\n",
       " 'difference',\n",
       " 'differenter',\n",
       " 'difficile',\n",
       " 'difficilement',\n",
       " 'difficult',\n",
       " 'difficulte',\n",
       " 'diffusion',\n",
       " 'dimag',\n",
       " 'dimage',\n",
       " 'dimager',\n",
       " 'dimension',\n",
       " 'dincertitude',\n",
       " 'dindexation',\n",
       " 'dindice',\n",
       " 'dindividus',\n",
       " 'dinduction',\n",
       " 'dinference',\n",
       " 'dinferer',\n",
       " 'dinfluence',\n",
       " 'dinform',\n",
       " 'dinformation',\n",
       " 'dintegration',\n",
       " 'dintegrer',\n",
       " 'dinteraction',\n",
       " 'dinteraction entrer',\n",
       " 'dinteret',\n",
       " 'dinternet',\n",
       " 'dinterpretation',\n",
       " 'dinterrogation',\n",
       " 'dintroduir',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'discret',\n",
       " 'discretisation',\n",
       " 'discriminant',\n",
       " 'discriminanter',\n",
       " 'discrimination',\n",
       " 'discriminer',\n",
       " 'discussion',\n",
       " 'discuter',\n",
       " 'disponible',\n",
       " 'disposer',\n",
       " 'dispositif',\n",
       " 'disposition',\n",
       " 'dissimilarit',\n",
       " 'dissimilarite',\n",
       " 'dissimilarite entrer',\n",
       " 'distance',\n",
       " 'distancer',\n",
       " 'distancer entrer',\n",
       " 'distinct',\n",
       " 'distinguer',\n",
       " 'distribu',\n",
       " 'distribuer',\n",
       " 'distribution',\n",
       " 'ditems',\n",
       " 'ditemset',\n",
       " 'ditemset frequent',\n",
       " 'diversite',\n",
       " 'diviser',\n",
       " 'dizaine',\n",
       " 'dobjet',\n",
       " 'dobjets',\n",
       " 'dobtenir',\n",
       " 'docu',\n",
       " 'document',\n",
       " 'document textuel',\n",
       " 'document xml',\n",
       " 'documentaire',\n",
       " 'doffr',\n",
       " 'domaine',\n",
       " 'domaine dapplication',\n",
       " 'domaine fouiller',\n",
       " 'domaine lapprentissage',\n",
       " 'donne',\n",
       " 'donnee',\n",
       " 'donnee article',\n",
       " 'donnee artificiel',\n",
       " 'donnee baser',\n",
       " 'donnee cluster',\n",
       " 'donnee disponible',\n",
       " 'donnee geographiqu',\n",
       " 'donnee grand',\n",
       " 'donnee issu',\n",
       " 'donnee massif',\n",
       " 'donnee multidimensionnel',\n",
       " 'donnee numeriqu',\n",
       " 'donnee permettre',\n",
       " 'donnee plaire',\n",
       " 'donnee pouvoir',\n",
       " 'donnee presenter',\n",
       " 'donnee qualitatif',\n",
       " 'donnee reel',\n",
       " 'donnee reell',\n",
       " 'donnee reell issu',\n",
       " 'donnee reell montrer',\n",
       " 'donnee relationnel',\n",
       " 'donnee sequentiell',\n",
       " 'donnee simuleer',\n",
       " 'donnee symbolique',\n",
       " 'donnee synthetiqu',\n",
       " 'donnee textuel',\n",
       " 'donnee visualisation',\n",
       " 'donneer',\n",
       " 'donneer article',\n",
       " 'donneer luci',\n",
       " 'donneer plaire',\n",
       " 'donneer reell',\n",
       " 'donneer textuel',\n",
       " 'donnees',\n",
       " 'donner',\n",
       " 'donner resultat',\n",
       " 'dontologie',\n",
       " 'dontologie partir',\n",
       " 'dontologier',\n",
       " 'dopinion',\n",
       " 'doptimisation',\n",
       " 'dordre',\n",
       " 'dorigine',\n",
       " 'doter',\n",
       " 'doutil',\n",
       " 'doutils',\n",
       " 'duree',\n",
       " 'durer',\n",
       " 'durer processus',\n",
       " 'dusage',\n",
       " 'dutilisateur',\n",
       " 'dutilisation',\n",
       " 'dutiliser',\n",
       " 'dynam',\n",
       " 'dynamique',\n",
       " 'ecd',\n",
       " 'echantillon',\n",
       " 'echantillonnage',\n",
       " 'echell',\n",
       " 'echelle',\n",
       " 'eclairage',\n",
       " 'economiqu',\n",
       " 'effectu',\n",
       " 'efficace',\n",
       " 'efficacement',\n",
       " 'efficacite',\n",
       " 'effort',\n",
       " 'egc',\n",
       " 'element',\n",
       " 'elev',\n",
       " 'eleve',\n",
       " 'elevee',\n",
       " 'emergent',\n",
       " 'empirique',\n",
       " 'empiriquement',\n",
       " 'employer',\n",
       " 'encompte',\n",
       " 'encourageant',\n",
       " 'encourageant prometteur',\n",
       " 'engendrer',\n",
       " 'enjeu',\n",
       " 'enjeu majeur',\n",
       " 'enregistrement',\n",
       " 'enrichir',\n",
       " 'enrichissement',\n",
       " 'ensembl',\n",
       " 'ensembl donnee',\n",
       " 'ensembl donneer',\n",
       " 'ensembl mesure',\n",
       " 'ensemble',\n",
       " 'ensemble donnee',\n",
       " 'ensemble donneer',\n",
       " 'ensemble regl',\n",
       " 'ensembliste',\n",
       " 'entite',\n",
       " 'entrainer',\n",
       " 'entrepot',\n",
       " 'entrepot donnee',\n",
       " 'entreprendre',\n",
       " 'entreprise',\n",
       " 'entrer',\n",
       " 'entrer attribut',\n",
       " 'entrer classe',\n",
       " 'entrer concept',\n",
       " 'entrer donnee',\n",
       " 'entrer ensemble',\n",
       " 'entrer groupe',\n",
       " 'entrer individu',\n",
       " 'entrer objet',\n",
       " 'entrer ontologie',\n",
       " 'entrer variable',\n",
       " 'environnement',\n",
       " 'envisageable',\n",
       " 'equivalent',\n",
       " 'erreur',\n",
       " 'espac',\n",
       " 'espace',\n",
       " 'espacer',\n",
       " 'essentiel',\n",
       " 'essentiellement',\n",
       " 'estim',\n",
       " 'estimateur',\n",
       " 'estimation',\n",
       " 'estimation densite',\n",
       " 'estimee',\n",
       " 'estimer',\n",
       " 'etablie',\n",
       " 'etablir',\n",
       " 'etablisser',\n",
       " 'etape',\n",
       " 'etat',\n",
       " 'etde',\n",
       " 'etendu',\n",
       " 'eter',\n",
       " 'etiquetage',\n",
       " 'etiquete',\n",
       " 'etl',\n",
       " 'etle',\n",
       " 'etroitement',\n",
       " 'etude',\n",
       " 'etude comparatif',\n",
       " 'etude experimental',\n",
       " 'etuder',\n",
       " 'etudie',\n",
       " 'etudiee',\n",
       " 'etudier',\n",
       " 'euclidien',\n",
       " 'evalu',\n",
       " 'evaluation',\n",
       " 'evalue',\n",
       " 'evaluee',\n",
       " 'evaluees',\n",
       " 'evaluer',\n",
       " 'evenement',\n",
       " 'evidence',\n",
       " 'eviter',\n",
       " 'evoluer',\n",
       " 'evolution',\n",
       " 'evolutiv',\n",
       " 'exact',\n",
       " 'examiner',\n",
       " 'exemple',\n",
       " 'exhaustif',\n",
       " 'exhiber',\n",
       " 'existant',\n",
       " 'exister',\n",
       " 'exister entrer',\n",
       " 'experience',\n",
       " 'experience meneer',\n",
       " 'experience montrer',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experimentalement',\n",
       " 'experimentation',\n",
       " 'experimentation jeu',\n",
       " 'experimentation jeu donnee',\n",
       " 'experimentation menee',\n",
       " 'experimentation montrer',\n",
       " 'experimentaux',\n",
       " 'experimentaux montrer',\n",
       " 'expert',\n",
       " 'expert domaine',\n",
       " 'explicatif',\n",
       " 'expliciter',\n",
       " 'expliquer',\n",
       " 'exploitable',\n",
       " 'exploitation',\n",
       " 'exploiter',\n",
       " 'exploration',\n",
       " 'exploratoire',\n",
       " 'explorer',\n",
       " 'exponentiel',\n",
       " 'exposer',\n",
       " 'expression',\n",
       " 'exprimeer',\n",
       " 'exprimer',\n",
       " 'extension',\n",
       " 'extraction',\n",
       " 'extraction connaissance',\n",
       " 'extraction motif',\n",
       " 'extraction regl',\n",
       " 'extraire',\n",
       " 'extraire connaissance',\n",
       " 'extraire motif',\n",
       " 'extrait',\n",
       " 'extraite',\n",
       " 'face',\n",
       " 'facile',\n",
       " 'facilement',\n",
       " 'faciliter',\n",
       " 'facteur',\n",
       " 'factoriel',\n",
       " 'factoriel correspondance',\n",
       " 'factoriel correspondance afc',\n",
       " 'factorisation',\n",
       " 'faible',\n",
       " 'faire',\n",
       " 'faire appel',\n",
       " 'faire face',\n",
       " 'faire lobjet',\n",
       " 'faire partir',\n",
       " 'faisabilite',\n",
       " 'famille',\n",
       " 'favoriser',\n",
       " 'feature',\n",
       " 'ferme',\n",
       " 'ferme frequent',\n",
       " 'fiabilite',\n",
       " 'fiable',\n",
       " 'fichier',\n",
       " 'filtrage',\n",
       " 'filtrer',\n",
       " 'fin',\n",
       " 'final',\n",
       " 'finalement',\n",
       " 'financier',\n",
       " 'fixe',\n",
       " 'fixer',\n",
       " 'flexible',\n",
       " 'flot',\n",
       " 'flot donneer',\n",
       " 'flou',\n",
       " 'flouer',\n",
       " 'flux',\n",
       " 'flux donne',\n",
       " 'flux donnee',\n",
       " 'flux donneer',\n",
       " 'focaliser',\n",
       " 'fonction',\n",
       " 'fonction croyance',\n",
       " 'fonctionnalite',\n",
       " 'fonctionnel',\n",
       " 'fonctionnement',\n",
       " 'fonctionner',\n",
       " 'fond',\n",
       " 'fondamental',\n",
       " 'fondee',\n",
       " 'fondre',\n",
       " 'foret',\n",
       " 'foret aleatoir',\n",
       " 'formalisation',\n",
       " 'formaliser',\n",
       " 'formalisme',\n",
       " 'format',\n",
       " 'formation',\n",
       " 'forme',\n",
       " 'formel',\n",
       " 'formel concept',\n",
       " 'former',\n",
       " 'former regl',\n",
       " 'formulation',\n",
       " 'formuler',\n",
       " 'fort',\n",
       " 'fortement',\n",
       " 'fouill',\n",
       " 'fouill donneer',\n",
       " 'fouiller',\n",
       " 'fouiller donne',\n",
       " 'fouiller donnee',\n",
       " 'fouiller donneer',\n",
       " 'fouiller grand',\n",
       " 'fouiller texter',\n",
       " 'fournir',\n",
       " 'framework',\n",
       " 'france',\n",
       " 'français',\n",
       " 'frequence',\n",
       " 'frequent',\n",
       " 'frequente',\n",
       " 'fusion',\n",
       " 'futur',\n",
       " 'gain',\n",
       " 'galoi',\n",
       " 'garantir',\n",
       " 'gen',\n",
       " 'gene',\n",
       " 'gener',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans & Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeans on tfidf\n",
    "# the labels_ give assignment of doc to the cluster number \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_clustering is a dictionnary \n",
    "# it looks like -> { doc_number : [partition_number, cluster_number] }\n",
    "# This is used to reassign doc number to their respective partition and and cluster\n",
    "\n",
    "def kmeans(nb_clusters):\n",
    "    doc_clustering = {}\n",
    "    \n",
    "    km = KMeans(n_clusters=nb_clusters)\n",
    "\n",
    "    # Silhouette score mean\n",
    "    silhouette_mean = 0\n",
    "\n",
    "    numDoc = 0\n",
    "    for i in range(0, len(limits)):\n",
    "        dash = km.fit(partitions_tfidf[i])\n",
    "\n",
    "        # Silhouette\n",
    "        silhouette_mean += silhouette_score(partitions_tfidf[i], dash.labels_)\n",
    "\n",
    "        previousBound = 0\n",
    "        if i > 0:\n",
    "            previousBound = limits[i-1]\n",
    "        for numDocItern in range(0, limits[i]-previousBound):\n",
    "            doc_clustering[numDoc] = [i, dash.labels_[numDocItern]]\n",
    "            numDoc+=1\n",
    "\n",
    "    silhouette_mean = silhouette_mean / len(limits)\n",
    "    res = {}\n",
    "    res[\"silhouette\"] = silhouette_mean\n",
    "    res[\"clustering\"] = doc_clustering\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Silhouette Score for each number of cluster\n",
    "\n",
    "silhouette_by_cluster_nb = {}\n",
    "\n",
    "for nb_clusters in cluster_ranges:\n",
    "    silhouette_avg = 0\n",
    "    for trial in range(0, nb_trial_by_test):\n",
    "        km = kmeans(nb_clusters)\n",
    "        silhouette_avg += km[\"silhouette\"]\n",
    "    silhouette_avg = silhouette_avg / nb_trial_by_test\n",
    "    silhouette_by_cluster_nb[nb_clusters] = silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.005882146665734803,\n",
       " 3: 0.006156141086458524,\n",
       " 4: 0.006877380275053656,\n",
       " 5: 0.008156031106938277,\n",
       " 6: 0.008297116927823969,\n",
       " 7: 0.00848431407961979,\n",
       " 8: 0.01052726241457276,\n",
       " 9: 0.010710051761745581,\n",
       " 10: 0.012244922367287366,\n",
       " 11: 0.012355748241676652,\n",
       " 12: 0.01338943618125875,\n",
       " 13: 0.013506851247167778,\n",
       " 14: 0.014718522938735323,\n",
       " 15: 0.014850186317710531,\n",
       " 16: 0.015865536026335312,\n",
       " 17: 0.01708013375705329,\n",
       " 18: 0.018069627581797143,\n",
       " 19: 0.017640503603913074,\n",
       " 20: 0.018625730705663045,\n",
       " 21: 0.020159544012955295,\n",
       " 22: 0.020324998701204244,\n",
       " 23: 0.021201184275473507,\n",
       " 24: 0.021325736188046267,\n",
       " 25: 0.021553766271393354,\n",
       " 26: 0.022206857618850953,\n",
       " 27: 0.02334414403599976,\n",
       " 28: 0.024058370159133747,\n",
       " 29: 0.024108913191845893}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want silhouette scores to be high\n",
    "silhouette_by_cluster_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clustering = kmeans(5)[\"clustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to get list of documents number\n",
    "# return [dou numbers]\n",
    "# params : partition_number , cluster number\n",
    "def get_doc(part, clust):\n",
    "    docs = []\n",
    "    for i in range(0,len(doc_clustering)):\n",
    "        if doc_clustering[i][0] == part and doc_clustering[i][1] == clust:\n",
    "            docs.append(i)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the partitions variable\n",
    "# Here partitions[part][cluster] = list of docs numbe\n",
    "partitions = []\n",
    "for i in range(0, len(limits)):\n",
    "    clusters = []\n",
    "    for j in range(0, nb_clusters):\n",
    "        clusters.append(get_doc(i,j))\n",
    "    partitions.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 10, 16, 30, 35, 54, 69, 80, 82, 83, 84, 88, 89, 90, 100],\n",
       "  [1,\n",
       "   4,\n",
       "   12,\n",
       "   15,\n",
       "   18,\n",
       "   33,\n",
       "   34,\n",
       "   36,\n",
       "   41,\n",
       "   48,\n",
       "   49,\n",
       "   56,\n",
       "   58,\n",
       "   74,\n",
       "   75,\n",
       "   78,\n",
       "   85,\n",
       "   87,\n",
       "   92,\n",
       "   99,\n",
       "   108],\n",
       "  [2,\n",
       "   6,\n",
       "   13,\n",
       "   22,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   37,\n",
       "   38,\n",
       "   44,\n",
       "   46,\n",
       "   47,\n",
       "   51,\n",
       "   55,\n",
       "   61,\n",
       "   64,\n",
       "   66,\n",
       "   73,\n",
       "   86,\n",
       "   95,\n",
       "   96,\n",
       "   104,\n",
       "   107,\n",
       "   110,\n",
       "   111],\n",
       "  [0,\n",
       "   7,\n",
       "   14,\n",
       "   19,\n",
       "   20,\n",
       "   25,\n",
       "   26,\n",
       "   53,\n",
       "   62,\n",
       "   63,\n",
       "   67,\n",
       "   70,\n",
       "   76,\n",
       "   77,\n",
       "   79,\n",
       "   81,\n",
       "   93,\n",
       "   102,\n",
       "   103,\n",
       "   105,\n",
       "   113],\n",
       "  [3,\n",
       "   8,\n",
       "   9,\n",
       "   11,\n",
       "   17,\n",
       "   21,\n",
       "   23,\n",
       "   24,\n",
       "   31,\n",
       "   32,\n",
       "   39,\n",
       "   40,\n",
       "   42,\n",
       "   43,\n",
       "   45,\n",
       "   50,\n",
       "   52,\n",
       "   57,\n",
       "   59,\n",
       "   60,\n",
       "   65,\n",
       "   68,\n",
       "   71,\n",
       "   72,\n",
       "   91,\n",
       "   94,\n",
       "   97,\n",
       "   98,\n",
       "   101,\n",
       "   106,\n",
       "   109,\n",
       "   112],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[114,\n",
       "   141,\n",
       "   145,\n",
       "   150,\n",
       "   151,\n",
       "   159,\n",
       "   170,\n",
       "   175,\n",
       "   176,\n",
       "   181,\n",
       "   183,\n",
       "   186,\n",
       "   188,\n",
       "   193,\n",
       "   196,\n",
       "   198,\n",
       "   203,\n",
       "   216,\n",
       "   217,\n",
       "   223,\n",
       "   241,\n",
       "   252,\n",
       "   260,\n",
       "   261,\n",
       "   280,\n",
       "   290,\n",
       "   296,\n",
       "   298],\n",
       "  [115,\n",
       "   121,\n",
       "   123,\n",
       "   129,\n",
       "   137,\n",
       "   139,\n",
       "   140,\n",
       "   142,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   152,\n",
       "   154,\n",
       "   158,\n",
       "   163,\n",
       "   172,\n",
       "   174,\n",
       "   182,\n",
       "   187,\n",
       "   194,\n",
       "   195,\n",
       "   202,\n",
       "   208,\n",
       "   211,\n",
       "   212,\n",
       "   215,\n",
       "   218,\n",
       "   227,\n",
       "   232,\n",
       "   233,\n",
       "   235,\n",
       "   236,\n",
       "   245,\n",
       "   246,\n",
       "   254,\n",
       "   258,\n",
       "   263,\n",
       "   272,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   282,\n",
       "   285,\n",
       "   288,\n",
       "   289,\n",
       "   295,\n",
       "   297,\n",
       "   299],\n",
       "  [116,\n",
       "   117,\n",
       "   124,\n",
       "   126,\n",
       "   127,\n",
       "   131,\n",
       "   155,\n",
       "   157,\n",
       "   160,\n",
       "   161,\n",
       "   164,\n",
       "   166,\n",
       "   173,\n",
       "   177,\n",
       "   199,\n",
       "   222,\n",
       "   253,\n",
       "   266,\n",
       "   271,\n",
       "   273,\n",
       "   279,\n",
       "   284,\n",
       "   287,\n",
       "   294],\n",
       "  [119,\n",
       "   120,\n",
       "   122,\n",
       "   130,\n",
       "   132,\n",
       "   133,\n",
       "   144,\n",
       "   153,\n",
       "   156,\n",
       "   165,\n",
       "   167,\n",
       "   168,\n",
       "   178,\n",
       "   184,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   197,\n",
       "   201,\n",
       "   205,\n",
       "   206,\n",
       "   210,\n",
       "   214,\n",
       "   219,\n",
       "   221,\n",
       "   225,\n",
       "   226,\n",
       "   228,\n",
       "   229,\n",
       "   234,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   242,\n",
       "   244,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   256,\n",
       "   264,\n",
       "   265,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   283,\n",
       "   291,\n",
       "   292,\n",
       "   293],\n",
       "  [118,\n",
       "   125,\n",
       "   128,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   138,\n",
       "   143,\n",
       "   146,\n",
       "   162,\n",
       "   169,\n",
       "   171,\n",
       "   179,\n",
       "   180,\n",
       "   185,\n",
       "   192,\n",
       "   200,\n",
       "   204,\n",
       "   207,\n",
       "   209,\n",
       "   213,\n",
       "   220,\n",
       "   224,\n",
       "   230,\n",
       "   231,\n",
       "   237,\n",
       "   243,\n",
       "   255,\n",
       "   257,\n",
       "   259,\n",
       "   262,\n",
       "   274,\n",
       "   278,\n",
       "   281,\n",
       "   286,\n",
       "   300],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[306,\n",
       "   308,\n",
       "   313,\n",
       "   315,\n",
       "   318,\n",
       "   325,\n",
       "   331,\n",
       "   344,\n",
       "   345,\n",
       "   354,\n",
       "   359,\n",
       "   368,\n",
       "   372,\n",
       "   373,\n",
       "   374,\n",
       "   386,\n",
       "   402,\n",
       "   414,\n",
       "   421,\n",
       "   424,\n",
       "   439,\n",
       "   446,\n",
       "   456,\n",
       "   460,\n",
       "   465],\n",
       "  [309,\n",
       "   310,\n",
       "   312,\n",
       "   314,\n",
       "   319,\n",
       "   320,\n",
       "   337,\n",
       "   346,\n",
       "   353,\n",
       "   356,\n",
       "   358,\n",
       "   369,\n",
       "   370,\n",
       "   390,\n",
       "   398,\n",
       "   404,\n",
       "   409,\n",
       "   419,\n",
       "   420,\n",
       "   423,\n",
       "   427,\n",
       "   428,\n",
       "   431,\n",
       "   434,\n",
       "   436,\n",
       "   438,\n",
       "   440,\n",
       "   443,\n",
       "   445,\n",
       "   448],\n",
       "  [302,\n",
       "   303,\n",
       "   305,\n",
       "   311,\n",
       "   316,\n",
       "   321,\n",
       "   324,\n",
       "   326,\n",
       "   330,\n",
       "   332,\n",
       "   334,\n",
       "   335,\n",
       "   336,\n",
       "   338,\n",
       "   341,\n",
       "   343,\n",
       "   348,\n",
       "   349,\n",
       "   350,\n",
       "   357,\n",
       "   360,\n",
       "   361,\n",
       "   362,\n",
       "   364,\n",
       "   365,\n",
       "   366,\n",
       "   375,\n",
       "   376,\n",
       "   380,\n",
       "   383,\n",
       "   389,\n",
       "   391,\n",
       "   392,\n",
       "   394,\n",
       "   395,\n",
       "   397,\n",
       "   399,\n",
       "   406,\n",
       "   407,\n",
       "   408,\n",
       "   412,\n",
       "   413,\n",
       "   416,\n",
       "   432,\n",
       "   433,\n",
       "   435,\n",
       "   442,\n",
       "   450,\n",
       "   452,\n",
       "   453,\n",
       "   454,\n",
       "   458,\n",
       "   459,\n",
       "   462,\n",
       "   463,\n",
       "   464,\n",
       "   466],\n",
       "  [304,\n",
       "   322,\n",
       "   327,\n",
       "   328,\n",
       "   329,\n",
       "   339,\n",
       "   340,\n",
       "   342,\n",
       "   347,\n",
       "   352,\n",
       "   355,\n",
       "   371,\n",
       "   379,\n",
       "   382,\n",
       "   384,\n",
       "   385,\n",
       "   387,\n",
       "   388,\n",
       "   393,\n",
       "   396,\n",
       "   400,\n",
       "   401,\n",
       "   403,\n",
       "   405,\n",
       "   417,\n",
       "   418,\n",
       "   422,\n",
       "   425,\n",
       "   426,\n",
       "   429,\n",
       "   430,\n",
       "   441,\n",
       "   447,\n",
       "   451,\n",
       "   467],\n",
       "  [301,\n",
       "   307,\n",
       "   317,\n",
       "   323,\n",
       "   333,\n",
       "   351,\n",
       "   363,\n",
       "   367,\n",
       "   377,\n",
       "   378,\n",
       "   381,\n",
       "   410,\n",
       "   411,\n",
       "   415,\n",
       "   437,\n",
       "   444,\n",
       "   449,\n",
       "   455,\n",
       "   457,\n",
       "   461],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[472,\n",
       "   475,\n",
       "   484,\n",
       "   487,\n",
       "   491,\n",
       "   496,\n",
       "   497,\n",
       "   501,\n",
       "   503,\n",
       "   507,\n",
       "   508,\n",
       "   509,\n",
       "   510,\n",
       "   512,\n",
       "   517,\n",
       "   519,\n",
       "   521,\n",
       "   522,\n",
       "   524,\n",
       "   525,\n",
       "   527,\n",
       "   529,\n",
       "   541,\n",
       "   543,\n",
       "   559,\n",
       "   560,\n",
       "   575,\n",
       "   579,\n",
       "   580,\n",
       "   588,\n",
       "   591,\n",
       "   592,\n",
       "   594,\n",
       "   601,\n",
       "   608,\n",
       "   609,\n",
       "   611,\n",
       "   614,\n",
       "   616,\n",
       "   621,\n",
       "   630,\n",
       "   631,\n",
       "   634,\n",
       "   636,\n",
       "   641,\n",
       "   642,\n",
       "   643,\n",
       "   655,\n",
       "   656,\n",
       "   660,\n",
       "   661,\n",
       "   666,\n",
       "   673,\n",
       "   677,\n",
       "   688,\n",
       "   692],\n",
       "  [469,\n",
       "   471,\n",
       "   474,\n",
       "   478,\n",
       "   485,\n",
       "   486,\n",
       "   489,\n",
       "   494,\n",
       "   495,\n",
       "   500,\n",
       "   511,\n",
       "   533,\n",
       "   534,\n",
       "   535,\n",
       "   537,\n",
       "   544,\n",
       "   545,\n",
       "   546,\n",
       "   550,\n",
       "   552,\n",
       "   557,\n",
       "   558,\n",
       "   562,\n",
       "   567,\n",
       "   568,\n",
       "   578,\n",
       "   582,\n",
       "   583,\n",
       "   585,\n",
       "   595,\n",
       "   600,\n",
       "   603,\n",
       "   607,\n",
       "   613,\n",
       "   617,\n",
       "   622,\n",
       "   629,\n",
       "   633,\n",
       "   635,\n",
       "   637,\n",
       "   638,\n",
       "   644,\n",
       "   645,\n",
       "   647,\n",
       "   648,\n",
       "   649,\n",
       "   659,\n",
       "   667,\n",
       "   674,\n",
       "   681,\n",
       "   682,\n",
       "   685,\n",
       "   686],\n",
       "  [470,\n",
       "   477,\n",
       "   492,\n",
       "   498,\n",
       "   516,\n",
       "   523,\n",
       "   526,\n",
       "   528,\n",
       "   542,\n",
       "   563,\n",
       "   571,\n",
       "   590,\n",
       "   615,\n",
       "   620,\n",
       "   628,\n",
       "   657,\n",
       "   690],\n",
       "  [468,\n",
       "   473,\n",
       "   480,\n",
       "   490,\n",
       "   493,\n",
       "   499,\n",
       "   502,\n",
       "   513,\n",
       "   515,\n",
       "   518,\n",
       "   530,\n",
       "   536,\n",
       "   538,\n",
       "   540,\n",
       "   548,\n",
       "   554,\n",
       "   556,\n",
       "   564,\n",
       "   565,\n",
       "   572,\n",
       "   573,\n",
       "   577,\n",
       "   587,\n",
       "   589,\n",
       "   604,\n",
       "   606,\n",
       "   610,\n",
       "   619,\n",
       "   623,\n",
       "   624,\n",
       "   626,\n",
       "   627,\n",
       "   632,\n",
       "   639,\n",
       "   646,\n",
       "   651,\n",
       "   658,\n",
       "   662,\n",
       "   663,\n",
       "   670,\n",
       "   671,\n",
       "   675,\n",
       "   679,\n",
       "   689,\n",
       "   691,\n",
       "   693],\n",
       "  [476,\n",
       "   479,\n",
       "   481,\n",
       "   482,\n",
       "   483,\n",
       "   488,\n",
       "   504,\n",
       "   505,\n",
       "   506,\n",
       "   514,\n",
       "   520,\n",
       "   531,\n",
       "   532,\n",
       "   539,\n",
       "   547,\n",
       "   549,\n",
       "   551,\n",
       "   553,\n",
       "   555,\n",
       "   561,\n",
       "   566,\n",
       "   569,\n",
       "   570,\n",
       "   574,\n",
       "   576,\n",
       "   581,\n",
       "   584,\n",
       "   586,\n",
       "   593,\n",
       "   596,\n",
       "   597,\n",
       "   598,\n",
       "   599,\n",
       "   602,\n",
       "   605,\n",
       "   612,\n",
       "   618,\n",
       "   625,\n",
       "   640,\n",
       "   650,\n",
       "   652,\n",
       "   653,\n",
       "   654,\n",
       "   664,\n",
       "   665,\n",
       "   668,\n",
       "   669,\n",
       "   672,\n",
       "   676,\n",
       "   678,\n",
       "   680,\n",
       "   683,\n",
       "   684,\n",
       "   687],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []],\n",
       " [[697,\n",
       "   703,\n",
       "   713,\n",
       "   716,\n",
       "   719,\n",
       "   722,\n",
       "   737,\n",
       "   765,\n",
       "   778,\n",
       "   796,\n",
       "   803,\n",
       "   810,\n",
       "   834,\n",
       "   835,\n",
       "   840,\n",
       "   847,\n",
       "   882,\n",
       "   898,\n",
       "   922,\n",
       "   923,\n",
       "   927,\n",
       "   931,\n",
       "   932,\n",
       "   933,\n",
       "   935,\n",
       "   956,\n",
       "   970,\n",
       "   977,\n",
       "   980,\n",
       "   981,\n",
       "   985],\n",
       "  [694,\n",
       "   696,\n",
       "   698,\n",
       "   699,\n",
       "   700,\n",
       "   701,\n",
       "   708,\n",
       "   709,\n",
       "   710,\n",
       "   711,\n",
       "   712,\n",
       "   714,\n",
       "   715,\n",
       "   721,\n",
       "   730,\n",
       "   733,\n",
       "   738,\n",
       "   739,\n",
       "   740,\n",
       "   741,\n",
       "   742,\n",
       "   743,\n",
       "   744,\n",
       "   745,\n",
       "   750,\n",
       "   751,\n",
       "   752,\n",
       "   753,\n",
       "   757,\n",
       "   758,\n",
       "   759,\n",
       "   762,\n",
       "   764,\n",
       "   766,\n",
       "   768,\n",
       "   769,\n",
       "   770,\n",
       "   771,\n",
       "   773,\n",
       "   774,\n",
       "   775,\n",
       "   781,\n",
       "   783,\n",
       "   784,\n",
       "   785,\n",
       "   786,\n",
       "   788,\n",
       "   792,\n",
       "   794,\n",
       "   795,\n",
       "   797,\n",
       "   799,\n",
       "   800,\n",
       "   802,\n",
       "   804,\n",
       "   813,\n",
       "   816,\n",
       "   817,\n",
       "   821,\n",
       "   830,\n",
       "   831,\n",
       "   833,\n",
       "   836,\n",
       "   841,\n",
       "   844,\n",
       "   845,\n",
       "   848,\n",
       "   850,\n",
       "   852,\n",
       "   856,\n",
       "   857,\n",
       "   859,\n",
       "   866,\n",
       "   868,\n",
       "   869,\n",
       "   871,\n",
       "   872,\n",
       "   874,\n",
       "   875,\n",
       "   877,\n",
       "   878,\n",
       "   880,\n",
       "   886,\n",
       "   889,\n",
       "   892,\n",
       "   894,\n",
       "   901,\n",
       "   904,\n",
       "   905,\n",
       "   908,\n",
       "   916,\n",
       "   917,\n",
       "   918,\n",
       "   919,\n",
       "   920,\n",
       "   921,\n",
       "   924,\n",
       "   925,\n",
       "   926,\n",
       "   928,\n",
       "   930,\n",
       "   934,\n",
       "   936,\n",
       "   940,\n",
       "   944,\n",
       "   946,\n",
       "   947,\n",
       "   950,\n",
       "   952,\n",
       "   953,\n",
       "   957,\n",
       "   959,\n",
       "   960,\n",
       "   964,\n",
       "   965,\n",
       "   967,\n",
       "   969,\n",
       "   971,\n",
       "   972,\n",
       "   978,\n",
       "   979,\n",
       "   982,\n",
       "   983,\n",
       "   984,\n",
       "   986,\n",
       "   987],\n",
       "  [695,\n",
       "   707,\n",
       "   723,\n",
       "   724,\n",
       "   725,\n",
       "   732,\n",
       "   748,\n",
       "   749,\n",
       "   756,\n",
       "   767,\n",
       "   776,\n",
       "   782,\n",
       "   789,\n",
       "   798,\n",
       "   808,\n",
       "   812,\n",
       "   815,\n",
       "   823,\n",
       "   824,\n",
       "   865,\n",
       "   876,\n",
       "   879,\n",
       "   881,\n",
       "   887,\n",
       "   891,\n",
       "   895,\n",
       "   913,\n",
       "   914,\n",
       "   915,\n",
       "   929,\n",
       "   939,\n",
       "   942,\n",
       "   943,\n",
       "   955,\n",
       "   962,\n",
       "   968,\n",
       "   973],\n",
       "  [704,\n",
       "   705,\n",
       "   717,\n",
       "   718,\n",
       "   720,\n",
       "   726,\n",
       "   727,\n",
       "   728,\n",
       "   729,\n",
       "   731,\n",
       "   734,\n",
       "   735,\n",
       "   736,\n",
       "   755,\n",
       "   760,\n",
       "   763,\n",
       "   777,\n",
       "   780,\n",
       "   787,\n",
       "   790,\n",
       "   791,\n",
       "   793,\n",
       "   801,\n",
       "   807,\n",
       "   809,\n",
       "   811,\n",
       "   814,\n",
       "   818,\n",
       "   820,\n",
       "   822,\n",
       "   825,\n",
       "   827,\n",
       "   829,\n",
       "   832,\n",
       "   837,\n",
       "   842,\n",
       "   846,\n",
       "   851,\n",
       "   854,\n",
       "   855,\n",
       "   858,\n",
       "   860,\n",
       "   861,\n",
       "   863,\n",
       "   864,\n",
       "   867,\n",
       "   884,\n",
       "   885,\n",
       "   896,\n",
       "   899,\n",
       "   900,\n",
       "   902,\n",
       "   903,\n",
       "   906,\n",
       "   909,\n",
       "   910,\n",
       "   912,\n",
       "   937,\n",
       "   938,\n",
       "   945,\n",
       "   949,\n",
       "   951,\n",
       "   954,\n",
       "   958,\n",
       "   961,\n",
       "   966,\n",
       "   988,\n",
       "   989,\n",
       "   990],\n",
       "  [702,\n",
       "   706,\n",
       "   746,\n",
       "   747,\n",
       "   754,\n",
       "   761,\n",
       "   772,\n",
       "   779,\n",
       "   805,\n",
       "   806,\n",
       "   819,\n",
       "   826,\n",
       "   828,\n",
       "   838,\n",
       "   839,\n",
       "   843,\n",
       "   849,\n",
       "   853,\n",
       "   862,\n",
       "   870,\n",
       "   873,\n",
       "   883,\n",
       "   888,\n",
       "   890,\n",
       "   893,\n",
       "   897,\n",
       "   907,\n",
       "   911,\n",
       "   941,\n",
       "   948,\n",
       "   963,\n",
       "   974,\n",
       "   975,\n",
       "   976],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khi²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_of_your_word = tf[numDoc][strWord]\n",
    "tf = []\n",
    "for doc in usable:\n",
    "    tf_doc = {}\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        tf_doc[word] = doc.count(word)\n",
    "    tf.append(tf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number total of words\n",
    "# nb_total_word[numPartition]\n",
    "nb_total_word = []\n",
    "nb = 0\n",
    "\n",
    "for numDoc in range(0, len(usable)):\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        nb += tf[numDoc][word]\n",
    "    if numDoc+1 in limits:\n",
    "        nb_total_word.append(nb)\n",
    "        nb=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13017, 20640, 19717, 25286, 34465]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_total_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequentiell': 0,\n",
       " 'presenter methode': 0,\n",
       " 'projet anr': 0,\n",
       " 'dense': 0,\n",
       " 'complementarite': 0,\n",
       " 'exploitable': 0,\n",
       " 'apprentissage supervis': 0,\n",
       " 'probleme': 0,\n",
       " 'monder reel': 0,\n",
       " 'modularite': 0,\n",
       " 'dapprendre': 0,\n",
       " 'outrer': 0,\n",
       " 'celuici': 0,\n",
       " 'guidee': 0,\n",
       " 'protein': 0,\n",
       " 'futur': 0,\n",
       " 'gestion': 0,\n",
       " 'method dapprentissage': 0,\n",
       " 'tableau contingence': 0,\n",
       " 'nature': 0,\n",
       " 'meilleur qualite': 0,\n",
       " 'performance predictiv': 0,\n",
       " 'grand quantite': 0,\n",
       " 'compacter': 0,\n",
       " 'phraser': 0,\n",
       " 'proposer methode': 0,\n",
       " 'scenario': 0,\n",
       " 'linformation': 0,\n",
       " 'arbitraire': 0,\n",
       " 'distinguer': 0,\n",
       " 'daider': 0,\n",
       " 'maximal': 0,\n",
       " 'probleme difficile': 0,\n",
       " 'score': 0,\n",
       " 'reecriture': 0,\n",
       " 'pallier probleme': 0,\n",
       " 'fouiller donneer': 0,\n",
       " 'machiner': 0,\n",
       " 'lorganisation': 0,\n",
       " 'connaître': 0,\n",
       " 'acteur': 0,\n",
       " 'lanalys formel': 0,\n",
       " 'decennie': 0,\n",
       " 'classification croise': 0,\n",
       " 'capturer': 0,\n",
       " 'regl dassoci': 0,\n",
       " 'flouer': 0,\n",
       " 'ignorer': 0,\n",
       " 'preser': 0,\n",
       " 'pendre': 0,\n",
       " 'procedure': 0,\n",
       " 'debut': 0,\n",
       " 'multilabel': 0,\n",
       " 'problematiqu': 0,\n",
       " 'sinscrit': 0,\n",
       " 'profil utilisateur': 0,\n",
       " 'formuler': 0,\n",
       " 'permettre utilisateur': 0,\n",
       " 'decision': 0,\n",
       " 'reduire': 0,\n",
       " 'graphe conceptuel': 0,\n",
       " 'modele generatif': 0,\n",
       " 'poindre voir': 0,\n",
       " 'complexite': 0,\n",
       " 'problematique': 0,\n",
       " 'papier presente': 0,\n",
       " 'regle dassoci': 0,\n",
       " 'baser': 0,\n",
       " 'final': 0,\n",
       " 'amont': 0,\n",
       " 'mettre jour': 0,\n",
       " 'recherche': 0,\n",
       " 'difficulte': 0,\n",
       " 'hypothese': 0,\n",
       " 'supervis': 0,\n",
       " 'exhaustif': 0,\n",
       " 'calcul': 0,\n",
       " 'integration': 0,\n",
       " 'lancer': 0,\n",
       " 'plaire plaire': 0,\n",
       " 'batch': 0,\n",
       " 'lexploitation connaissance': 0,\n",
       " 'quune': 0,\n",
       " 'introduire': 0,\n",
       " 'grand ensembl donnee': 0,\n",
       " 'cas donnee': 0,\n",
       " 'donnee baser': 0,\n",
       " 'perdre': 0,\n",
       " 'classifier': 0,\n",
       " 'dapplication': 0,\n",
       " 'expert domaine': 0,\n",
       " 'lanalyse donnee': 0,\n",
       " 'retenir': 0,\n",
       " 'terminologie': 0,\n",
       " 'region': 0,\n",
       " 'lordre': 0,\n",
       " 'analyser donnee': 0,\n",
       " 'fort': 0,\n",
       " 'mis': 0,\n",
       " 'interaction entrer': 0,\n",
       " 'problem classification': 0,\n",
       " 'scor': 0,\n",
       " 'fonction': 0,\n",
       " 'dacquisition': 0,\n",
       " 'tester': 0,\n",
       " 'millier': 0,\n",
       " 'confiance': 0,\n",
       " 'illustrer': 0,\n",
       " 'lavantage': 0,\n",
       " 'plateforme': 2,\n",
       " 'comparaison entrer': 1,\n",
       " 'rechercheer': 0,\n",
       " 'issu': 0,\n",
       " 'fouiller': 0,\n",
       " 'devaluation': 0,\n",
       " 'contribuer': 0,\n",
       " 'obtenir resultat': 0,\n",
       " 'modelise': 0,\n",
       " 'danalyse': 0,\n",
       " 'collaboration': 0,\n",
       " 'actuellement': 0,\n",
       " 'genetiqu': 0,\n",
       " 'dansl': 0,\n",
       " 'decouvert': 0,\n",
       " 'ressource': 0,\n",
       " 'massif': 0,\n",
       " 'lineaire': 0,\n",
       " 'cuber': 0,\n",
       " 'recente': 0,\n",
       " 'baser donneer': 0,\n",
       " 'outil visualisation': 0,\n",
       " 'operation': 0,\n",
       " 'supposer': 0,\n",
       " 'matier': 0,\n",
       " 'volee': 0,\n",
       " 'ponder': 0,\n",
       " 'exact': 0,\n",
       " 'levaluation': 0,\n",
       " 'recent': 0,\n",
       " 'discuter': 0,\n",
       " 'approximatif': 0,\n",
       " 'page web': 0,\n",
       " 'devaluer qualite': 0,\n",
       " 'phrase': 0,\n",
       " 'heterogener': 0,\n",
       " 'schema': 0,\n",
       " 'annoter': 0,\n",
       " 'disposer': 0,\n",
       " 'donnee presenter': 0,\n",
       " 'entrer ensemble': 0,\n",
       " 'lapproche propose': 0,\n",
       " 'dapprentissage automatique': 0,\n",
       " 'connaissance priori': 0,\n",
       " 'iteration': 0,\n",
       " 'regle': 0,\n",
       " 'autoorganisatrice': 0,\n",
       " 'entreprendre': 0,\n",
       " 'dinternet': 0,\n",
       " 'dinfluence': 0,\n",
       " 'extraction regl': 0,\n",
       " 'champ': 0,\n",
       " 'permettre mettre': 0,\n",
       " 'terminologique': 0,\n",
       " 'resultat obtenir montrer': 0,\n",
       " 'inconvenient': 0,\n",
       " 'lespace representation': 0,\n",
       " 'dansun': 0,\n",
       " 'nonsupervis': 0,\n",
       " 'analyser': 1,\n",
       " 'moteur rechercher': 0,\n",
       " 'virtuel': 0,\n",
       " 'mem': 1,\n",
       " 'respecter': 0,\n",
       " 'p2p': 0,\n",
       " 'coefficient': 0,\n",
       " 'developp': 0,\n",
       " 'comprehension': 0,\n",
       " 'satellit': 0,\n",
       " 'conçu': 0,\n",
       " 'decrir': 0,\n",
       " 'lelaboration': 0,\n",
       " 'article method': 0,\n",
       " 'attribut': 0,\n",
       " 'preliminair': 0,\n",
       " 'contrairement': 0,\n",
       " 'resultat rechercher': 0,\n",
       " 'reell montrer': 0,\n",
       " 'sentir': 0,\n",
       " 'texter': 0,\n",
       " 'papier presenter': 0,\n",
       " 'hierarchi': 0,\n",
       " 'lutilisateur': 0,\n",
       " 'ensembl mesure': 0,\n",
       " 'instance': 0,\n",
       " 'dordre': 0,\n",
       " 'dextraction connaissance partir': 0,\n",
       " 'extraction': 0,\n",
       " 'fiabilite': 0,\n",
       " 'meilleur resultat': 0,\n",
       " 'orienter': 0,\n",
       " 'dexploration': 0,\n",
       " 'dinteraction': 0,\n",
       " 'comportemer': 0,\n",
       " 'expliquer': 0,\n",
       " 'poids': 0,\n",
       " 'moindre': 0,\n",
       " 'relier': 0,\n",
       " 'motif': 0,\n",
       " 'travail rechercher': 0,\n",
       " 'grand': 0,\n",
       " 'qualite': 0,\n",
       " 'dincertitude': 0,\n",
       " 'topologie': 0,\n",
       " 'uniforme': 0,\n",
       " 'lalgorithm proposer': 0,\n",
       " 'lapproche': 0,\n",
       " 'dameliorer': 0,\n",
       " 'risquer': 0,\n",
       " 'dynam': 0,\n",
       " 'graphe voisinage': 0,\n",
       " 'donnee permettre': 0,\n",
       " 'metier': 0,\n",
       " 'reseaux bayesien': 0,\n",
       " 'algebriqu': 0,\n",
       " 'jusquer': 0,\n",
       " 'etde': 0,\n",
       " 'scientifique': 0,\n",
       " 'opinion': 0,\n",
       " 'ontologique': 0,\n",
       " 'factoriel': 0,\n",
       " 'commencer': 0,\n",
       " 'collecter': 0,\n",
       " 'dexperimentation': 0,\n",
       " 'deuxieme': 0,\n",
       " 'associee': 0,\n",
       " 'lien': 0,\n",
       " 'experience': 0,\n",
       " 'local': 0,\n",
       " 'terme': 0,\n",
       " 'precedemment': 0,\n",
       " 'trer': 1,\n",
       " 'couverture': 0,\n",
       " 'jeu donnee reell': 0,\n",
       " 'avancee': 0,\n",
       " 'publication': 0,\n",
       " 'mettre disposition': 0,\n",
       " 'loutil': 0,\n",
       " 'defaut': 0,\n",
       " 'letude': 0,\n",
       " 'lorsquil': 0,\n",
       " 'adapt': 0,\n",
       " 'luire': 0,\n",
       " 'prendre compter': 0,\n",
       " 'constituer': 0,\n",
       " 'etablir': 0,\n",
       " 'mesurer dinteret': 0,\n",
       " 'permettre caracteriser': 0,\n",
       " 'constater': 0,\n",
       " 'format': 0,\n",
       " 'requérir': 0,\n",
       " 'linterrogation': 0,\n",
       " 'quils': 0,\n",
       " 'necessiter': 0,\n",
       " 'permettre dobtenir': 0,\n",
       " 'susciter': 0,\n",
       " 'sift': 0,\n",
       " 'article methode': 0,\n",
       " 'dontologie': 0,\n",
       " 'adn': 0,\n",
       " 'noeud': 0,\n",
       " 'conjointement': 0,\n",
       " 'programmation logique': 0,\n",
       " 'ensemble regl': 0,\n",
       " 'approximation': 0,\n",
       " 'lintegration': 0,\n",
       " 'generatif': 0,\n",
       " 'entrer ontologie': 0,\n",
       " 'estim': 0,\n",
       " 'permettre dameliorer': 0,\n",
       " 'processus dextraction connaissance': 0,\n",
       " 'usage': 1,\n",
       " 'ontologie domaine': 0,\n",
       " 'evolutiv': 0,\n",
       " 'decrire': 0,\n",
       " 'exponentiel': 0,\n",
       " 'applicable': 0,\n",
       " 'carte': 0,\n",
       " 'flou': 0,\n",
       " 'dusage': 0,\n",
       " 'traduire': 0,\n",
       " 'cle': 0,\n",
       " 'categorie': 0,\n",
       " 'separateur': 0,\n",
       " 'ajoutee': 0,\n",
       " 'graph voisinage': 0,\n",
       " 'mesurer similarite': 0,\n",
       " 'prendre': 0,\n",
       " 'experimentation': 0,\n",
       " 'couleur': 0,\n",
       " 'dapprentissage': 0,\n",
       " 'spatial': 0,\n",
       " 'laugmentation': 0,\n",
       " 'requete': 0,\n",
       " 'systeme gestion': 0,\n",
       " 'version': 0,\n",
       " 'reconstruction': 0,\n",
       " 'participatif': 0,\n",
       " 'utile': 0,\n",
       " 'algorithm dapprentissage': 0,\n",
       " 'mesurer proximite': 0,\n",
       " 'partir ensembl': 0,\n",
       " 'grand tailler': 0,\n",
       " 'variable cibl': 0,\n",
       " 'distribuer': 0,\n",
       " 'dater': 0,\n",
       " 'compromis entrer': 0,\n",
       " 'architecturer': 0,\n",
       " 'artificiel': 0,\n",
       " 'dentre': 0,\n",
       " 'arbre decision': 0,\n",
       " 'exploitation': 0,\n",
       " 'evaluees': 0,\n",
       " 'prealabl': 0,\n",
       " 'regrouper': 0,\n",
       " 'relever': 0,\n",
       " 'gestion connaissance': 0,\n",
       " 'dintegration': 0,\n",
       " 'focaliser': 0,\n",
       " 'variable explicatif': 0,\n",
       " 'qualite classification': 0,\n",
       " 'article decrit': 0,\n",
       " 'poindre': 0,\n",
       " 'combinaison': 0,\n",
       " 'propager': 0,\n",
       " 'presenter nouvel': 0,\n",
       " 'apr': 0,\n",
       " 'appeler': 0,\n",
       " 'statique': 0,\n",
       " 'profit': 0,\n",
       " 'kmean': 0,\n",
       " 'article proposer methodologie': 0,\n",
       " 'selection modele': 0,\n",
       " 'specialis': 0,\n",
       " 'entrer groupe': 0,\n",
       " 'structurel': 0,\n",
       " 'creer': 0,\n",
       " 'pretraitement': 0,\n",
       " 'serier': 0,\n",
       " 'proposer nouvel algorithme': 0,\n",
       " 'lobjet': 0,\n",
       " 'importance': 0,\n",
       " 'capteur': 0,\n",
       " 'fonctionner': 0,\n",
       " 'sousjacent': 0,\n",
       " 'applique': 0,\n",
       " 'sortir': 0,\n",
       " 'beneficier': 0,\n",
       " 'candidat': 2,\n",
       " 'classique': 0,\n",
       " 'autour': 0,\n",
       " 'donnee numeriqu': 0,\n",
       " 'configuration': 0,\n",
       " 'cadrer travail': 0,\n",
       " 'petit': 0,\n",
       " 'permettre': 1,\n",
       " 'proteine': 0,\n",
       " 'dextraction connaissance': 0,\n",
       " 'negativ': 0,\n",
       " 'challenge': 0,\n",
       " 'eleve': 0,\n",
       " 'detude': 0,\n",
       " 'tweet': 2,\n",
       " 'present': 0,\n",
       " 'etudier': 0,\n",
       " 'lacces': 0,\n",
       " 'dassoci': 0,\n",
       " 'maintenir': 0,\n",
       " 'campagne': 0,\n",
       " 'encourageant': 0,\n",
       " 'dimag': 0,\n",
       " 'taux': 0,\n",
       " 'condensees': 0,\n",
       " 'varier': 0,\n",
       " 'generalisation': 0,\n",
       " 'consequent': 0,\n",
       " 'generalist': 0,\n",
       " 'regler': 0,\n",
       " 'motif ensembliste': 0,\n",
       " 'donnees': 0,\n",
       " 'construire partir': 0,\n",
       " 'lactivite': 0,\n",
       " 'dissimilarit': 0,\n",
       " 'qualite resultat': 0,\n",
       " 'jeu dedonnee': 0,\n",
       " 'visualisation donneer': 0,\n",
       " 'situation': 0,\n",
       " 'entrepot': 0,\n",
       " 'competence': 0,\n",
       " 'dexempl': 0,\n",
       " 'variant': 0,\n",
       " 'validation': 0,\n",
       " 'presentees': 0,\n",
       " 'cadrer article': 0,\n",
       " 'lusage': 1,\n",
       " 'facteur': 0,\n",
       " 'courir': 0,\n",
       " 'party': 0,\n",
       " 'dattributs': 0,\n",
       " 'temps dexecution': 0,\n",
       " 'confronter': 0,\n",
       " 'detectiond': 0,\n",
       " 'nouvelleapproche': 0,\n",
       " 'donnee synthetiqu': 0,\n",
       " 'spatiotemporell': 0,\n",
       " 'stockeer': 0,\n",
       " 'quantite donnee': 0,\n",
       " 'dependanc': 0,\n",
       " 'donnee reel': 0,\n",
       " 'grand base donneer': 0,\n",
       " 'validite': 0,\n",
       " 'comprendre': 0,\n",
       " 'cadrer': 0,\n",
       " 'rechercher dinformation': 0,\n",
       " 'priser': 0,\n",
       " 'lexperience': 0,\n",
       " 'plateform': 2,\n",
       " 'emergent': 0,\n",
       " 'docu': 0,\n",
       " 'danalyser': 0,\n",
       " 'automat': 0,\n",
       " 'donneer': 0,\n",
       " 'sinteresse': 0,\n",
       " 'lapproch propose': 0,\n",
       " 'compter': 0,\n",
       " 'som': 0,\n",
       " 'annotation semantiqu': 0,\n",
       " 'enrichissement': 0,\n",
       " 'system': 0,\n",
       " 'modification': 0,\n",
       " 'methode efficace': 0,\n",
       " 'groupe': 0,\n",
       " 'adaptee': 0,\n",
       " 'eviter': 0,\n",
       " 'simuleer': 0,\n",
       " 'regroupement': 0,\n",
       " 'dinteraction entrer': 0,\n",
       " 'selection variable': 0,\n",
       " 'sens': 0,\n",
       " 'chemin': 0,\n",
       " 'article traire': 0,\n",
       " 'humain': 0,\n",
       " 'extraire motif': 0,\n",
       " 'priser decision': 0,\n",
       " 'mal': 0,\n",
       " 'faire': 0,\n",
       " 'largement': 0,\n",
       " 'limplementation': 0,\n",
       " 'charger': 0,\n",
       " 'exhiber': 0,\n",
       " 'mise': 0,\n",
       " 'referentiel': 0,\n",
       " 'decouvrir motif': 0,\n",
       " 'faisabilite': 0,\n",
       " 'devoir': 0,\n",
       " 'mining': 0,\n",
       " 'bloc': 0,\n",
       " 'detablir': 0,\n",
       " 'vecteur support': 0,\n",
       " 'loptimisation': 0,\n",
       " 'traitement': 0,\n",
       " 'logique': 0,\n",
       " 'utiliser algorithme': 0,\n",
       " 'traduction': 0,\n",
       " 'syntaxe': 0,\n",
       " 'generer': 0,\n",
       " 'selection': 0,\n",
       " 'mettre': 1,\n",
       " 'xquery': 0,\n",
       " 'mettre lumiere': 0,\n",
       " 'porter': 0,\n",
       " 'transform': 0,\n",
       " 'lafc': 0,\n",
       " 'calculer': 0,\n",
       " 'fonctionnel': 0,\n",
       " 'application': 0,\n",
       " 'probabilit': 0,\n",
       " 'connaissance baser': 0,\n",
       " 'patron': 0,\n",
       " 'modele prediction': 0,\n",
       " 'faire appel': 0,\n",
       " 'precision': 0,\n",
       " 'biomedical': 0,\n",
       " 'adopter': 0,\n",
       " 'nest': 0,\n",
       " 'generee': 0,\n",
       " 'technologi': 0,\n",
       " 'fusion': 0,\n",
       " 'lumiere': 0,\n",
       " 'detecter': 0,\n",
       " 'parallele': 0,\n",
       " 'decriver': 0,\n",
       " 'connu': 0,\n",
       " 'theorie': 0,\n",
       " 'proposer dextraire': 0,\n",
       " 'personnalisation': 0,\n",
       " 'exprimer': 0,\n",
       " 'apprendre': 0,\n",
       " 'topolog': 0,\n",
       " 'composant': 0,\n",
       " 'ponderation': 0,\n",
       " 'empiriquement': 0,\n",
       " 'role': 0,\n",
       " 'etle': 0,\n",
       " 'conference': 0,\n",
       " 'regle dassociation': 0,\n",
       " 'retrouver': 0,\n",
       " 'combin': 0,\n",
       " 'etiquete': 0,\n",
       " 'experience meneer': 0,\n",
       " 'localement': 0,\n",
       " 'significativement': 0,\n",
       " 'manipulation': 0,\n",
       " 'extraction connaissance': 0,\n",
       " 'tot': 0,\n",
       " 'classification supervise': 0,\n",
       " 'projection': 0,\n",
       " 'represente': 0,\n",
       " 'griller': 0,\n",
       " 'international': 0,\n",
       " 'egc': 0,\n",
       " 'relation semantiqu': 0,\n",
       " 'difference': 0,\n",
       " 'proposer article methode': 0,\n",
       " 'donnee reell': 0,\n",
       " 'documentaire': 0,\n",
       " 'client': 0,\n",
       " 'axe': 0,\n",
       " 'dapporter': 0,\n",
       " 'lespace': 0,\n",
       " 'permettre dextraire': 0,\n",
       " 'mettre oeuvrer': 0,\n",
       " 'coûteux': 0,\n",
       " 'temporel': 0,\n",
       " 'utilisee': 0,\n",
       " 'moteur': 0,\n",
       " 'olap': 0,\n",
       " 'fichier': 0,\n",
       " 'born': 0,\n",
       " 'method': 0,\n",
       " 'ferme frequent': 0,\n",
       " 'repartition': 0,\n",
       " 'experimentation montrer': 0,\n",
       " 'proposer permettre': 0,\n",
       " 'degr': 0,\n",
       " 'baser connaissance': 0,\n",
       " 'travail recent': 0,\n",
       " 'paradigm': 0,\n",
       " 'period': 0,\n",
       " 'mesurer dissimilarite': 0,\n",
       " 'million': 0,\n",
       " 'definis': 0,\n",
       " 'prototype': 0,\n",
       " 'decouverte motif': 0,\n",
       " 'jour': 0,\n",
       " 'letat lart': 0,\n",
       " 'algorithme': 0,\n",
       " 'fournir': 1,\n",
       " 'domaine dapplication': 0,\n",
       " 'topographique': 0,\n",
       " 'grouper': 0,\n",
       " 'representation donnee': 0,\n",
       " 'capable': 0,\n",
       " 'surune': 0,\n",
       " 'contenu': 0,\n",
       " 'devenement': 1,\n",
       " 'iteratif': 0,\n",
       " 'method dextraction': 0,\n",
       " 'graphe': 0,\n",
       " 'individuel': 0,\n",
       " 'trajectoire': 0,\n",
       " 'larbr': 0,\n",
       " 'lanalys formel concept': 0,\n",
       " 'factoriel correspondance': 0,\n",
       " 'referent': 0,\n",
       " 'faire face': 0,\n",
       " 'morphosyntaxique': 0,\n",
       " 'statistique': 0,\n",
       " 'compromis': 0,\n",
       " 'controle': 0,\n",
       " 'performer': 0,\n",
       " 'lajout': 0,\n",
       " 'tableau donnee': 0,\n",
       " 'resume': 0,\n",
       " 'classification automatique': 0,\n",
       " 'lidentification': 0,\n",
       " 'compatible': 0,\n",
       " 'nombre': 0,\n",
       " 'nommees': 0,\n",
       " 'formalisation': 0,\n",
       " 'decd': 0,\n",
       " 'patient': 0,\n",
       " 'method visualisation': 0,\n",
       " 'ainsiqu': 0,\n",
       " 'densite': 0,\n",
       " 'gain': 0,\n",
       " 'structur': 0,\n",
       " 'visualisation interactif': 0,\n",
       " 'domaine': 0,\n",
       " 'xml': 0,\n",
       " 'contraindre': 0,\n",
       " 'mixte': 0,\n",
       " 'donnee relationnel': 0,\n",
       " 'lindice': 0,\n",
       " 'collectif': 0,\n",
       " 'associ': 0,\n",
       " 'naïf': 0,\n",
       " 'reseaux neuron': 0,\n",
       " 'etendu': 0,\n",
       " 'minoritaire': 0,\n",
       " 'croiser': 0,\n",
       " 'proportion': 0,\n",
       " 'contrainte': 0,\n",
       " 'liee': 0,\n",
       " 'representation condensee': 0,\n",
       " 'semantiqu entrer': 0,\n",
       " 'tâcher': 0,\n",
       " 'direct': 0,\n",
       " 'comparatif': 0,\n",
       " 'impossible': 0,\n",
       " 'centrer': 0,\n",
       " 'supervise': 0,\n",
       " 'inspiree': 0,\n",
       " 'ascendant': 0,\n",
       " 'qualite recommandation': 0,\n",
       " 'connaissance domaine': 0,\n",
       " 'specifiqu': 1,\n",
       " 'conduire': 0,\n",
       " 'gener': 0,\n",
       " 'qualitatif': 0,\n",
       " 'nonsupervise': 0,\n",
       " 'etude': 0,\n",
       " 'lexperimentation': 0,\n",
       " 'proposer method': 0,\n",
       " 'experimentation menee': 0,\n",
       " 'image': 0,\n",
       " 'approche existant': 0,\n",
       " 'linterpretation': 0,\n",
       " 'devoir permettre': 0,\n",
       " 'resultant': 0,\n",
       " 'raison': 1,\n",
       " 'instant': 0,\n",
       " 'donnee multidimensionnel': 0,\n",
       " 'relation entrer': 0,\n",
       " 'dependance fonctionnel': 0,\n",
       " 'dextraction': 0,\n",
       " 'appliquee': 0,\n",
       " 'donnee grand': 0,\n",
       " 'representent': 0,\n",
       " 'moyen': 0,\n",
       " 'numeriquer': 0,\n",
       " 'noyau': 0,\n",
       " 'densembl': 0,\n",
       " 'memoir': 0,\n",
       " 'comparer': 0,\n",
       " 'jeu donnee synthetiqu': 0,\n",
       " 'traire': 0,\n",
       " 'proposer article': 0,\n",
       " 'anne': 0,\n",
       " 'acquisition': 0,\n",
       " 'processus fouiller': 0,\n",
       " 'interess': 0,\n",
       " 'graduel': 0,\n",
       " 'seri': 0,\n",
       " 'conception': 0,\n",
       " 'dautre partir': 0,\n",
       " 'echantillonnage': 0,\n",
       " 'traiter probleme': 0,\n",
       " 'lensembl': 0,\n",
       " 'extrait': 0,\n",
       " 'produire': 0,\n",
       " 'parametr': 0,\n",
       " 'fouill donneer': 0,\n",
       " 'indicateur': 0,\n",
       " 'baser dapprentissage': 0,\n",
       " 'algorithmique': 0,\n",
       " 'distribu': 0,\n",
       " 'grand echelle': 0,\n",
       " 'dexpression': 0,\n",
       " 'projet': 0,\n",
       " 'monder': 0,\n",
       " 'etroitement': 0,\n",
       " 'ordre': 0,\n",
       " 'sequentiel': 0,\n",
       " 'ecd': 0,\n",
       " 'associeer': 0,\n",
       " 'consommation': 0,\n",
       " 'derreur': 0,\n",
       " 'information': 0,\n",
       " 'anr': 0,\n",
       " 'grand ensembl': 0,\n",
       " 'examiner': 0,\n",
       " 'long': 0,\n",
       " 'etudie': 0,\n",
       " 'habituellement': 0,\n",
       " 'table': 0,\n",
       " 'similaire': 0,\n",
       " 'sequenc devenement': 0,\n",
       " 'naturellement': 0,\n",
       " 'lie': 0,\n",
       " 'ameliorer qualite': 0,\n",
       " 'interface': 0,\n",
       " 'recemment': 0,\n",
       " 'evoluer': 0,\n",
       " 'volum': 0,\n",
       " 'lanalyse formel': 0,\n",
       " 'contenir document': 0,\n",
       " 'fixer': 0,\n",
       " 'lon': 0,\n",
       " 'cooperativ': 0,\n",
       " 'decomposition': 0,\n",
       " 'munir': 0,\n",
       " 'valider': 0,\n",
       " 'document xml': 0,\n",
       " 'article present methode': 0,\n",
       " 'complexe': 0,\n",
       " 'priori': 0,\n",
       " 'conflit': 0,\n",
       " 'nom': 0,\n",
       " 'categoriel': 0,\n",
       " 'lanalyse formel concept': 0,\n",
       " 'machine': 0,\n",
       " 'outil': 0,\n",
       " 'arbre': 0,\n",
       " 'paradigme': 0,\n",
       " 'experiment': 0,\n",
       " 'saver': 0,\n",
       " 'defi': 0,\n",
       " 'montrer faisabilite': 0,\n",
       " 'adaptation': 0,\n",
       " 'sappui': 0,\n",
       " 'text': 0,\n",
       " 'celer proposer': 0,\n",
       " 'repondre': 0,\n",
       " 'interactif': 0,\n",
       " 'sousensembl': 0,\n",
       " 'reside': 1,\n",
       " 'modele permettre': 0,\n",
       " 'factorisation': 0,\n",
       " 'benchmark': 0,\n",
       " 'profil': 0,\n",
       " 'volumetrie': 0,\n",
       " 'agregation': 0,\n",
       " 'mass': 0,\n",
       " 'position': 0,\n",
       " 'domaine fouiller': 0,\n",
       " 'resultat experimentaux montrer': 0,\n",
       " 'lexpert': 0,\n",
       " 'utilisable': 0,\n",
       " 'impliqu': 0,\n",
       " 'montrer linteret': 0,\n",
       " 'dindexation': 0,\n",
       " 'context': 0,\n",
       " 'definition': 0,\n",
       " 'evalu': 0,\n",
       " 'partir base': 0,\n",
       " 'detection': 0,\n",
       " 'modele conceptuel': 0,\n",
       " 'nair': 0,\n",
       " 'sest': 0,\n",
       " 'distance': 0,\n",
       " 'lintroduction': 0,\n",
       " 'discretisation': 0,\n",
       " 'efficace': 0,\n",
       " 'luci': 0,\n",
       " 'pouvoir trouver': 0,\n",
       " 'resoudre': 0,\n",
       " 'industriel': 0,\n",
       " 'reconnaitre': 0,\n",
       " 'extraire connaissance': 0,\n",
       " 'papier present': 0,\n",
       " 'parcourir': 0,\n",
       " 'dattribut': 0,\n",
       " 'organiser': 0,\n",
       " 'sequenc': 0,\n",
       " 'iii': 0,\n",
       " 'lautre': 0,\n",
       " 'utiliser donnee': 0,\n",
       " 'surl': 0,\n",
       " 'qualitativement': 0,\n",
       " 'tabler': 0,\n",
       " 'inclure': 0,\n",
       " 'prendre decision': 0,\n",
       " 'detr': 0,\n",
       " 'discriminer': 0,\n",
       " 'motif sequentiel': 0,\n",
       " 'propriete': 0,\n",
       " 'limite': 0,\n",
       " 'meilleure': 0,\n",
       " 'ligne': 0,\n",
       " 'amene': 0,\n",
       " 'web donnee': 0,\n",
       " 'structurer sousjacent': 0,\n",
       " 'clef': 0,\n",
       " 'bayesien naïf': 0,\n",
       " 'letiquetage': 0,\n",
       " 'presenter': 0,\n",
       " 'technologie': 0,\n",
       " 'base': 0,\n",
       " 'binaire': 0,\n",
       " 'lextraction motif': 0,\n",
       " 'reponse requete': 0,\n",
       " 'montrer': 0,\n",
       " 'dextrair': 0,\n",
       " 'former regl': 0,\n",
       " 'propagation': 0,\n",
       " 'question': 0,\n",
       " 'sadapter': 0,\n",
       " 'processus dextraction': 0,\n",
       " 'implicitement': 0,\n",
       " 'thematiqu': 0,\n",
       " 'donnee artificiel': 0,\n",
       " 'donner resultat': 0,\n",
       " 'separateur vaste': 0,\n",
       " 'relaxation': 0,\n",
       " 'tâch': 0,\n",
       " 'serie temporel': 0,\n",
       " 'caracteristique': 1,\n",
       " 'dizaine': 0,\n",
       " 'sommet': 0,\n",
       " 'nouvel algorithm': 0,\n",
       " 'jusqua': 0,\n",
       " 'entrer variable': 0,\n",
       " 'algorithm efficace': 0,\n",
       " 'longueur': 0,\n",
       " 'correspondre': 0,\n",
       " 'prevention': 0,\n",
       " 'signature': 0,\n",
       " 'dinterrogation': 0,\n",
       " 'mod': 0,\n",
       " 'vision': 0,\n",
       " 'spectral': 0,\n",
       " 'specificite': 0,\n",
       " 'lexploitation': 0,\n",
       " 'technique fouiller': 0,\n",
       " 'partir sequence': 0,\n",
       " 'temps reponse': 0,\n",
       " 'destimer': 0,\n",
       " 'extension': 0,\n",
       " 'sou former': 0,\n",
       " 'ameliorer': 0,\n",
       " 'regl dassociation': 0,\n",
       " 'encourageant prometteur': 0,\n",
       " 'liste': 0,\n",
       " 'plaire voisin': 0,\n",
       " 'provenir': 0,\n",
       " 'suite': 0,\n",
       " 'frequent': 0,\n",
       " 'strategiqu': 0,\n",
       " 'voire': 0,\n",
       " 'performance': 0,\n",
       " 'classification': 0,\n",
       " 'interpretation': 0,\n",
       " 'capacite': 0,\n",
       " 'taill': 0,\n",
       " 'associer': 0,\n",
       " 'eter': 0,\n",
       " 'impact': 0,\n",
       " 'initialement': 0,\n",
       " 'generation': 0,\n",
       " 'sousensemble': 0,\n",
       " 'proposer papier': 0,\n",
       " 'interpreter': 0,\n",
       " 'informatique': 0,\n",
       " 'darbr': 0,\n",
       " 'structurer donnee': 0,\n",
       " 'potentiellement': 0,\n",
       " 'svm': 0,\n",
       " 'rechercher dimager': 0,\n",
       " 'science': 0,\n",
       " 'resoudre probleme': 0,\n",
       " 'central': 0,\n",
       " 'pondere': 0,\n",
       " 'linfluence': 0,\n",
       " 'donneer reell': 0,\n",
       " 'analys': 2,\n",
       " 'decoupage': 0,\n",
       " 'lestimation': 0,\n",
       " 'concis': 0,\n",
       " 'structuration': 0,\n",
       " 'simultanee': 0,\n",
       " 'pourtant': 0,\n",
       " 'difficilement': 0,\n",
       " 'iterativ': 0,\n",
       " 'navigation': 0,\n",
       " 'ligne colonne': 0,\n",
       " 'association': 0,\n",
       " 'guider': 0,\n",
       " 'equivalent': 0,\n",
       " 'dimension': 0,\n",
       " 'reel': 1,\n",
       " 'contextuel': 0,\n",
       " 'associe': 0,\n",
       " 'caracteriseer': 0,\n",
       " 'concerner': 0,\n",
       " 'appliqu': 0,\n",
       " 'carte topologique': 0,\n",
       " 'facilement': 0,\n",
       " 'article': 0,\n",
       " 'evolution': 0,\n",
       " 'cartographie': 0,\n",
       " 'determination': 0,\n",
       " 'rapidement': 0,\n",
       " 'nouvel': 0,\n",
       " 'dapparition': 0,\n",
       " 'dinference': 0,\n",
       " 'signal': 0,\n",
       " 'possede': 0,\n",
       " 'temps reel': 1,\n",
       " 'donnee textuel': 0,\n",
       " 'recours': 0,\n",
       " 'correctement': 0,\n",
       " 'direction': 0,\n",
       " 'critere devaluation': 0,\n",
       " 'echelle': 0,\n",
       " 'chercheur': 0,\n",
       " 'developpement': 0,\n",
       " 'nommer': 0,\n",
       " 'evaluer': 0,\n",
       " 'elevee': 0,\n",
       " 'solution': 0,\n",
       " 'minimal': 0,\n",
       " 'partir texte': 0,\n",
       " 'complementair': 0,\n",
       " 'utiliser methode': 0,\n",
       " 'standard': 0,\n",
       " 'classification multilabel': 0,\n",
       " 'contribution': 0,\n",
       " 'feature': 0,\n",
       " 'offrir': 0,\n",
       " 'compose': 0,\n",
       " 'presenter application': 0,\n",
       " 'atypique': 0,\n",
       " 'applicatif': 0,\n",
       " 'entrer individu': 0,\n",
       " 'estimation densite': 0,\n",
       " 'specifier': 0,\n",
       " 'dater stream': 0,\n",
       " 'doutils': 0,\n",
       " 'sappuyer': 0,\n",
       " 'dexploiter': 0,\n",
       " 'reduction': 0,\n",
       " 'prealablement': 0,\n",
       " 'gestion flux donneer': 0,\n",
       " 'envisageable': 0,\n",
       " 'lamelioration': 0,\n",
       " 'programmation': 0,\n",
       " 'selectionde': 0,\n",
       " 'succe': 0,\n",
       " 'plaire particulierement': 0,\n",
       " 'aleatoir': 0,\n",
       " 'mobilite': 0,\n",
       " 'automatiser': 0,\n",
       " 'labsence': 0,\n",
       " 'definissons': 0,\n",
       " 'etuder': 0,\n",
       " 'semiautomatique': 0,\n",
       " 'partir ensemble': 0,\n",
       " 'parametre': 0,\n",
       " 'permettre partir': 0,\n",
       " 'methode original': 0,\n",
       " 'fouiller donnee': 0,\n",
       " 'relationnel': 0,\n",
       " 'dalgorithme': 0,\n",
       " 'mettre evidence': 0,\n",
       " 'site web': 0,\n",
       " 'passage': 0,\n",
       " 'entrer objet': 0,\n",
       " 'syntaxique': 0,\n",
       " 'appliquer': 0,\n",
       " 'lapplication': 0,\n",
       " 'plaire': 0,\n",
       " 'juger': 0,\n",
       " 'logique inductif': 0,\n",
       " 'concepteur': 0,\n",
       " 'statistique implicatif': 0,\n",
       " 'euclidien': 0,\n",
       " 'estimee': 0,\n",
       " 'corpu': 0,\n",
       " 'limage': 0,\n",
       " 'terme qualite': 0,\n",
       " 'dynamique': 0,\n",
       " 'inferieur': 0,\n",
       " 'gerer': 0,\n",
       " 'enrichir': 0,\n",
       " 'sig': 0,\n",
       " 'dentrepris': 0,\n",
       " 'mettre placer': 0,\n",
       " 'semantique': 0,\n",
       " 'classificateur': 0,\n",
       " 'parametriqu': 0,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_word[num_partition][word]\n",
    "nb_word = []\n",
    "\n",
    "word_in_this_parti = {}\n",
    "for word in vectorizer.get_feature_names():\n",
    "    word_in_this_parti[word] = 0\n",
    "\n",
    "for numDoc in range(0, len(usable)):\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        word_in_this_parti[word] += tf[numDoc][word]\n",
    "    if numDoc+1 in limits:\n",
    "        nb_word.append(word_in_this_parti)\n",
    "        word_in_this_parti = {}\n",
    "        for word in vectorizer.get_feature_names():\n",
    "            word_in_this_parti[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nb_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_word_by_cluster[numPartition][numCluster]\n",
    "nb_word_by_cluster = []\n",
    "for parti in partitions:\n",
    "    nb_word_clus = []\n",
    "    for cluster in parti:\n",
    "        nb = 0\n",
    "        for numDoc in cluster:\n",
    "            for word in vectorizer.get_feature_names():\n",
    "                nb += tf[numDoc][word]\n",
    "        nb_word_clus.append(nb)\n",
    "    nb_word_by_cluster.append(nb_word_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_of_khi2 = khi2[numPartition][numCluster][word]\n",
    "khi2 = []\n",
    "\n",
    "for numParti in range(0, len(partitions)):\n",
    "    khi2parti = []\n",
    "    for numCluster in range(0, len(partitions[numParti])):\n",
    "        khi2cluster = {}\n",
    "        \n",
    "        for word in vectorizer.get_feature_names():\n",
    "            if nb_word_by_cluster[numParti][numCluster] == 0:\n",
    "                khi2cluster[word] = 0\n",
    "            else:\n",
    "                word_in_this_parti[word] = 0\n",
    "                E = nb_word[numParti][word]\n",
    "                E =+ nb_word_by_cluster[numParti][numCluster]\n",
    "                E = E/ nb_total_word[numParti]\n",
    "                N = 0\n",
    "                for numDoc in partitions[numParti][numCluster]:\n",
    "                    N += tf[numDoc][word]\n",
    "                khi2cluster[word] = (pow(N - E, 2)/E)        \n",
    "        khi2parti.append(khi2cluster)\n",
    "    khi2.append(khi2parti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of your labels = labels[numPartition][numCluster]\n",
    "labels = []\n",
    "\n",
    "for numPartition in range(0, len(nb_word_by_cluster)):\n",
    "    label_clus = []\n",
    "    for numCluster in range(0, len(nb_word_by_cluster[numPartition])):\n",
    "        label_clus.append(Counter(khi2[numPartition][numCluster]).most_common(5))\n",
    "    labels.append(label_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[('donne', 41484.82779904815),\n",
       "   ('donnee', 30744.32193846826),\n",
       "   ('rdf', 4577.536003859994),\n",
       "   ('donneer', 3842.755004476896),\n",
       "   ('format', 2565.9184838106407)],\n",
       "  [('method', 4010.1592523300537),\n",
       "   ('propos', 3716.698438625557),\n",
       "   ('propose', 2903.2127855206313),\n",
       "   ('poser', 2190.0723144285544),\n",
       "   ('present', 1974.6577534007172)],\n",
       "  [('donne', 7001.946272365945),\n",
       "   ('utilis', 6662.613478581548),\n",
       "   ('format', 4803.604090430043),\n",
       "   ('formation', 4523.267088163938),\n",
       "   ('information', 4251.358056114731)],\n",
       "  [('relation', 7520.444327216775),\n",
       "   ('trer', 4216.824615245576),\n",
       "   ('label', 3611.5680895930113),\n",
       "   ('entrer', 2791.556838467898),\n",
       "   ('extraction', 2303.4650292869806)],\n",
       "  [('donne', 28563.295284812164),\n",
       "   ('donnee', 22612.831284812168),\n",
       "   ('method', 3944.995284812168),\n",
       "   ('mettre', 3490.796884812169),\n",
       "   ('utilis', 3490.796884812169)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)]],\n",
       " [[('donne', 11430.688302038743),\n",
       "   ('utilis', 10364.1759680729),\n",
       "   ('log', 9349.883747959047),\n",
       "   ('base', 7477.959649287321),\n",
       "   ('propos', 7477.959649287321)],\n",
       "  [('donne', 34687.34041442544),\n",
       "   ('donnee', 31048.346470295724),\n",
       "   ('vis', 10798.877433374446),\n",
       "   ('classification', 10798.877433374446),\n",
       "   ('propos', 8440.039379066964)],\n",
       "  [('donne', 14427.464724684934),\n",
       "   ('donnee', 11188.042644174771),\n",
       "   ('the', 6860.511356809285),\n",
       "   ('them', 5091.6121937961325),\n",
       "   ('mettre', 4690.519328112593)],\n",
       "  [('donne', 26042.966788220772),\n",
       "   ('donnee', 20258.080164912633),\n",
       "   ('method', 12089.049755350323),\n",
       "   ('plaire', 9334.844446860254),\n",
       "   ('utilis', 9334.844446860254)],\n",
       "  [('motif', 24863.30614101457),\n",
       "   ('donne', 24165.89734505206),\n",
       "   ('donnee', 18335.649327748528),\n",
       "   ('action', 9085.881483480323),\n",
       "   ('method', 7466.887972305125)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)]],\n",
       " [[('log', 21143.737774852772),\n",
       "   ('ontolog', 11872.417046079996),\n",
       "   ('concept', 11311.848809572606),\n",
       "   ('ontologie', 8233.112474062122),\n",
       "   ('trer', 7315.313917857239)],\n",
       "  [('donne', 30204.23133264344),\n",
       "   ('donnee', 26977.322031661355),\n",
       "   ('motif', 15296.166341308955),\n",
       "   ('quen', 6906.872580477066),\n",
       "   ('propose', 5065.912152978512)],\n",
       "  [('donne', 40321.040737869414),\n",
       "   ('donnee', 33247.73745215513),\n",
       "   ('vis', 16546.654023583706),\n",
       "   ('utilis', 15694.372880726563),\n",
       "   ('poser', 11409.616737869424)],\n",
       "  [('mod', 14791.201991782176),\n",
       "   ('reseau', 13243.222960690347),\n",
       "   ('format', 12258.759234491263),\n",
       "   ('model', 11780.784059750364),\n",
       "   ('mode', 11780.784059750364)],\n",
       "  [('regl', 26061.784617402238),\n",
       "   ('regle', 10306.645791730869),\n",
       "   ('donne', 4701.6275850854445),\n",
       "   ('action', 4299.774603747256),\n",
       "   ('system', 3915.870643801876)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)]],\n",
       " [[('donne', 122294.51275316553),\n",
       "   ('donnee', 97414.50841812915),\n",
       "   ('present', 17440.005863554165),\n",
       "   ('donneer', 11307.950746663006),\n",
       "   ('vis', 10080.77378428493)],\n",
       "  [('mod', 20657.987448430176),\n",
       "   ('mode', 18894.972074445028),\n",
       "   ('model', 17763.30788373852),\n",
       "   ('log', 17763.30788373852),\n",
       "   ('present', 12629.139633608962)],\n",
       "  [('motif', 32589.96109178059),\n",
       "   ('donne', 19103.407551698678),\n",
       "   ('quen', 19103.407551698678),\n",
       "   ('donnee', 18054.906673992416),\n",
       "   ('sequentiel', 8474.440904536596)],\n",
       "  [('trer', 22563.187207912433),\n",
       "   ('regl', 14206.701088712281),\n",
       "   ('entrer', 9415.930364581047),\n",
       "   ('log', 8575.59101299883),\n",
       "   ('mettre', 8170.148186363224)],\n",
       "  [('donne', 25386.09767552178),\n",
       "   ('method', 25386.09767552178),\n",
       "   ('classification', 24745.510754188013),\n",
       "   ('donnee', 20490.605283161793),\n",
       "   ('vis', 17162.790456357005)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)]],\n",
       " [[('present', 31168.58135560537),\n",
       "   ('donne', 29052.23057309053),\n",
       "   ('represent', 19586.450756576767),\n",
       "   ('donnee', 17916.489612486104),\n",
       "   ('presentation', 15551.044658357665)],\n",
       "  [('donne', 137892.50491367918),\n",
       "   ('donnee', 113538.14783663617),\n",
       "   ('utilis', 50365.62646729746),\n",
       "   ('method', 49666.552330221835),\n",
       "   ('present', 34936.25457701467)],\n",
       "  [('docu', 99153.9784769625),\n",
       "   ('document', 93666.06132762982),\n",
       "   ('annot', 19078.410609926465),\n",
       "   ('format', 15226.17817477159),\n",
       "   ('xml', 14507.80673181012)],\n",
       "  [('donne', 107517.9143672917),\n",
       "   ('connaiss', 101013.21350755786),\n",
       "   ('connaissance', 93475.46671683827),\n",
       "   ('donnee', 81561.99598312023),\n",
       "   ('motif', 19749.364255408524)],\n",
       "  [('regl', 202534.2077132429),\n",
       "   ('regle', 103006.53221181019),\n",
       "   ('donne', 48638.62032069271),\n",
       "   ('donnee', 37917.16831496205),\n",
       "   ('associ', 23010.68908860102)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)],\n",
       "  [('sequentiell', 0),\n",
       "   ('presenter methode', 0),\n",
       "   ('dense', 0),\n",
       "   ('complementarite', 0),\n",
       "   ('statistique implicatif', 0)]]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some clusters can be empty\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
