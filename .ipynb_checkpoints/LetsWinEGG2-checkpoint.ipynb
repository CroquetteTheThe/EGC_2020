{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "from gensim import corpora, models, utils\n",
    "from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
    "from gensim.models import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy lib\n",
    "# On https://spacy.io/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Parameters #\n",
    "##############\n",
    "\n",
    "min_gram = 1\n",
    "max_gram = 3\n",
    "\n",
    "# To create ours partitions, we must first know the years which will be the limits\n",
    "limit_years = [2007, 2010, 2014]\n",
    "\n",
    "# Ignore words that appear at a frequency less than max_frequ in the corpus\n",
    "max_frequ = 0.8\n",
    "\n",
    "# Ignore words appearing less than min_appear in the whole corpus\n",
    "min_appear = 5\n",
    "\n",
    "# Number of clusters by partitions\n",
    "nb_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas preprocessing methods.\n",
    "\n",
    "# Lemmatisation without poncutations\n",
    "\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()\n",
    "fstw = stopwords.words('french')\n",
    "\n",
    "# French Stop Words, extraits depuis le fichier stopwords-fr.txt + stopwords french de nltk\n",
    "sourceFST = [x.replace('\\n', '') for x in open('stopwords-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]+fstw\n",
    "sourceFST += [x.replace('\\n', '') for x in open('perso_words-fr.txt', mode=\"r\", encoding=\"utf-8\").readlines()]\n",
    "\n",
    "# Based on ration of french and english stopwords\n",
    "def isEnglish(article):\n",
    "    total_fsw = len([x for x in article.split() if x in sourceFST])\n",
    "    total_esw = len([x for x in article.split() if x in stopwords.words('english')])\n",
    "    ratio = 100\n",
    "    if total_fsw != 0:\n",
    "        ratio = total_esw/total_fsw\n",
    "    return ratio > 1 and total_esw > 3\n",
    "\n",
    "def lemmatize(article):\n",
    "    arti_lower = article.lower()\n",
    "    arti_2words = re.sub(\" [0-z][0-z] \", \" \", arti_lower) # word of length < 2\n",
    "    arti_e = re.sub(\"(é|è|ê)\", \"e\", arti_2words)\n",
    "    arti_o = re.sub(\"à\", \"a\", arti_e)\n",
    "    arti_i = re.sub(\"ô\", \"o\", arti_o)\n",
    "    artiregex = re.sub(\"î\", \"i\", arti_i)\n",
    "    output = []\n",
    "    outPonc = artiregex.translate(artiregex.maketrans(\"\",\"\", string.punctuation))\n",
    "    outLem = nlp(outPonc)\n",
    "    for token in outLem:\n",
    "        if token.lemma_ not in sourceFST and [x for x in token.lemma_ if x not in \"0123456789\"] != []:\n",
    "            output.append(token.lemma_)\n",
    "    res = ' '.join(output)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    "data = pd.read_csv('export_articles_EGC_2004_2018.csv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process our corpus, and determine a limit to split it in partitions\n",
    "\n",
    "# usable[] correspond to our corpus processed\n",
    "# limits[] let us know when to delimit partitions\n",
    "limits = []\n",
    "usable = []\n",
    "\n",
    "prev_year = data['year'][0]\n",
    "numArti = 0\n",
    "for i in range(0, len(data['abstract']), 1):\n",
    "    #if not null, empty, or whatever (so if there is a abstract):\n",
    "    if not isinstance(data['abstract'][i], float) and not isEnglish(data['abstract'][i]):\n",
    "        text = data['abstract'][i]\n",
    "        if not isinstance(data['title'][i], float):\n",
    "            text += \" \"+data['title'][i]\n",
    "\n",
    "        numArti+=1\n",
    "        usable.append(re.sub(\" [0-z][0-z] \", \" \", stemmer.stem(lemmatize(text))))\n",
    "        year = data['year'][i]\n",
    "        if year != prev_year:\n",
    "            prev_year = year\n",
    "            if year in limit_years:\n",
    "                limits.append(numArti)\n",
    "limits.append(numArti)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'articles = 991\n",
      "nombre de mots = 2410\n",
      "limits = [223, 468, 694, 991]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'plateforme objectif permettre citoyen euxmemer tweet politique devenement specifiqu francepour cas lelection presidentiell ideo2017 analyser quasitemps reel message candidat fournir principal caracteristiqueslusage lexiqu politique comparaison entrer candidat ideo2017   plateforme citoyen dediee lanalyse tweet evenement polit'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display pre-processed datas\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=sourceFST, use_idf=True, ngram_range=(min_gram, max_gram), max_df=max_frequ, min_df=min_appear)\n",
    "tfidf = vectorizer.fit_transform(usable)\n",
    "\n",
    "print(\"nombre d'articles =\", len(usable))\n",
    "print(\"nombre de mots =\", len(tfidf.toarray()[0]))\n",
    "print(\"limits =\", limits)\n",
    "\n",
    "usable[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of partitions_tfidf[], which give us the TFIDF of each cluster of each partition\n",
    "# partitions_tfidf[num_partition][num_doc][num_word]\n",
    "# Beware, num_doc can't be equals to 1091 (max). You have partitions, so every doc aren't in every partitions\n",
    "# num_word can be found via vectorizer.get_feature_name()\n",
    "partitions_tfidf = []\n",
    "beg = 0\n",
    "for l in limits:\n",
    "    last = l\n",
    "    partitions_tfidf.append([list(x) for x in list(tfidf.toarray())[beg:last]])\n",
    "    beg = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3d',\n",
       " 'acce',\n",
       " 'accessible',\n",
       " 'achat',\n",
       " 'acquisition',\n",
       " 'acquérir',\n",
       " 'acteur',\n",
       " 'actif',\n",
       " 'action',\n",
       " 'activite',\n",
       " 'actuel',\n",
       " 'actuellement',\n",
       " 'adapt',\n",
       " 'adaptatif',\n",
       " 'adaptation',\n",
       " 'adapte',\n",
       " 'adaptee',\n",
       " 'adapter',\n",
       " 'adequat',\n",
       " 'adn',\n",
       " 'adopter',\n",
       " 'afc',\n",
       " 'affiner',\n",
       " 'agent',\n",
       " 'agregation',\n",
       " 'aid',\n",
       " 'aider',\n",
       " 'ainsiqu',\n",
       " 'ajoutee',\n",
       " 'ajouter',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'aleatoir',\n",
       " 'algebriqu',\n",
       " 'algorithm',\n",
       " 'algorithm classification',\n",
       " 'algorithm dapprentissage',\n",
       " 'algorithm dextraction',\n",
       " 'algorithm efficace',\n",
       " 'algorithme',\n",
       " 'algorithme dapprentissage',\n",
       " 'algorithme dextraction',\n",
       " 'algorithme ete',\n",
       " 'algorithme fouiller',\n",
       " 'algorithme incremental',\n",
       " 'algorithmique',\n",
       " 'alignement',\n",
       " 'alternatif',\n",
       " 'amelior',\n",
       " 'amelioration',\n",
       " 'ameliore',\n",
       " 'amelioree',\n",
       " 'ameliorer',\n",
       " 'ameliorer qualite',\n",
       " 'amene',\n",
       " 'amont',\n",
       " 'an',\n",
       " 'analys',\n",
       " 'analyse',\n",
       " 'analyser',\n",
       " 'analyser donnee',\n",
       " 'analyser factoriel',\n",
       " 'analyser semantiqu',\n",
       " 'analytique',\n",
       " 'anne',\n",
       " 'annees',\n",
       " 'annot',\n",
       " 'annotation',\n",
       " 'annotation semantiqu',\n",
       " 'annoter',\n",
       " 'anormal',\n",
       " 'anr',\n",
       " 'apartir',\n",
       " 'apparer',\n",
       " 'appartenir',\n",
       " 'appel',\n",
       " 'appele',\n",
       " 'appelee',\n",
       " 'appeler',\n",
       " 'applicable',\n",
       " 'applicatif',\n",
       " 'application',\n",
       " 'application donnee',\n",
       " 'application reell',\n",
       " 'appliqu',\n",
       " 'applique',\n",
       " 'appliquee',\n",
       " 'appliquees',\n",
       " 'appliquer',\n",
       " 'apport',\n",
       " 'apporter',\n",
       " 'apprehender',\n",
       " 'apprendre',\n",
       " 'apprentissage',\n",
       " 'apprentissage automatique',\n",
       " 'apprentissage supervis',\n",
       " 'approche',\n",
       " 'approche existant',\n",
       " 'appropriee',\n",
       " 'approprier',\n",
       " 'approximatif',\n",
       " 'approximation',\n",
       " 'apr',\n",
       " 'aprer',\n",
       " 'arbitraire',\n",
       " 'arborescent',\n",
       " 'arbre',\n",
       " 'arbre decision',\n",
       " 'architecturer',\n",
       " 'article',\n",
       " 'article decrit',\n",
       " 'article etuder',\n",
       " 'article etudie',\n",
       " 'article interesser',\n",
       " 'article introduire',\n",
       " 'article method',\n",
       " 'article methode',\n",
       " 'article montrer',\n",
       " 'article present',\n",
       " 'article present method',\n",
       " 'article present methode',\n",
       " 'article presenter',\n",
       " 'article presenter method',\n",
       " 'article presenton',\n",
       " 'article proposer',\n",
       " 'article proposer method',\n",
       " 'article proposer methode',\n",
       " 'article proposer methodologie',\n",
       " 'article traire',\n",
       " 'articlenou',\n",
       " 'artificiel',\n",
       " 'ascendant',\n",
       " 'ascendant hierarchiqu',\n",
       " 'aspect',\n",
       " 'assister',\n",
       " 'associ',\n",
       " 'association',\n",
       " 'associe',\n",
       " 'associee',\n",
       " 'associeer',\n",
       " 'associees',\n",
       " 'associer',\n",
       " 'assurer',\n",
       " 'attaquer',\n",
       " 'atteindre',\n",
       " 'attention',\n",
       " 'attribu',\n",
       " 'attribut',\n",
       " 'atypique',\n",
       " 'augmenter',\n",
       " 'automat',\n",
       " 'automate',\n",
       " 'automatique',\n",
       " 'automatiquement',\n",
       " 'automatiser',\n",
       " 'autoorganisatrice',\n",
       " 'autour',\n",
       " 'avancee',\n",
       " 'avantage',\n",
       " 'axe',\n",
       " 'axer',\n",
       " 'axiome',\n",
       " 'baptis',\n",
       " 'base',\n",
       " 'base donnee',\n",
       " 'base donnee relationnel',\n",
       " 'base donneer',\n",
       " 'baseesur',\n",
       " 'baser',\n",
       " 'baser connaissance',\n",
       " 'baser dapprentissage',\n",
       " 'baser donne',\n",
       " 'baser donneer',\n",
       " 'baser modele',\n",
       " 'baser technique',\n",
       " 'batch',\n",
       " 'bayesien',\n",
       " 'bayesien naïf',\n",
       " 'bayesienn',\n",
       " 'benchmark',\n",
       " 'beneficier',\n",
       " 'besoin',\n",
       " 'biais',\n",
       " 'bibliographique',\n",
       " 'biclustering',\n",
       " 'binaire',\n",
       " 'bioinformatique',\n",
       " 'biologique',\n",
       " 'biomedical',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'booleenn',\n",
       " 'boosting',\n",
       " 'born',\n",
       " 'bruitees',\n",
       " 'brut',\n",
       " 'cadrer',\n",
       " 'cadrer article',\n",
       " 'cadrer classification',\n",
       " 'cadrer general',\n",
       " 'cadrer lanalyse',\n",
       " 'cadrer projet',\n",
       " 'cadrer rechercher',\n",
       " 'cadrer theoriqu',\n",
       " 'cadrer travail',\n",
       " 'calcul',\n",
       " 'calcul similarite',\n",
       " 'calculee',\n",
       " 'calculer',\n",
       " 'campagne',\n",
       " 'cancer',\n",
       " 'candidat',\n",
       " 'capable',\n",
       " 'capacite',\n",
       " 'capteur',\n",
       " 'capturer',\n",
       " 'caracter',\n",
       " 'caractere',\n",
       " 'caracterisation',\n",
       " 'caracterise',\n",
       " 'caracteriseer',\n",
       " 'caracteriser',\n",
       " 'caracteristiqu',\n",
       " 'caracteristique',\n",
       " 'caracteristiquer',\n",
       " 'cart',\n",
       " 'carte',\n",
       " 'carte autoorganisatrice',\n",
       " 'carte topologique',\n",
       " 'cartographie',\n",
       " 'cartographique',\n",
       " 'cas',\n",
       " 'cas donnee',\n",
       " 'categorie',\n",
       " 'categoriel',\n",
       " 'categoriell',\n",
       " 'categorisation',\n",
       " 'causer',\n",
       " 'celer',\n",
       " 'celer proposer',\n",
       " 'cell',\n",
       " 'celleci',\n",
       " 'cellesci',\n",
       " 'cellule',\n",
       " 'celuici',\n",
       " 'centaine',\n",
       " 'central',\n",
       " 'centree',\n",
       " 'centrer',\n",
       " 'cesser',\n",
       " 'cestadir',\n",
       " 'chain',\n",
       " 'chaine',\n",
       " 'chaine markov',\n",
       " 'challenge',\n",
       " 'champ',\n",
       " 'changement',\n",
       " 'changer',\n",
       " 'charger',\n",
       " 'chemin',\n",
       " 'chercher',\n",
       " 'chercheur',\n",
       " 'choisir',\n",
       " 'choix',\n",
       " 'choix mesurer',\n",
       " 'chronique',\n",
       " 'cibl',\n",
       " 'cibler',\n",
       " 'cl',\n",
       " 'clairement',\n",
       " 'classe',\n",
       " 'classement',\n",
       " 'classer',\n",
       " 'classificateur',\n",
       " 'classification',\n",
       " 'classification automatique',\n",
       " 'classification croise',\n",
       " 'classification document',\n",
       " 'classification donnee',\n",
       " 'classification hierarchiqu',\n",
       " 'classification multilabel',\n",
       " 'classification supervise',\n",
       " 'classification supervisee',\n",
       " 'classifier',\n",
       " 'classifieur',\n",
       " 'classifieur bayesien',\n",
       " 'classifieur bayesien naïf',\n",
       " 'classique',\n",
       " 'cle',\n",
       " 'clef',\n",
       " 'client',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'coclustering',\n",
       " 'codage',\n",
       " 'coefficient',\n",
       " 'coeur',\n",
       " 'cognitif',\n",
       " 'coherence',\n",
       " 'collaboratif',\n",
       " 'collaboration',\n",
       " 'collecter',\n",
       " 'collectif',\n",
       " 'collection',\n",
       " 'collection document',\n",
       " 'colonne',\n",
       " 'combin',\n",
       " 'combinaison',\n",
       " 'combinatoire',\n",
       " 'combiner',\n",
       " 'commencer',\n",
       " 'commercial',\n",
       " 'commun',\n",
       " 'communaut',\n",
       " 'communautair',\n",
       " 'communautaire',\n",
       " 'communaute',\n",
       " 'communication',\n",
       " 'compact',\n",
       " 'compacter',\n",
       " 'comparaison',\n",
       " 'comparaison entrer',\n",
       " 'comparatif',\n",
       " 'comparee',\n",
       " 'comparer',\n",
       " 'comparer resultat',\n",
       " 'compatible',\n",
       " 'competence',\n",
       " 'complementair',\n",
       " 'complementarite',\n",
       " 'complet',\n",
       " 'completer',\n",
       " 'complex',\n",
       " 'complexe',\n",
       " 'complexit',\n",
       " 'complexite',\n",
       " 'comportement',\n",
       " 'comportemer',\n",
       " 'comporter',\n",
       " 'composant',\n",
       " 'compose',\n",
       " 'composer',\n",
       " 'comprehension',\n",
       " 'comprendre',\n",
       " 'compromis',\n",
       " 'compromis entrer',\n",
       " 'compter',\n",
       " 'concentrer',\n",
       " 'concept',\n",
       " 'concept treillis',\n",
       " 'concepteur',\n",
       " 'conception',\n",
       " 'conceptuel',\n",
       " 'concerner',\n",
       " 'concevoir',\n",
       " 'concis',\n",
       " 'conclure',\n",
       " 'conclusion',\n",
       " 'concret',\n",
       " 'condensee',\n",
       " 'condensees',\n",
       " 'condition',\n",
       " 'conditionnel',\n",
       " 'conduire',\n",
       " 'conferenc',\n",
       " 'conference',\n",
       " 'confiance',\n",
       " 'configuration',\n",
       " 'confirmer',\n",
       " 'conflit',\n",
       " 'confronter',\n",
       " 'conjoint',\n",
       " 'conjointement',\n",
       " 'connaiss',\n",
       " 'connaissance',\n",
       " 'connaissance baser',\n",
       " 'connaissance domaine',\n",
       " 'connaissance expert',\n",
       " 'connaissance partir',\n",
       " 'connaissance partir donnee',\n",
       " 'connaissance priori',\n",
       " 'connaissancer',\n",
       " 'connaître',\n",
       " 'connexion',\n",
       " 'connu',\n",
       " 'consequent',\n",
       " 'conserver',\n",
       " 'consider',\n",
       " 'considere',\n",
       " 'consideree',\n",
       " 'considerer',\n",
       " 'consist',\n",
       " 'consister',\n",
       " 'consommation',\n",
       " 'constant',\n",
       " 'constater',\n",
       " 'constituer',\n",
       " 'construction',\n",
       " 'construction automatique',\n",
       " 'construction darbr',\n",
       " 'construction dontologie',\n",
       " 'construir',\n",
       " 'construire',\n",
       " 'construire partir',\n",
       " 'construit',\n",
       " 'construit partir',\n",
       " 'contenir',\n",
       " 'contenir document',\n",
       " 'contenu',\n",
       " 'context',\n",
       " 'contexte',\n",
       " 'contextuel',\n",
       " 'contingence',\n",
       " 'continu',\n",
       " 'continuer',\n",
       " 'contraindre',\n",
       " 'contraint',\n",
       " 'contrainte',\n",
       " 'contrairement',\n",
       " 'contribuer',\n",
       " 'contribution',\n",
       " 'controle',\n",
       " 'controler',\n",
       " 'convergence',\n",
       " 'convier',\n",
       " 'conçu',\n",
       " 'cooperativ',\n",
       " 'corpu',\n",
       " 'corpus',\n",
       " 'correct',\n",
       " 'correctement',\n",
       " 'correlation',\n",
       " 'correlation entrer',\n",
       " 'correspondance',\n",
       " 'correspondance afc',\n",
       " 'correspondance entrer',\n",
       " 'correspondant',\n",
       " 'correspondre',\n",
       " 'couleur',\n",
       " 'coupl',\n",
       " 'couple',\n",
       " 'coupler',\n",
       " 'courir',\n",
       " 'courir temps',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'couverture',\n",
       " 'couvrir',\n",
       " 'coût',\n",
       " 'coûteux',\n",
       " 'creation',\n",
       " 'cree',\n",
       " 'creer',\n",
       " 'criter',\n",
       " 'critere',\n",
       " 'critere devaluation',\n",
       " 'croise',\n",
       " 'croisee',\n",
       " 'croiser',\n",
       " 'croissance',\n",
       " 'croyance',\n",
       " 'croître',\n",
       " 'cube',\n",
       " 'cuber',\n",
       " 'culturel',\n",
       " 'cycle',\n",
       " 'dabord',\n",
       " 'daccelerer',\n",
       " 'dacquisition',\n",
       " 'dadapter',\n",
       " 'dagregation',\n",
       " 'daid',\n",
       " 'daid decision',\n",
       " 'daider',\n",
       " 'dalgorithme',\n",
       " 'dalignemer',\n",
       " 'dameliorer',\n",
       " 'dameliorer performance',\n",
       " 'danalyse',\n",
       " 'danalyser',\n",
       " 'dannotation',\n",
       " 'danscet',\n",
       " 'danscet article',\n",
       " 'danscet article proposer',\n",
       " 'dansl',\n",
       " 'dansun',\n",
       " 'dappariemer',\n",
       " 'dapparition',\n",
       " 'dappartenance',\n",
       " 'dapplication',\n",
       " 'dapporter',\n",
       " 'dapprendre',\n",
       " 'dapprentissage',\n",
       " 'dapprentissage automatique',\n",
       " 'dapprentissage supervis',\n",
       " 'darbr',\n",
       " 'darbr decision',\n",
       " 'darticl',\n",
       " 'dassoci',\n",
       " 'dassociation',\n",
       " 'dater',\n",
       " 'dater mining',\n",
       " 'dater stream',\n",
       " 'dattribut',\n",
       " 'dattributs',\n",
       " 'daugmenter',\n",
       " 'dautre',\n",
       " 'dautre partir',\n",
       " 'debut',\n",
       " 'decd',\n",
       " 'decennie',\n",
       " 'dechantillon',\n",
       " 'dechantillonnage',\n",
       " 'decider',\n",
       " 'decideur',\n",
       " 'decis',\n",
       " 'decision',\n",
       " 'decisionnel',\n",
       " 'decisionnell',\n",
       " 'decomposition',\n",
       " 'decoupage',\n",
       " 'decouvert',\n",
       " 'decouverte',\n",
       " 'decouverte motif',\n",
       " 'decouvrir',\n",
       " 'decouvrir motif',\n",
       " 'decrir',\n",
       " 'decrire',\n",
       " 'decrit',\n",
       " 'decrite',\n",
       " 'decrivant',\n",
       " 'decriver',\n",
       " 'decrivons',\n",
       " 'dedie',\n",
       " 'dediee',\n",
       " 'dedition',\n",
       " 'dedonnee',\n",
       " 'deduire',\n",
       " 'defaut',\n",
       " 'deffectuer',\n",
       " 'defi',\n",
       " 'defi egc',\n",
       " 'defini',\n",
       " 'definie',\n",
       " 'definier',\n",
       " 'definir',\n",
       " 'definis',\n",
       " 'definisser',\n",
       " 'definissons',\n",
       " 'definit',\n",
       " 'definition',\n",
       " 'degager',\n",
       " 'degr',\n",
       " 'degre',\n",
       " 'delagage',\n",
       " 'delement',\n",
       " 'demander',\n",
       " 'demarch',\n",
       " 'demonstration',\n",
       " 'denrichir',\n",
       " 'dense',\n",
       " 'densembl',\n",
       " 'densite',\n",
       " 'dentiter',\n",
       " 'dentre',\n",
       " 'dentrepris',\n",
       " 'depart',\n",
       " 'dependanc',\n",
       " 'dependance',\n",
       " 'dependance fonctionnel',\n",
       " 'depender',\n",
       " 'deper',\n",
       " 'dequivalence',\n",
       " 'derive',\n",
       " 'derreur',\n",
       " 'descripteur',\n",
       " 'descriptif',\n",
       " 'description',\n",
       " 'desdonnee',\n",
       " 'desequilibre',\n",
       " 'destimer',\n",
       " 'detablir',\n",
       " 'detailler',\n",
       " 'detat',\n",
       " 'detecter',\n",
       " 'detection',\n",
       " 'detection changement',\n",
       " 'detectiond',\n",
       " 'detendre',\n",
       " 'determination',\n",
       " 'determine',\n",
       " 'determiner',\n",
       " 'detr',\n",
       " 'detre',\n",
       " 'detude',\n",
       " 'detudier',\n",
       " 'deuxieme',\n",
       " 'devaluation',\n",
       " 'devaluer',\n",
       " 'devaluer qualite',\n",
       " 'developp',\n",
       " 'developpe',\n",
       " 'developpee',\n",
       " 'developpement',\n",
       " 'developpemer',\n",
       " 'developper',\n",
       " 'devenement',\n",
       " 'devenir',\n",
       " 'devenir plaire',\n",
       " 'devoir',\n",
       " 'devoir permettre',\n",
       " 'devolution',\n",
       " 'dexecution',\n",
       " 'dexempl',\n",
       " 'dexperience',\n",
       " 'dexperimentation',\n",
       " 'dexploiter',\n",
       " 'dexploration',\n",
       " 'dexplorer',\n",
       " 'dexpression',\n",
       " 'dexprimer',\n",
       " 'dextraction',\n",
       " 'dextraction connaissance',\n",
       " 'dextraction connaissance partir',\n",
       " 'dextraction motif',\n",
       " 'dextrair',\n",
       " 'dextraire',\n",
       " 'dheuristiqu',\n",
       " 'diagnostic',\n",
       " 'dictionnair',\n",
       " 'didentification',\n",
       " 'didentifier',\n",
       " 'difference',\n",
       " 'differenter',\n",
       " 'difficile',\n",
       " 'difficilement',\n",
       " 'difficult',\n",
       " 'difficulte',\n",
       " 'diffusion',\n",
       " 'dimag',\n",
       " 'dimage',\n",
       " 'dimager',\n",
       " 'dimension',\n",
       " 'dincertitude',\n",
       " 'dindexation',\n",
       " 'dindice',\n",
       " 'dindividus',\n",
       " 'dinduction',\n",
       " 'dinference',\n",
       " 'dinferer',\n",
       " 'dinfluence',\n",
       " 'dinform',\n",
       " 'dinformation',\n",
       " 'dintegration',\n",
       " 'dintegrer',\n",
       " 'dinteraction',\n",
       " 'dinteraction entrer',\n",
       " 'dinteret',\n",
       " 'dinternet',\n",
       " 'dinterpretation',\n",
       " 'dinterrogation',\n",
       " 'dintroduir',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'discret',\n",
       " 'discretisation',\n",
       " 'discriminant',\n",
       " 'discriminanter',\n",
       " 'discrimination',\n",
       " 'discriminer',\n",
       " 'discussion',\n",
       " 'discuter',\n",
       " 'disponible',\n",
       " 'disposer',\n",
       " 'dispositif',\n",
       " 'disposition',\n",
       " 'dissimilarit',\n",
       " 'dissimilarite',\n",
       " 'dissimilarite entrer',\n",
       " 'distance',\n",
       " 'distancer',\n",
       " 'distancer entrer',\n",
       " 'distinct',\n",
       " 'distinguer',\n",
       " 'distribu',\n",
       " 'distribuer',\n",
       " 'distribution',\n",
       " 'ditems',\n",
       " 'ditemset',\n",
       " 'ditemset frequent',\n",
       " 'diversite',\n",
       " 'diviser',\n",
       " 'dizaine',\n",
       " 'dobjet',\n",
       " 'dobjets',\n",
       " 'dobtenir',\n",
       " 'docu',\n",
       " 'document',\n",
       " 'document textuel',\n",
       " 'document xml',\n",
       " 'documentaire',\n",
       " 'doffr',\n",
       " 'domaine',\n",
       " 'domaine dapplication',\n",
       " 'domaine lapprentissage',\n",
       " 'don',\n",
       " 'donne',\n",
       " 'donnee',\n",
       " 'donnee article',\n",
       " 'donnee artificiel',\n",
       " 'donnee baser',\n",
       " 'donnee cluster',\n",
       " 'donnee disponible',\n",
       " 'donnee geographiqu',\n",
       " 'donnee issu',\n",
       " 'donnee massif',\n",
       " 'donnee multidimensionnel',\n",
       " 'donnee numeriqu',\n",
       " 'donnee permettre',\n",
       " 'donnee plaire',\n",
       " 'donnee pouvoir',\n",
       " 'donnee presenter',\n",
       " 'donnee qualitatif',\n",
       " 'donnee reel',\n",
       " 'donnee reell',\n",
       " 'donnee reell issu',\n",
       " 'donnee reell montrer',\n",
       " 'donnee relationnel',\n",
       " 'donnee sequentiell',\n",
       " 'donnee simuleer',\n",
       " 'donnee symbolique',\n",
       " 'donnee synthetiqu',\n",
       " 'donnee textuel',\n",
       " 'donnee tr',\n",
       " 'donnee visualisation',\n",
       " 'donneer',\n",
       " 'donneer article',\n",
       " 'donneer luci',\n",
       " 'donneer plaire',\n",
       " 'donneer reell',\n",
       " 'donneer textuel',\n",
       " 'donnees',\n",
       " 'donner',\n",
       " 'donner resultat',\n",
       " 'dontologie',\n",
       " 'dontologie partir',\n",
       " 'dontologier',\n",
       " 'dopinion',\n",
       " 'doptimisation',\n",
       " 'dordre',\n",
       " 'dorigine',\n",
       " 'doter',\n",
       " 'doutil',\n",
       " 'doutils',\n",
       " 'duree',\n",
       " 'durer',\n",
       " 'durer processus',\n",
       " 'dusage',\n",
       " 'dutilisateur',\n",
       " 'dutilisation',\n",
       " 'dutiliser',\n",
       " 'dynam',\n",
       " 'dynamique',\n",
       " 'ecd',\n",
       " 'echantillon',\n",
       " 'echantillonnage',\n",
       " 'echell',\n",
       " 'echelle',\n",
       " 'eclairage',\n",
       " 'economiqu',\n",
       " 'effectu',\n",
       " 'efficace',\n",
       " 'efficacement',\n",
       " 'efficacite',\n",
       " 'effort',\n",
       " 'eg',\n",
       " 'egc',\n",
       " 'element',\n",
       " 'elev',\n",
       " 'eleve',\n",
       " 'elevee',\n",
       " 'emergent',\n",
       " 'empirique',\n",
       " 'empiriquement',\n",
       " 'employer',\n",
       " 'encompte',\n",
       " 'encourageant',\n",
       " 'encourageant prometteur',\n",
       " 'engendrer',\n",
       " 'enjeu',\n",
       " 'enjeu majeur',\n",
       " 'enregistrement',\n",
       " 'enrichir',\n",
       " 'enrichissement',\n",
       " 'ensembl',\n",
       " 'ensembl donnee',\n",
       " 'ensembl donneer',\n",
       " 'ensembl mesure',\n",
       " 'ensemble',\n",
       " 'ensemble donnee',\n",
       " 'ensemble donneer',\n",
       " 'ensemble regl',\n",
       " 'ensembliste',\n",
       " 'entite',\n",
       " 'entrainer',\n",
       " 'entrepot',\n",
       " 'entrepot donnee',\n",
       " 'entreprendre',\n",
       " 'entreprise',\n",
       " 'entrer',\n",
       " 'entrer attribut',\n",
       " 'entrer classe',\n",
       " 'entrer concept',\n",
       " 'entrer donnee',\n",
       " 'entrer ensemble',\n",
       " 'entrer groupe',\n",
       " 'entrer individu',\n",
       " 'entrer objet',\n",
       " 'entrer ontologie',\n",
       " 'entrer variable',\n",
       " 'environnement',\n",
       " 'envisageable',\n",
       " 'equivalent',\n",
       " 'erreur',\n",
       " 'espac',\n",
       " 'espace',\n",
       " 'espacer',\n",
       " 'essentiel',\n",
       " 'essentiellement',\n",
       " 'estim',\n",
       " 'estimateur',\n",
       " 'estimation',\n",
       " 'estimation densite',\n",
       " 'estimee',\n",
       " 'estimer',\n",
       " 'etablie',\n",
       " 'etablir',\n",
       " 'etablisser',\n",
       " 'etape',\n",
       " 'etat',\n",
       " 'etde',\n",
       " 'ete',\n",
       " 'ete developpe',\n",
       " 'ete etudie',\n",
       " 'ete implemente',\n",
       " 'ete propos',\n",
       " 'ete propose',\n",
       " 'ete proposees',\n",
       " 'etendu',\n",
       " 'eter',\n",
       " 'etiquetage',\n",
       " 'etiquete',\n",
       " 'etl',\n",
       " 'etle',\n",
       " 'etroitement',\n",
       " 'etude',\n",
       " 'etude comparatif',\n",
       " 'etude experimental',\n",
       " 'etuder',\n",
       " 'etudie',\n",
       " 'etudiee',\n",
       " 'etudier',\n",
       " 'euclidien',\n",
       " 'evalu',\n",
       " 'evaluation',\n",
       " 'evalue',\n",
       " 'evaluee',\n",
       " 'evaluees',\n",
       " 'evaluer',\n",
       " 'evenement',\n",
       " 'evidence',\n",
       " 'eviter',\n",
       " 'evoluer',\n",
       " 'evolution',\n",
       " 'evolutiv',\n",
       " 'ex',\n",
       " 'exact',\n",
       " 'examiner',\n",
       " 'exemple',\n",
       " 'exhaustif',\n",
       " 'exhiber',\n",
       " 'existant',\n",
       " 'exister',\n",
       " 'exister entrer',\n",
       " 'experience',\n",
       " 'experience montrer',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experimentalement',\n",
       " 'experimentation',\n",
       " 'experimentation jeu',\n",
       " 'experimentation jeu donnee',\n",
       " 'experimentation menee',\n",
       " 'experimentation montrer',\n",
       " 'experimentaux',\n",
       " 'experimentaux montrer',\n",
       " 'expert',\n",
       " 'expert domaine',\n",
       " 'explicatif',\n",
       " 'expliciter',\n",
       " 'expliquer',\n",
       " 'exploitable',\n",
       " 'exploitation',\n",
       " 'exploiter',\n",
       " 'exploration',\n",
       " 'exploratoire',\n",
       " 'explorer',\n",
       " 'exponentiel',\n",
       " 'exposer',\n",
       " 'expression',\n",
       " 'exprimeer',\n",
       " 'exprimer',\n",
       " 'extension',\n",
       " 'extraction',\n",
       " 'extraction connaissance',\n",
       " 'extraction motif',\n",
       " 'extraction regl',\n",
       " 'extraire',\n",
       " 'extraire connaissance',\n",
       " 'extraire motif',\n",
       " 'extrait',\n",
       " 'extraite',\n",
       " 'face',\n",
       " 'facile',\n",
       " 'facilement',\n",
       " 'faciliter',\n",
       " 'facteur',\n",
       " 'factoriel',\n",
       " 'factoriel correspondance',\n",
       " 'factoriel correspondance afc',\n",
       " 'factorisation',\n",
       " 'faible',\n",
       " 'faire',\n",
       " 'faire appel',\n",
       " 'faire face',\n",
       " 'faire lobjet',\n",
       " 'faire partir',\n",
       " 'faisabilite',\n",
       " 'famille',\n",
       " 'favoriser',\n",
       " 'feature',\n",
       " 'ferme',\n",
       " 'ferme frequent',\n",
       " 'fiabilite',\n",
       " 'fiable',\n",
       " 'fichier',\n",
       " 'filtrage',\n",
       " 'filtrer',\n",
       " 'fin',\n",
       " 'final',\n",
       " 'finalement',\n",
       " 'financier',\n",
       " 'fixe',\n",
       " 'fixer',\n",
       " 'flexible',\n",
       " 'flot',\n",
       " 'flot donneer',\n",
       " 'flou',\n",
       " 'flouer',\n",
       " 'flux',\n",
       " 'flux don',\n",
       " 'flux donne',\n",
       " 'flux donnee',\n",
       " 'flux donneer',\n",
       " 'focaliser',\n",
       " 'fonction',\n",
       " 'fonction croyance',\n",
       " 'fonctionnalite',\n",
       " 'fonctionnel',\n",
       " 'fonctionnement',\n",
       " 'fonctionner',\n",
       " 'fond',\n",
       " 'fondamental',\n",
       " 'fondee',\n",
       " 'fondre',\n",
       " 'for',\n",
       " 'foret',\n",
       " 'foret aleatoir',\n",
       " 'formalisation',\n",
       " 'formaliser',\n",
       " 'formalisme',\n",
       " 'format',\n",
       " 'formation',\n",
       " 'forme',\n",
       " 'formel',\n",
       " 'formel concept',\n",
       " 'former',\n",
       " 'former regl',\n",
       " 'formulation',\n",
       " 'formuler',\n",
       " 'fort',\n",
       " 'fortement',\n",
       " 'fouill',\n",
       " 'fouill donneer',\n",
       " 'fouiller',\n",
       " 'fouiller donne',\n",
       " 'fouiller donnee',\n",
       " 'fouiller donneer',\n",
       " 'fouiller grand',\n",
       " 'fouiller texter',\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeans on tfidf\n",
    "# the labels_ give assignment of doc to the cluster number \n",
    "km = KMeans(n_clusters=nb_clusters)\n",
    "km.fit(tfidf)\n",
    "cluster = km.labels_\n",
    "\n",
    "cluster_partition = [cluster[:limits[0]],cluster[limits[0]:limits[1]],cluster[limits[1]:limits[2]],cluster[limits[2]:limits[3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_km = []\n",
    "for i in range(0, len(limits)):\n",
    "    dash = km.fit(partitions_tfidf[i])\n",
    "    part_km.append(dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(part_km[1]).labels_\n",
    "#\n",
    "#all_labels = []\n",
    "#for i in range(0,len(limits)):\n",
    "#    for j in range(0, len((part_km[i]).labels_)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_clustering is a dictionnary \n",
    "# it looks like -> { doc_number : [partition_number, cluster_number] }\n",
    "# This is used to reassign doc number to their respective partition and and cluster\n",
    "doc_clustering = {}\n",
    "for i in range(0,len(usable)):\n",
    "    if i < limits[0]:\n",
    "        doc_clustering[i] = [0, cluster[i]]\n",
    "    elif i >= limits[0] and i < limits[1]:\n",
    "        doc_clustering[i] = [1, cluster[i]]\n",
    "    elif i >= limits[1] and i < limits[2]:\n",
    "        doc_clustering[i] = [2, cluster[i]]\n",
    "    else:\n",
    "        doc_clustering[i] = [3, cluster[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to get list of documents number\n",
    "# return [dou numbers]\n",
    "# params : partition_number , cluster number\n",
    "partitions = []\n",
    "def get_doc(part, clust):\n",
    "    docs = []\n",
    "    for i in range(0,len(doc_clustering)):\n",
    "        if doc_clustering[i][0] == part and doc_clustering[i][1] == clust:\n",
    "            docs.append(i)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the partitions variable\n",
    "# Here partitions[part][cluster] = list of docs numbe\n",
    "partitions = []\n",
    "for i in range(0, len(limits)):\n",
    "    clusters = []\n",
    "    for j in range(0, nb_clusters):\n",
    "        clusters.append(get_doc(i,j))\n",
    "    partitions.append(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of output for doc_clustering\n",
    "# doc 465 is in cluster 1 of the partition 1\n",
    "# doc 154 is in cluster 2 of the partition 0\n",
    "\n",
    "print(doc_clustering[465])\n",
    "print(doc_clustering[154])\n",
    "print()\n",
    "\n",
    "# Here, just count docs number by cluster.\n",
    "print(Counter(cluster_partition[0]))\n",
    "print(Counter(cluster_partition[1]))\n",
    "print(Counter(cluster_partition[2]))\n",
    "print(Counter(cluster_partition[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT QUALITY MEASURE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khi²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_of_your_word = tf[numDoc][strWord]\n",
    "tf = []\n",
    "for doc in usable:\n",
    "    tf_doc = {}\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        tf_doc[word] = doc.count(word)\n",
    "    tf.append(tf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number total of words\n",
    "# nb_total_word[numPartition]\n",
    "nb_total_word = []\n",
    "nb = 0\n",
    "\n",
    "for numDoc in range(0, len(usable)):\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        nb += tf[numDoc][word]\n",
    "    if numDoc+1 in limits:\n",
    "        nb_total_word.append(nb)\n",
    "        nb=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_total_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_word[num_partition][word]\n",
    "nb_word = []\n",
    "\n",
    "word_in_this_parti = {}\n",
    "for word in vectorizer.get_feature_names():\n",
    "    word_in_this_parti[word] = 0\n",
    "\n",
    "for numDoc in range(0, len(usable)):\n",
    "    for word in vectorizer.get_feature_names():\n",
    "        word_in_this_parti[word] += tf[numDoc][word]\n",
    "    if numDoc+1 in limits:\n",
    "        nb_word.append(word_in_this_parti)\n",
    "        word_in_this_parti = {}\n",
    "        for word in vectorizer.get_feature_names():\n",
    "            word_in_this_parti[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nb_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_word_by_cluster[numPartition][numCluster]\n",
    "nb_word_by_cluster = []\n",
    "for parti in partitions:\n",
    "    nb_word_clus = []\n",
    "    for cluster in parti:\n",
    "        nb = 0\n",
    "        for numDoc in cluster:\n",
    "            for word in vectorizer.get_feature_names():\n",
    "                nb += tf[numDoc][word]\n",
    "        nb_word_clus.append(nb)\n",
    "    nb_word_by_cluster.append(nb_word_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected values, if nothing were dependant\n",
    "# exp[numPartition][numCluster][numWord]\n",
    "#exp = []\n",
    "#for numParti in range(0, len(partitions)):\n",
    "#    exp_clus = []\n",
    "#    for numCluster in range(0, len(partitions[numParti])):\n",
    "#        exp_word = []\n",
    "#        for numWord in range(0, vectorizer.get_feature_names()):\n",
    "#            exp_word.append((nb_word[numParti][numWord] + nb_word_by_cluster[numPart][numCluster]) / nb_total_word[numParti])\n",
    "#        exp_cluster.append(exp_word)\n",
    "#    exp.append(exp_clus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_of_khi2 = khi2[numPartition][numCluster][word]\n",
    "khi2 = []\n",
    "\n",
    "for numParti in range(0, len(partitions)):\n",
    "    khi2parti = []\n",
    "    for numCluster in range(0, len(partitions[numParti])):\n",
    "        khi2cluster = {}\n",
    "        \n",
    "        for word in vectorizer.get_feature_names():\n",
    "            word_in_this_parti[word] = 0\n",
    "            E = nb_word[numParti][word]\n",
    "            E =+ nb_word_by_cluster[numParti][numCluster]\n",
    "            E = E/ nb_total_word[numParti]\n",
    "            N = 0\n",
    "            for numDoc in partitions[numParti][numCluster]:\n",
    "                N += tf[numDoc][word]\n",
    "            khi2cluster[word] = (pow(N - E, 2)/E)        \n",
    "        khi2parti.append(khi2cluster)\n",
    "    khi2.append(khi2parti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of your labels = labels[numPartition][numCluster]\n",
    "labels = []\n",
    "\n",
    "for numPartition in range(0, len(nb_word_by_cluster)):\n",
    "    label_clus = []\n",
    "    for numCluster in range(0, len(nb_word_by_cluster[numPartition])):\n",
    "        label_clus.append(Counter(khi2[numPartition][numCluster]).most_common(5))\n",
    "    labels.append(label_clus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
